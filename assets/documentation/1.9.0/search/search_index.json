{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welcome to Percona Everest","text":"<p>We are excited to welcome you to Percona Everest, designed to demonstrate the core capabilities of our new open source cloud-native database platform!</p>"},{"location":"index.html#why-percona-everest","title":"Why Percona Everest?","text":"<p>Percona Everest is the first open-source platform for automated database provisioning and management. It supports multiple database technologies and can be hosted on any Kubernetes infrastructure, in the cloud or on-premises.</p> <p></p>"},{"location":"index.html#ready-to-test-drive-percona-everest","title":"Ready to test drive Percona Everest?","text":"<p>Let\u2019s start by enabling you to deploy an automated private DBaaS, eliminating vendor lock-in and complex in-house platform development. </p> <p>Percona Everest quickstart guide Manage your first cluster </p> <p>Refer to our documentation, and you\u2019ll be set up in no time.</p>"},{"location":"index.html#discover","title":"Discover","text":"<p>Discover how Percona Everest simplifies and streamlines your database management and provisioning.</p> <p>Discover Percona Everest </p>"},{"location":"index.html#secure","title":"Secure","text":"<p>Explore how our security features are designed to ensure the security of your hosted databases.</p> <p>Secure your deployments </p>"},{"location":"index.html#manage-users","title":"Manage users","text":"<p>Learn how to manage user accounts in Percona Everest.</p> <p>Manage user accounts </p>"},{"location":"index.html#percona-everest-api","title":"Percona Everest API","text":"<p>Get ready to dive into our APIs and uncover their potential.</p> <p>Dive into our APIs </p>"},{"location":"API.html","title":"Percona Everest API","text":"<p>Percona Everest provides a set of APIs that enable you to access its features programmatically. These APIs provide a convenient and efficient way for developers to interact with the various functionalities of Percona Everest. </p>"},{"location":"API.html#using-the-api","title":"Using the API","text":"<p>The API is accessible on the same host and port as the Percona Everest Web UI. You can find detailed information about connecting to the Percona Everest Web UI in the installation guides. For instance, if you are connecting to your Percona Everest instance using port forwarding:</p> <pre><code>kubectl port-forward svc/everest 8080:8080 -n everest-system\n</code></pre> <p>You can then connect to the API via the <code>http://127.0.0.1:8080</code> host.</p>"},{"location":"API.html#authentication","title":"Authentication","text":"<p>Currently, the API only supports authentication via a JWT token. </p> <p>You can obtain this JWT token from the Web UI after logging in. For the built-in Everest users you can also obtain this JWT token by calling the following endpoint:</p> <pre><code>curl --location -s '&lt;EVEREST_HOST&gt;/v1/session' --header 'Content-Type: application/json' --data '{\"username\": \"&lt;YOUR_USERNAME&gt;\",\"password\": \"&lt;YOUR_PASSWORD&gt;\"}' | jq -r .token\n</code></pre>"},{"location":"API.html#readmeio-api-documentation","title":"Readme.io API documentation","text":"<p>While you can achieve many tasks using either the Percona Everest user interface or <code>everestctl</code>, leveraging the API allows for easier integration into your technology infrastructure.</p> <p>Check out our API endpoints for Percona Everest, where you can perform a wide range of functions.</p> <p>To access the API documentation, click Percona Everest API.</p>"},{"location":"api_rbac.html","title":"Navigating the breaking API changes for RBAC","text":"<p>Starting with Percona Everest v1.2.0, breaking changes are being made to the API for <code>monitoring-instances</code> and <code>backup-storage</code> resources. These changes are:</p> <ul> <li> <p>Before the release of Percona Everest 1.2.0, these resources were globally scoped, but now they will be specific to namespaces. </p> </li> <li> <p>The database clusters can only use <code>monitoring-instances</code> and <code>backup-storages</code> located within the same namespace as the cluster. The system used a <code>.spec.allowedNamespaces</code> field to control access to these global resources. This field determined the namespaces where the resource could be accessed, providing a certain degree of access control.</p> </li> <li> <p>With the update to Percona Everest v1.2.0, the shift from global scope to designated namespaces for these resources marks a significant change in the way access control is managed. This change enhances security by ensuring these resources are only accessible within their designated namespaces.</p> </li> </ul>"},{"location":"api_rbac.html#challenges-with-globally-scoped-namespaces","title":"Challenges with globally scoped namespaces","text":"<p>In Percona Everest v1.2.0, we\u2019ve rolled out Role Based Access Control (RBAC) to enhance security and provide more granular control over the access privileges for specific resources within the system. This implementation provides fine-grained control over which users and user groups can access particular resources within the system. </p> <p>The RBAC model functions on the principle that all resources are organized into namespaces. This enables a well-structured and hierarchical arrangement of resources, simplifying access rights management according to the namespace to which a resource is associated.</p> <p>Prior to Percona Everest version 1.2.0, certain resources such as <code>backup-storages</code> and <code>monitoring-instances</code> were not organized into namespaces but were accessible globally. To enforce access restrictions on these globally scoped resources, the system utilized a <code>.spec.allowedNamespaces</code> field. The <code>.spec.allowedNamespaces</code> field specifies the namespaces within which the resource can be accessed, giving you certain level of control.</p> <p>Using the <code>.spec.allowedNamespaces</code> field for globally scoped resources presented challenges when integrating with the core RBAC model. To fix this and align with the RBAC framework, <code>backup-storages</code> and <code>monitoring-instances</code> are now namespaced resources. This ensures that all resources conform to the same RBAC model, which results in a consistent and manageable access control structure across the system.</p>"},{"location":"api_rbac.html#changes-in-the-percona-everest-apis","title":"Changes in the Percona Everest APIs","text":"<p>The APIs have been updated with the following modifications:</p> <ul> <li> <p>The existing APIs for backup storage and monitoring instances are deprecated. Now, you should use the API path prefixed with <code>/namespaces/{namespace}</code>.</p> Example <p><code>/v1/backup-storages</code> is now</p> <p><code>/v1/namespaces/{namespace}/backup-storages</code></p> <p>Check out the API documentation for more details.</p> </li> <li> <p>The <code>.spec.allowedNamespaces</code> field has been deprecated. Access control for these resources is now managed through the RBAC policy.</p> </li> <li> <p><code>database-clusters</code> can now only reference <code>backup-storages</code> and <code>monitoring-instances</code> created within the same namespace as the <code>database-cluster</code>.</p> </li> </ul>"},{"location":"api_rbac.html#migrating-to-percona-everest-120","title":"Migrating to Percona Everest 1.2.0","text":"<p>When upgrading to 1.2.0, all your existing backup-storages and monitoring-instances will be automatically migrated to the namespaces specified in their <code>.spec.allowedNamespaces</code>fields. After the upgrade, these resources will be accessible exclusively through the new API endpoints.</p> <p>Need more details? Check out the upgrade section.</p>"},{"location":"contribute.html","title":"Contributing guide","text":"<p>Thank you for deciding to contribute and help us improve Percona Everest! We also contribute to other open source projects and communities! Let\u2019s make technology better!</p> <p>By contributing, you agree to the Percona Community code of conduct.</p> <p>We welcome all kinds of contributions so here\u2019s how you can get involved:</p> <ul> <li>Submit bug reports or feature requests</li> <li>Submit a code patch</li> <li>Contribute to documentation</li> </ul>"},{"location":"contribute.html#submit-a-bug-report-or-feature-request","title":"Submit a bug report or feature request","text":"<p>If you find a bug in Percona Everest, you can submit a report via the Percona  Everest Community Forum.  Start by searching the open topics for a similar report. If you find that someone else has already reported the same issue, you can upvote that report to increase its visibility.</p> <p>If there is no existing report, submit a report following these steps:</p> <ol> <li> <p>Sign in to Percona Everest Forum. You will need to create an account if you do not have one.</p> </li> <li> <p>Create a report that:      </p> <ul> <li>describes the steps to reproduce the issue</li> <li>includes the version of Percona Everest, your environment, and so on</li> <li>has not been reported already </li> <li>is scoped to a single bug</li> </ul> </li> </ol>"},{"location":"contribute.html#contribute-to-percona-everest-code","title":"Contribute to Percona Everest code","text":"<p>If you\u2019d like to submit a code patch, follow the Contributing guide in Everest code repository.</p>"},{"location":"contribute.html#contribute-to-percona-everest-documentation","title":"Contribute to Percona Everest documentation","text":"<p>Found a typo or didn\u2019t find what you needed? Here\u2019s how you can contribute to the documentation:</p> <ol> <li> <p>Request a doc change through a Jira issue. If you\u2019ve spotted a doc issue (a typo, broken links, inaccurate instructions, etc.) but don\u2019t have time nor desire to fix it yourself - let us know about it.</p> <ul> <li>Click the Jira link in the contact us section. This opens the Jira issue tracker.</li> <li>Sign in (create a Jira account if you don\u2019t have one) and click Create to create an issue.</li> <li>Describe the issue you have detected in the Summary, Description, Steps To Reproduce, Affects Version fields.</li> </ul> </li> <li> <p>Contribute to documentation directly. </p> <p>To contribute to the documentation, you should be familiar with the following technologies:</p> <ul> <li>Markdown markup language. We write the documentation in it.</li> <li>git and GitHub</li> </ul> <p>The <code>.md</code> files are in the <code>docs/</code> directory. </p> <p>Edit documentation online via GitHub.</p> <ul> <li> <p>Select the pencil icon next to the page title to open the source file in the GitHub editor. If you haven\u2019t worked with the repository before, GitHub creates a fork of it for you.</p> </li> <li> <p>Edit the page. You can check your changes on the Preview tab.</p> </li> <li> <p>Commit your changes:</p> <ul> <li>In the Commit changes section, describe your changes.</li> <li>Select the Create a new branch for this commit and start a pull request option.</li> <li>Click Propose changes.</li> </ul> </li> <li> <p>GitHub creates a branch and a commit for your changes. It loads a new page on which you can open a pull request to Percona. The page shows the base branch - the one you offer your changes for, your commit message and a diff - a visual representation of your changes against the original page. This allows you to make a last-minute review. When you are ready, click the Create pull request button.</p> </li> <li> <p>Someone from our team reviews the pull request and if everything is correct, merges it into the documentation. Then it gets published on the site.</p> </li> </ul> </li> </ol>"},{"location":"features.html","title":"Features","text":"<p>Some of the key features of Percona Everest are:</p>"},{"location":"features.html#deployments","title":"Deployments","text":"<ul> <li>Multi-cloud deployments: Percona Everest enables you to transcend the limitations of a single cloud provider. Deploy your databases in the Kubernetes cluster, to ensure redundancy, high availability, and data sovereignty.</li> <li>Multiple open source database support: Percona Everest offers managed solutions for Percona\u2019s open source databases, including PostgreSQL, MySQL, and MongoDB.</li> <li>Private deployments and DIY: Percona Everest provides complete control over your database environment, ensuring the privacy and security of your data. Private deployments enable you to customize every aspect of your database setup using a do-it-yourself approach.</li> </ul>"},{"location":"features.html#database-provisioning","title":"Database provisioning","text":"<ul> <li>Horizontal and vertical scaling: Percona Everest enables you to adapt to your application\u2019s demands using horizontal scaling for multi-node deployments or vertical scaling for single-node setups. With Percona Everest, you have the power to manage resources and ensure your databases are performing at their best.</li> <li>Database storage class support: Percona Everest tailors your storage needs efficiently by leveraging its database storage class support. Furthermore, it allocates resources efficiently while maintaining optimal performance and cost.    </li> <li>Disaster recovery capabilities: Percona Everest prioritizes data protection with a comprehensive disaster recovery suite. Create on-demand backups, seamlessly restore existing databases, or create new ones from backups to ensure that your data is protected.</li> <li>Advanced configuration options: Percona Everest gives fine-grained control of your database environment with advanced configuration features. You can manage external access permissions and optimize your database engine configuration.</li> </ul>"},{"location":"features.html#database-management","title":"Database management","text":"<ul> <li>Resource allocation flexibility: You can handle changing workloads by adjusting your resource allocations on the fly. Whether you need more processing power or memory, Percona Everest\u2019s vertical scaling has you covered.</li> </ul>"},{"location":"features.html#administrative","title":"Administrative","text":"<ul> <li>Database monitoring with PMM: Monitor your databases and Kubernetes clusters with Percona Monitoring and Management (PMM) to gain insights into performance metrics, query analysis, and other important functions.</li> </ul>"},{"location":"get-help.html","title":"Get help from Percona","text":"<p>Our documentation guides are packed with information, but they can\u2019t cover everything you need to know about Percona Everest. They also won\u2019t cover every scenario you might come across. Don\u2019t be afraid to try things out and ask questions when you get stuck.</p>"},{"location":"get-help.html#perconas-community-forum","title":"Percona\u2019s Community Forum","text":"<p>Be a part of a space where you can tap into a wealth of knowledge from other database enthusiasts and experts who work with Percona\u2019s software every day. While our service is entirely free, keep in mind that response times can vary depending on the complexity of the question. You are engaging with people who genuinely love solving database challenges.</p> <p>We recommend visiting our Community Forum. It\u2019s an excellent place for discussions, technical insights, and support around Percona database software. If you\u2019re new and feeling a bit unsure, our FAQ and Guide for New Users ease you in.</p> <p>If you have thoughts, feedback, or ideas, the community team would like to hear from you at Any ideas on how to make the forum better?. We\u2019re always excited to connect and improve everyone\u2019s experience.</p>"},{"location":"get-help.html#percona-experts","title":"Percona experts","text":"<p>Percona experts bring years of experience in tackling tough database performance issues and design challenges.</p> <p>We understand your challenges when managing complex database environments. That\u2019s why we offer various services to help you simplify your operations and achieve your goals.</p> Service Description 24/7 Expert Support Our dedicated team of database experts is available 24/7 to assist you with any database issues. We provide flexible support plans tailored to your specific needs. Hands-On Database Management Our managed services team can take over the day-to-day management of your database infrastructure, freeing up your time to focus on other priorities. Expert Consulting Our experienced consultants provide guidance on database topics like architecture design, migration planning, performance optimization, and security best practices. Comprehensive Training Our training programs help your team develop skills to manage databases effectively, offering virtual and in-person courses. <p>We\u2019re here to help you every step of the way. Whether you need a quick fix or a long-term partnership, we\u2019re ready to provide your expertise and support.</p>"},{"location":"quick-install.html","title":"Percona Everest quick install guide","text":"<p>Helm simplifies the installation of Percona Everest. With this guide, you\u2019ll be up and running with Percona Everest in no time. However, we also have a comprehensive installation guide that covers all possibilities.</p> <p>Percona Helm charts can be found in percona/percona-helm-charts repository in Github.</p> <p>Alternative installation method</p> <p>If you prefer an alternative method, you can install Percona Everest using everestctl.</p>"},{"location":"quick-install.html#prerequisites","title":"Prerequisites","text":"<p>Before getting started with Percona Everest, do the following:</p> <ol> <li> <p>Install Helm v3  .</p> </li> <li> <p>Install yq .</p> </li> <li> <p>Set up a Kubernetes cluster.</p> <p>Note</p> <p>Percona Everest assists with installing all the necessary operators and required packages, but does not deploy a Kubernetes cluster.</p> <p>We recommend setting up Percona Everest on the Amazon Elastic Kubernetes Service (EKS) or Google Kubernetes Engine (GKE).</p> <p>Create EKS cluster  Create GKE cluster </p> </li> <li> <p>Verify that you have access to the Kubernetes cluster that you want to use with Everest. By default, Everest uses the kubeconfig file available under <code>~/.kube/config</code>. </p> <p>If your file is located elsewhere, use the export command below to set the <code>KUBECONFIG</code> environment variable:</p> <pre><code>export KUBECONFIG=~/.kube/config\n</code></pre> <p>To verify access to the Kubernetes cluster, run the following command:</p> <pre><code>kubectl get nodes\n</code></pre> Expected output <pre><code>NAME                                    STATUS   ROLES    AGE   VERSION\ngke-&lt;name&gt;-default-pool-75d48bfc-bx8g   Ready    &lt;none&gt;   11h   v1.26.7-gke.500\ngke-&lt;name&gt;-default-pool-75d48bfc-c2df   Ready    &lt;none&gt;   11h   v1.26.7-gke.500\ngke-&lt;name&gt;-default-pool-75d48bfc-zl7k   Ready    &lt;none&gt;   11h   v1.26.7-gke.500\n</code></pre> </li> </ol>"},{"location":"quick-install.html#install-percona-everest","title":"Install Percona Everest","text":"<p>To install Percona Everest using Helm follow these steps:</p> <ol> <li> <p>Add the Percona Helm repository.</p> <pre><code>helm repo add percona https://percona.github.io/percona-helm-charts/\nhelm repo update\n</code></pre> </li> <li> <p>Install Percona Everest.</p> <pre><code>helm install everest-core percona/everest \\\n--namespace everest-system \\\n--create-namespace\n</code></pre>  \ud83c\udf10 Install Percona Everest and access it using Ingress <p>Prerequisite</p> <ul> <li> <p>An Ingress controller (e.g., Nginx) installed on your Kubernetes cluster</p> </li> <li> <p>If TLS is required on your Ingress endpoint, a Secret containing the TLS certificates</p> </li> </ul> <p>Example</p> <p>To install Percona Everest and access using Ingress, here are the steps:</p> <ol> <li> <p>Install Percona Everest:</p> <p><pre><code>helm install everest percona/everest \\\n  -n everest-system \\\n  --set ingress.enabled=true \\\n  --set ingress.ingressClassName=\"\" \\\n  --set ingress.hosts[0].host=everest.example.com \\\n  --set ingress.hosts[0].paths[0].path=/ \\\n  --set  ingress.hosts[0].paths[0].pathType=ImplementationSpecific\n</code></pre> Replace <code>everest.example.com</code> with your own domain.</p> </li> <li> <p>Verify Ingress:</p> <pre><code>kubectl get ingress -n everest-system\n</code></pre> <p>Make sure the address provided is valid and that it correctly routes to the Percona Everest service.</p> </li> </ol> Example: Custom YAML configuration file <p><pre><code>ingress:\n# -- Enable ingress for Everest server\nenabled: true\n# -- Ingress class name. This is used to specify which ingress controller should handle this ingress.\ningressClassName: \"nginx\"\n# -- Additional annotations for the ingress resource.\nannotations: {}\n# -- List of hosts and their paths for the ingress resource.\nhosts:\n    - host: everest.example.com\n      paths:\n        - path: /\n          pathType: ImplementationSpecific\n# -- TLS configuration for the ingress resource.\n# -- Each entry in the list specifies a TLS certificate and the hosts it applies to.\ntls: []\n#  - secretName: everest-tls\n#    hosts:\n#      - everest.example.com\n</code></pre> Install Percona Everest using this file:</p> <pre><code>helm install everest percona/everest \\\n-n everest-system \\\n-f everest-values.yaml\n</code></pre> \ud83d\udd12 Install Percona Everest with TLS enabled <p>Install Percona Everest with TLS enabled:</p> <pre><code>helm install everest-core percona/everest \\\n--namespace everest-system \\\n--create-namespace\n--set server.tls.enabled=true\n</code></pre> <p>For comprehensive instructions on enabling TLS for Percona Everest, see the section TLS setup with Percona Everest.</p> <p>Once Percona Everest is running successfully, you can create additional database namespaces. For detailed information, refer to the section on namespace management.</p> <p>Note</p> <ul> <li>If <code>dbNamespace.namespaceOverride</code> is set, the specified namespace will be provisioned instead of the default <code>everest</code> namespace.</li> <li>If <code>dbNamespace.enabled=false</code> is set, no namespaces will be provisioned. You can provision namespaces later with the <code>everestctl namespaces add &lt;NAMESPACE&gt;</code> command.</li> <li>If you installed Percona Everest using <code>helm</code> and need to uninstall it, make sure to uninstall it exclusively through <code>helm</code> for seamless removal.</li> </ul> </li> </ol>"},{"location":"quick-install.html#post-installation-steps","title":"Post-installation steps","text":"<p>Once you have successfully installed Percona Everest, proceed with the following steps:</p> <ol> <li> <p>Retrieve the <code>admin</code> password.</p> <pre><code>kubectl get secret everest-accounts -n everest-system -o jsonpath='{.data.users\\.yaml}' | base64 --decode  | yq '.admin.passwordHash'\n</code></pre> <p>Note</p> <p>The default admin password is stored in plain text. It is highly recommended to update the password using <code>everestctl</code> to ensure that the passwords are hashed.</p> <p>For information on user management, see the section manage users in Percona Everest.</p> </li> <li> <p>Access the Everest UI/API using one of the following options, as the <code>everest</code> Service is not exposed with an external IP by default:</p> Load BalancerIngressNode PortPort forwarding <ol> <li> <p>Use the following command to change the Everest service type to <code>LoadBalancer</code>:</p> <pre><code>helm install percona-everest percona/everest \\\n--set service.type=LoadBalancer\n</code></pre> When TLS is enabled <pre><code>NAME      TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE\neverest   LoadBalancer   10.43.172.194   34.175.201.246       443:8080/TCP    10s\n</code></pre> </li> <li> <p>Retrieve the external IP address for the Everest service. This is the address where you can then launch Everest at the end of the installation procedure. In this example, the external IP address used is <code>http://34.175.201.246</code>.</p> <pre><code>kubectl get svc/everest -n everest-system\n</code></pre> </li> </ol> <p>To access Percona Everest, open your browser and go to: <code>https://everest.example.com</code>.</p> <p>Note</p> <p>Replace <code>everest.example.com</code> with your own domain.</p> <ol> <li> <p>Run the following command to change the Everest service type to <code>NodePort</code>:</p> <pre><code>kubectl patch svc/everest -n everest-system -p '{\"spec\": {\"type\": \"NodePort\"}}'\n</code></pre> </li> <li> <p>The following command displays the port assigned by Kubernetes to the everest service, which is <code>32349</code> in this case.</p> <pre><code>kubectl get svc/everest -n everest-system\nNAME      TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\neverest   NodePort   10.43.139.191   &lt;none&gt;        8080:32349/TCP   28m\n</code></pre> When TLS is enabled <pre><code>kubectl get svc/everest -n everest-system\nNAME      TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\neverest   NodePort   10.43.139.191   &lt;none&gt;        443:32349/TCP   28m\n</code></pre> </li> <li> <p>Retrieve the external IP addresses for the kubernetes cluster nodes.</p> Expected output <pre><code>NAME                                          STATUS   ROLES    AGE   VERSION               INTERNAL-IP     EXTERNAL-IP      OS-IMAGE                             KERNEL-VERSION CONTAINER-RUNTIME\ngke-everest-test-default-pool-8bbed860-65gx   Ready    &lt;none&gt;   3m35s v1.30.3-gke.1969001   10.204.15.199   34.175.155.135   Container-Optimized OS from Google   6.1.100+       containerd://1.7.19\ngke-everest-test-default-pool-8bbed860-pqzb   Ready    &lt;none&gt;   3m35s v1.30.3-gke.1969001   10.204.15.200   34.175.120.50    Container-Optimized OS from Google   6.1.100+       containerd://1.7.19\ngke-everest-test-default-pool-8bbed860-s0hg   Ready    &lt;none&gt;   3m35s v1.30.3-gke.1969001   10.204.15.201   34.175.201.246   Container-Optimized OS from Google   6.1.100+       containerd://1.7.19\n</code></pre> </li> <li> <p>To launch the Percona Everest UI and create your first database cluster, go to the IP address/port found in steps 2 and 3. In this example, the external IP address used is <code>http://34.175.155.135:32349</code>. Nevertheless, you have the option to use any node IP specified in the above steps.</p> </li> </ol> <p>The <code>kubectl port-forward</code> command in Kubernetes is used to create a temporary connection between your local machine and a specific Kubernetes resource (e.g., a Pod, Service, or Deployment) by forwarding traffic from a local port to a port on the resource. </p> <ol> <li> <p>Run the following command to setup a port-forward to the Percona Everest server service:</p> <pre><code>kubectl port-forward svc/everest 8080:8080 -n everest-system\n</code></pre> <p>Percona Everest will be available at <code>http://127.0.0.1:8080</code>. This method is mostly useful for testing purposes. </p> When TLS is enabled <pre><code>kubectl port-forward svc/everest 8443:443 -n everest-system\n</code></pre> <p>Percona Everest will be available at <code>https://127.0.0.1:8443</code>.</p> </li> </ol> </li> </ol>"},{"location":"quick-install.html#next-steps","title":"Next steps","text":"<p>Provision a database </p>"},{"location":"administer/Idp_groups_integration.html","title":"RBAC: Integration with IdP groups","text":"<p>You can now assign RBAC policies to user groups from an external IDP. This update simplifies permissions management for external users, eliminating the need for unique Sub IDs (unique identifiers for authenticated users).</p> <p>During the SSO authentication, if the group\u2019s scope is requested but the Identity Provider (IdP) lacks the necessary groups claim configuration or does not support it by default, SSO could fail or not function as expected.</p> <p>A user will be authorized to perform an operation if either their subject or any of the groups they belong to has the required permission. To use IdP groups in Percona Everest RBAC, you would need to set up the groups claim in your IdP provider configuration.</p>"},{"location":"administer/Idp_groups_integration.html#okta","title":"OKTA","text":"<p>Once you successfully establish an Identity Provider (IdP) integration with Okta, the <code>issuerURL</code> in this configuration identifies your API server, serving as a unique identifier for your server within Okta. Additionally, you will have a client application, referred to as the Application integration, which is represented by the <code>clientID</code>. This setup allows for secure communication and authentication between your application and Okta\u2019s services.</p> <p>To use IdP groups in Percona Everest RBAC, set up the groups claim in your IdP provider settings. Here are the steps to configure the groups claim:</p> <ol> <li> <p>Navigate to Security &gt; API.</p> </li> <li> <p>In the list, find the API server that you use and click Edit.</p> </li> <li> <p>Click Scopes &gt; Add Scope. </p> <p>Note</p> <p>A scope specifies the level and type of access a client application can request from an Identity Provider (IdP) during the authentication process.</p> <p>Add a scope called groups while keeping all other options to their default settings.</p> <p></p> </li> <li> <p>Click Create.</p> </li> <li> <p>Click Claims &gt; Add Claim. </p> <p>Note</p> <p>A claim specifies the scope to activate and the information required within that scope.</p> <ol> <li> <p>Add a claim named groups.</p> </li> <li> <p>Set the Include in token type to ID Token and choose Always.</p> </li> <li> <p>Change the Value type to Groups.</p> </li> <li> <p>Select the Filter as Matches regexp and add a filter to match the desired Okta groups for Everest, for example: .*.</p> </li> <li> <p>Set Include in to groups, which is the scope you created earlier.</p> </li> </ol> <p></p> </li> <li> <p>Click Access Policies &gt; Add Policy. A policy restricts how this authorization server is used.</p> <ol> <li> <p>Add Name and Description.</p> </li> <li> <p>Assign the policy to the client (Application Integration) you created earlier. The field should auto-complete as you type. Create the policy.</p> </li> <li> <p>Create the policy.</p> </li> </ol> <p></p> </li> <li> <p>Add a rule to the policy. A Rule defines the details of usage:</p> <ol> <li> <p>Add a name. If you prefer, you can use default option.</p> </li> <li> <p>Fine-tune the settings to align with your organization\u2019s security policy. Here are some suggestions:</p> <ul> <li>Uncheck all grant types except for the Authorization Code.</li> <li>Adjust the token lifetime to determine how long a session can remain active.</li> <li>Restrict the refresh token lifetime or consider deactivating it completely.</li> </ul> <p></p> </li> <li> <p>Click Create Rule.</p> </li> </ol> </li> </ol>"},{"location":"administer/Idp_groups_integration.html#configure-percona-everest-to-fetch-groups-from-idp","title":"Configure Percona Everest to fetch groups from IdP","text":"<p>During the SSO authentication, if the group\u2019s scope is requested but the Identity Provider (IdP), like Okta, lacks the necessary groups claim configuration or does not support it by default, SSO could fail or not function as expected.</p> <p>To retrieve the OIDC groups, you need to include the scope by specifying the following fields:</p> <pre><code>everestctl settings oidc configure --issuer-url &lt;oidc_issuer_url&gt; --client-id &lt;client_id&gt; --scopes openid,profile,email,groups\n</code></pre> <p>Take a look at the descriptions of the various fields in the table below:</p> Field Description scopes openid Grants access to the user\u2019s identity, necessary for OIDC flows to issue an ID token with the unique identifier (subject sub). profile Grants access basic profile information. email Grants access to the user\u2019s email address and its verification status. groups Grants access to obtain information about the user\u2019s group memberships. <p>Note</p> <p>The default scope is set to <code>openid profile email</code>.</p> Example <p>Let\u2019s consider a scenario where an employee needs to log into the company portal using SSO.</p> <ol> <li> <p>The portal redirects to OKTA and requests the following scope:</p> <pre><code>everestctl settings oidc configure --issuer-url https://example.com --client-id 123456 --scopes openid,profile,email,groups\n</code></pre> </li> <li> <p>OKTA authenticates the user and provides an ID token that includes:</p> <ul> <li><code>openid</code> - User identifier (sub)</li> <li><code>profile</code> - Users name, picure, and other profile data</li> <li><code>email</code> - Verified email address</li> <li><code>groups</code> - User\u2019s group membership (ProjecTeam,Admins)</li> </ul> </li> </ol> <p>The portal retrieves the group\u2019s claim from the ID token and grants access to the appropriate dashboard based on the user\u2019s membership.</p>"},{"location":"administer/Idp_groups_integration.html#configure-rbac-to-assign-permissions-to-the-groups","title":"Configure RBAC to assign permissions to the groups","text":"<p>To configure RBAC, you can assign permissions to the groups that a user belongs to. Just specify the name of the group when creating the policy assignment.</p> <pre><code>g, groupname, role:admin\n</code></pre> <p>Similarly, for policies:</p> <pre><code>p, groupname, database-clusters, *, */\n</code></pre> <p>For additional information, refer to the section on assigning roles to users in RBAC.</p>"},{"location":"administer/affinity.html","title":"Leveraging Pod scheduling policies in Percona Everest","text":"<p>Important</p> <p>Percona Everest relies on the Kubernetes scheduler for pod placement and resource management.</p>"},{"location":"administer/affinity.html#introduction","title":"Introduction","text":"<p>Percona Everest supports database workload scheduling on Kubernetes by allowing users to define Pod scheduling policies, including Kubernetes Affinity and Anti-Affinity rules. These policies not only optimize performance and enhance system resilience but also ensure that your resources are utilized to their fullest potential.</p>"},{"location":"administer/affinity.html#why-pod-scheduling-policies-matter","title":"Why Pod scheduling policies matter","text":"<p>Database administrators often need control over the allocation of database workloads across Kubernetes clusters. This is important for enhancing performance, improving resource management, or ensuring high availability based on deployment needs. This section describes a solution that Percona Everest provides to address this challenge.</p>"},{"location":"administer/affinity.html#what-pod-scheduling-policies-feature-aims-to-achieve","title":"What Pod scheduling policies feature aims to achieve","text":"<p>This feature in Percona Everest aims to achieve the following goals:</p> <ol> <li> <p>Enable Percona Everest users to utilize the Kubernetes Affinity and Anti-Affinity features when deploying their database clusters.</p> </li> <li> <p>Enable Percona Everest administrators to simplify the complexity of Kubernetes Affinity rules configuration for users:</p> <ul> <li>Administrators can create Affinity presets independently.</li> <li>Users can then select which Affinity preset to apply to their database cluster.</li> </ul> </li> </ol>"},{"location":"administer/affinity.html#understanding-pod-scheduling-policies","title":"Understanding Pod scheduling policies","text":"<p>Important</p> <p>Pod scheduling policies do not belong to or are limited by any namespace. In general, they can be used in all namespaces.</p> <p>The Pod scheduling policy is preset\u00a0that includes a set of Kubernetes\u00a0Affinity\u00a0rules applied to the appropriate DB cluster components.</p> <p>Kubernetes features three primary types of affinity that play a crucial role in how pods are scheduled and interact within a DB cluster. </p>"},{"location":"administer/affinity.html#pod-affinity","title":"Pod affinity","text":"<p>Pod affinity enables you to control the placement of pods based on the location of other pods. By using affinity rules, you can ensure that pods are scheduled together (co-located) on the same node, in the same zone, or within any other topological boundary.</p> <p>Kubernetes uses labels, which are key-value pairs, to identify and categorize pods.</p> <p>\ud83d\udcda Learn more in Kubernetes documentation - Pod affinity.</p>"},{"location":"administer/affinity.html#pod-anti-affinity","title":"Pod anti-affinity","text":"<p>Pod anti-affinity prevents certain pods from being scheduled on the same node or within the same topology, such as a zone or region.</p> <p>Like pod affinity, Pod anti-affinity also uses pod labels to identify and match pods that should not be co-located.</p> <p>\ud83d\udcda Learn more in Kubernetes documentation - Pod anti-affinity.</p>"},{"location":"administer/affinity.html#node-affinity","title":"Node affinity","text":"<p>Node affinity determines which nodes a pod can be scheduled on. Based on the labels assigned to nodes, you can define rules about where a pod should or should not be deployed. </p> <p>Nodes in a Kubernetes cluster have labels that consist of key-value pairs.</p> <p>\ud83d\udcda Learn more in Kubernetes documentation - Node affinity.</p>"},{"location":"administer/affinity.html#types-of-pod-scheduling-policies","title":"Types of Pod scheduling policies","text":"<p>There are two types of policies in Percona Everest:</p> <ul> <li>Default Policies - Predefined Pod scheduling policies in Percona Everest that come bundled with every Percona Everest deployment.</li> <li>Custom policies - User-defined pod scheduling policies created to meet specific requirements.</li> </ul>"},{"location":"administer/affinity.html#next-steps","title":"Next steps","text":"<p>Default Pod scheduling policies </p> <p>Custom Pod scheduling policies </p>"},{"location":"administer/apply_policies_cluster.html","title":"Apply or change Pod scheduling policies for your DB clusters","text":""},{"location":"administer/apply_policies_cluster.html#apply-pod-scheduling-policy-to-a-new-db-cluster","title":"Apply pod scheduling policy to a new DB cluster","text":"<p>Important</p> <p>If RBAC is enabled, Percona Everest only displays Pod scheduling policies applicable to the selected DB Engine type for which the user has read access.</p> <p>You can apply a Pod scheduling policy when creating a cluster by following these steps:</p> <ol> <li> <p>From the database creation wizard, go to Advanced Configurations page. In the Pod scheduling policy section, choose a policy from the dropdown.</p> <p></p> </li> <li> <p>Click Continue till you reach the end of the wizard.</p> </li> <li> <p>Click Create Database to apply the policy.</p> </li> </ol> <p>Note</p> <p>You must first create the policy to see the custom policy in the Pod scheduling policy dropdown on the Advanced Configurations page. </p>"},{"location":"administer/apply_policies_cluster.html#apply-pod-scheduling-policy-to-an-existing-db-cluster","title":"Apply pod scheduling policy to an existing DB cluster","text":"<p>Warning</p> <p>When you apply a policy to an existing DB cluster, the database cluster may restart to use the new affinity configuration.</p> <p>You can apply a Pod scheduling policy for an existing DB cluster by following these steps:</p> <ol> <li> <p>Go to the Overview page of the desired cluster and click Edit on the Advanced configuration panel. The Edit advanced configuration pop-up opens.</p> </li> <li> <p>In the Pod scheduling policy section, select the policy from the dropdown.</p> </li> <li> <p>Click Save. The chosen pod scheduling policy will now be added to your cluster.</p> <p> </p> </li> </ol>"},{"location":"administer/apply_policies_cluster.html#change-pod-scheduling-policy-for-an-existing-db-cluster","title":"Change Pod scheduling policy for an existing DB cluster","text":"<p>Warning</p> <p>When you change the policy from policy A to policy B, the database cluster might restart to apply the new affinity configuration.</p> <p>You can change a Pod scheduling policy for an existing DB cluster by following these steps:</p> <ol> <li> <p>Go to the Overview page of the cluster you want to modify and click Edit in the Advanced configuration panel. The Edit advanced configuration pop-up opens.</p> <p></p> </li> <li> <p>In the Pod scheduling policy section, choose the policy you want to apply to the existing cluster.</p> <p> </p> </li> <li> <p>Click Save. The new policy will be applied to your DB cluster.</p> </li> </ol>"},{"location":"administer/apply_policies_cluster.html#remove-pod-scheduling-policy-for-an-existing-db-cluster","title":"Remove Pod scheduling policy for an existing DB cluster","text":"<p>To remove the policy from the cluster, turn off the Enable toggle in the Pod scheduling policy section. This will disable the policy assigned to the DB cluster.</p> <p> </p>"},{"location":"administer/custom_policies.html","title":"Custom Pod scheduling policies","text":"<p>Percona Everest allows you to define custom Pod scheduling policies to control how database pods are placed on Kubernetes nodes.</p>"},{"location":"administer/custom_policies.html#manage-pod-scheduling-policies-in-percona-everest","title":"Manage Pod scheduling policies in Percona Everest","text":"<p>A Percona Everest administrator or anyone with the necessary RBAC permissions can create, edit, or delete the Pod scheduling policies. Over time, these policies may need to be updated to add new affinity rules, modify existing ones, or remove outdated configurations.</p>"},{"location":"administer/custom_policies.html#create-pod-scheduling-policy-for-your-db-cluster","title":"Create Pod scheduling policy for your DB cluster","text":"<p>Here are the steps to configure pod scheduling rules for the policies for your database clusters:</p> <ol> <li> <p>From the Percona Everest home page, navigate to the  Settings &gt; Pod scheduling policies page. Here, you can view both default and custom policies.</p> <p></p> </li> <li> <p>Click Create policy.</p> </li> <li> <p>In the pop-up that appears, enter a Policy name and select the database technology from the dropdown. Click Create.</p> </li> <li> <p>Click Add rule.</p> </li> <li> <p>A pop-up will appear where you need to enter the following details for the Rule type and Rule details section:</p> <p></p> <p>Refer to the following table for the detailed attribute descriptions.</p> \ud83d\udccb Custom Pod scheduling rule attributes <p>The table below describes the key attributes used to define pod scheduling rules in Percona Everest:</p> Attribute Description Comments Components The database cluster components the rule applies to:- DB Node- Proxy / Router / PgBouncer- Config Server - DB Nodes and Proxies are applicable for MySQL and PostgreSQL.- Config Servers apply to MongoDB sharded clusters. Priority Defines the distinct level of rule enforcement:- Preferred: Kubernetes will try to honor the rule but will schedule the pod even if it\u2019s not met.- Required: The rule must be satisfied for the pod to be scheduled. Use Preferred for flexible placement and Required for hard constraints. Weight (1\u2013100) Determines the priority of a Preferred rule. Higher values indicate stronger preference. Only applicable to Preferred rules. Topology Key Specifies the domain used to group nodes or pods for affinity. Determines the scope (e.g., zone, hostname) for applying scheduling rules. Examples: <code>kubernetes.io/hostname</code><code>topology.kubernetes.io/zone</code> <code>topology.kubernetes.io/region</code>Custom: <code>rack</code> Key The pod label key used in Pod Affinity or Anti-Affinity rules. Helps target specific pods to influence scheduling decisions. Should match a label present on existing pods in the cluster.Examples:- <code>app</code>- <code>security</code>- <code>environment</code>- Custom: <code>web-store</code> Operator Logical condition used to evaluate the Key and Values. Determines how Kubernetes interprets the label match. Supported Operators:- <code>In</code>: Matches if the label value is in a specified list- <code>NotIn</code>: Matches if not in the list- <code>Exists</code>: Matches if the label key exists (regardless of value)- <code>DoesNotExist</code>: Matches if the label key does not exist Values Specific label values that must match for the rule to apply. Required when using <code>In</code> or <code>NotIn</code> operators. Examples:- <code>s2</code>- <code>database</code>- <code>production</code>- Custom: <code>finance</code>, <code>cache-tier</code> </li> <li> <p>Click Add to save the rule. The new pod scheduling policy is now available and can be applied to relevant components.</p> </li> </ol>"},{"location":"administer/custom_policies.html#update-pod-scheduling-rule-for-a-policy","title":"Update Pod scheduling rule for a policy","text":"<p>Warning</p> <p>If a user modifies a policy that is already in use by any DB cluster, the rule changes are propagated immediately to all DB clusters using this policy, which may result in restarts of DB pods.</p> <p>Here are the steps to update a Pod scheduling policy rule:</p> <ol> <li> <p>From the Percona Everest home page, navigate to the  Settings &gt; Pod scheduling policies page.</p> </li> <li> <p>Select the policy that you want to update.</p> </li> <li> <p>Click on the Edit icon. The Edit rule pop-up opens.</p> <p></p> </li> <li> <p>Make the required changes and click Save. </p> <p>The updated policy will be applied to all the affected database clusters.</p> </li> </ol>"},{"location":"administer/custom_policies.html#delete-pod-scheduling-policy","title":"Delete pod scheduling policy","text":"<p>If a specific Pod scheduling policy is no longer needed, the Percona Everest Administrator or anyone with the proper permissions can delete it.</p> <p>Here are the steps to delete a Pod scheduling policy:</p> <ol> <li> <p>From the Percona Everest home page, navigate to the  Settings &gt; Pod scheduling policies page.</p> </li> <li> <p>Click the ellipsis (three dots) next to the policy you want to delete.</p> </li> <li> <p>Click on the Delete icon. The Delete Rule confirmation pop-up opens.</p> </li> <li> <p>Click Delete.</p> <p>Note</p> <p>Before deleting a policy, ensure it is first removed from any cluster where it has been applied.</p> </li> </ol>"},{"location":"administer/default_policies.html","title":"Default configuration for Pod scheduling policies","text":"<p>In Percona Everest, the default pod scheduling policies are preset rules that help ensure optimal placement of database components across a Kubernetes cluster.</p> <p>Percona Everest users can use these predefined settings without the need to create custom rules for every database cluster they set up. </p> <p>Important</p> <ul> <li>The predefined Pod scheduling policies in Percona Everest are applied by default with every deployment for new and existing DB clusters based on your database type.</li> <li>Default policies cannot be modified or deleted.</li> <li>We recommend using the default pod scheduling policies for most deployments. The default policies are designed to allocate all the DB components on separate Kubernetes nodes, making the DB clusters redundant for fault tolerance.</li> </ul>"},{"location":"administer/default_policies.html#common-attributes-of-default-pod-scheduling-policies","title":"Common attributes of default Pod scheduling policies","text":"<p>The following are the common attributes of a default policy for all three database technologies.</p> <ul> <li> <p>Type: The Affinity Type applied is\u00a0Pod Anti-Affinity. This ensures that pods of the same component are not co-located on the same node.</p> </li> <li> <p>Preference: Preferred means the scheduler will try to satisfy this rule but will still schedule the pod even if the condition cannot be met.</p> </li> <li> <p>Topology Key: The topology key <code>kubernetes.io/hostname</code> defines the scope of the rule. In this case, it ensures that the anti-affinity is evaluated at the node level, preventing matching pods from being placed on the same node.</p> </li> </ul> <p>These policies use pod labels to identify which pods should not be co-located. The scheduler will\u00a0try\u00a0to honor the rule but will not enforce the separation of pods.</p>"},{"location":"administer/default_policies.html#default-policy-components-by-database-technology","title":"Default policy components by database technology","text":"<p>The Components for a default policy change as per the technology:</p>"},{"location":"administer/default_policies.html#components-for-mysql-database","title":"Components for MYSQL database","text":"<ul> <li> <p>DB Node: The core component that stores and serves data.</p> </li> <li> <p>Proxy: Acts as a load balancer and router for DB Nodes.</p> </li> </ul> <p>Default anti-affinity prevents multiple DB Nodes or Proxies of the same cluster from being scheduled on the same node.</p> <p></p>"},{"location":"administer/default_policies.html#components-for-postgresql-database","title":"Components for PostgreSQL database","text":"<ul> <li>DB Node: The main PostgreSQL database engine instance.</li> <li>PG Bouncer: A lightweight connection pooler for PostgreSQL.</li> </ul> <p>The policy ensures separation (that is, allocate each DB cluster or component to a seperate node) between DB Nodes and PG Bouncers. </p> <p></p>"},{"location":"administer/default_policies.html#components-for-mongodb-database-sharded-cluster","title":"Components for MongoDB database sharded cluster","text":"<ul> <li>DB Node: Stores the actual application data.</li> <li>Config Server: Stores metadata and configuration for the cluster; required for sharding.</li> <li>Router: It routes queries to the correct shard(s).</li> </ul> <p>This policy prevents multiple replica set members or config servers from failing simultaneously if a node goes down.</p> <p></p>"},{"location":"administer/default_policies.html#components-for-mongodb-database-non-sharded-cluster","title":"Components for MongoDB database non-sharded cluster","text":"<ul> <li>DB Node: Replica set members that handle reads and writes for the complete dataset</li> </ul> <p>This policy is designed to prefer the placement of DB Nodes (replica set members) on separate nodes.</p>"},{"location":"administer/manage_namespaces.html","title":"Namespaces management","text":"<p>The management of namespaces plays a vital role in efficiently organizing and allocating resources within Percona Everest.</p>"},{"location":"administer/manage_namespaces.html#add-new-namespaces","title":"Add new namespaces","text":"<p>You can run the following command for provisioning a new DB namespace:</p> <pre><code>everestctl namespaces add [NAMESPACE]\n</code></pre> <p>The command supports the following flags:</p> <p><code>--operator.mongodb=&lt;bool&gt;</code></p> <p><code>--operator.postgresql=&lt;bool&gt;</code></p> <p><code>--operator.xtradb-cluster=&lt;bool&gt;</code></p> <p><code>--take-ownership</code> - Allows Percona Everest to manage an existing Kubernetes namespace by adding the necessary labels. Without this flag, Percona Everest will attempt to create the namespace and throw an error if it already exists. Use this flag to take over an existing namespace.</p> Example <p><pre><code>everestctl namespaces add development --operator.postgresql=false\n\u2713 Installing namespace 'development'\n</code></pre> In the above command, we did not specify the MongoDB and MySQL operators.       Therefore, by default, Percona Everest assumes these operators are true and will add them.</p> <pre><code>everestctl namespaces add production\n\n? Which operators do you want to install? MongoDB    \n\u2713 Installing namespace 'production'\n</code></pre> <p>Note</p> <p>The <code>everestctl install</code> command allows you create database namespaces during the initial installation. However, it cannot be rerun to add more database namespaces. To create additional database namespaces after installation, use the namespaces add command.</p> <ul> <li> <p>To provision a DB namespace after installation, use the command <code>everestctl namespaces add</code>. </p> </li> <li> <p>You may choose to skip the DB namespace installation in the <code>everestctl install</code> command.</p> </li> </ul>"},{"location":"administer/manage_namespaces.html#update-namespaces","title":"Update namespaces","text":"<p>Important</p> <p>Removing operators with <code>update</code> is currently not supported.</p> <p>You can run the following command to add more operators to an existing DB namespace.</p> <pre><code>everestctl namespaces update [NAMESPACE] \n</code></pre> Example <pre><code>everestctl namespaces update development\n\n? Which operators do you want to install? MongoDB\n\u2713 Updating namespace 'development'\n</code></pre>"},{"location":"administer/manage_namespaces.html#delete-namespaces","title":"Delete namespaces","text":"<p>You can run the following command for deleting namespaces:</p> <pre><code>everestctl namespaces remove [NAMESPACE]\n</code></pre> <ul> <li> <p>This command deletes only the specified namespace, as long as it is managed by Percona Everest.</p> </li> <li> <p>Setting <code>--keep-namespace</code> deletes all resources within the namespace (e.g., operators, DatabaseClusters, BackupStorages) while preserving the namespace itself. Use this option to clean up the namespace without removing it.</p> </li> </ul> Example <pre><code>everestctl namespaces remove development\n\n\u2713 Deleting database clusters in namespace 'development'\n\u2713 Deleting backup storages in namespace 'development'\n\u2713 Deleting monitoring instances in namespace 'development'\n\u2713 Deleting namespace 'development'\n</code></pre>"},{"location":"administer/manage_users.html","title":"Manage users in Percona Everest","text":"<p>Percona Everest provides user management capabilities, enabling you to securely log in through either the Percona Everest UI or the API.</p> <p>Local user management involves administering Percona Everest users to ensure secure access to database resources. This encompasses tasks such as creating and deleting users, updating their passwords, etc.</p> <p>When you install Percona Everest, an <code>admin</code> user is automatically created, granting full access to the system.</p> <p>Note</p> <p>We strongly recommend using Single Sign-On (SSO) integration for the production environment.</p>"},{"location":"administer/manage_users.html#overview","title":"Overview","text":"<p>All user accounts are stored in the YAML format within the <code>everest-accounts</code> Secret in the <code>everest-system</code> namespace:</p> User accounts: YAML format <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n    name: everest-accounts\n    namespace: everest-system\ndata:                    \n  users.yaml: YWRtaW46CiAgcGFzc3dvcmRIYXNoOiBhZG1pbgogIGVuYWJsZWQ6IHRydWUKICBjYXBhYmlsaXRpZXM6CiAgICAtIGxvZ2lu\n</code></pre> <p>Decoding the base64 encoded value will yield a YAML that appears as follows:</p> YAML after decoding <pre><code>admin:\n    passwordHash: &lt;password&gt;\nenabled: true\ncapabilities:\n    - login\n</code></pre>"},{"location":"administer/manage_users.html#user-management-commands","title":"User management commands","text":"<p>This section provides a list of <code>everestctl</code> commands for managing users in Percona Everest.</p>"},{"location":"administer/manage_users.html#retrieve-password","title":"Retrieve password","text":"<p>You can retrieve the password for the <code>admin</code> user by running the following command:</p> <pre><code>everestctl accounts initial-admin-password\n</code></pre> <p>Note</p> <p>The passwords in this Secret are stored as hashes. However, the initial admin user has the password stored as plain text for convenient retrieval later on. We strongly recommend that you update the admin password after installation.</p>"},{"location":"administer/manage_users.html#update-the-password","title":"Update the password","text":"<p>To update the password for an existing user:</p> <pre><code>everestctl accounts set-password -u &lt;username&gt;\n</code></pre> <p>You will be prompted to update the password.</p> Example <pre><code>? Enter new password **********\n? Re-enter new password **********\n</code></pre>"},{"location":"administer/manage_users.html#create-a-new-user","title":"Create a new user","text":"<p>To create a new user:</p> <p><pre><code>everestctl accounts create -u &lt;username&gt;\n</code></pre> You will be prompted to enter the password for this user.</p> Example <pre><code>? Enter new password **********\nP2024-06-27T08:11:34Z   info    cli/accounts.go:141 User 'rasika' has been created  {\"component\": \"accounts\"}\n</code></pre> <p>Important</p> <p>For Percona Everest versions 1.0.0 and later, new users have full access to the system. However, once RBAC support is in place, an admin user will be able to manage permissions for users, granting them fine-grained control over database resources.</p> <p>For detailed information on granting permissions to new users, see assign permissions to a new user section.</p>"},{"location":"administer/manage_users.html#list-the-users","title":"List the users","text":"<p>To list all the users in Percona Everest:</p> <pre><code>everestctl accounts list\n</code></pre>"},{"location":"administer/manage_users.html#delete-a-user","title":"Delete a user","text":"<p>To delete an existing user:</p> <pre><code>everestctl accounts delete -u &lt;username&gt;\n</code></pre>"},{"location":"administer/manage_users.html#json-web-token-jwt-and-keys","title":"JSON Web Token (JWT) and keys","text":"<p>When you log in from the UI, Percona Everest issues a JSON Web Token to authenticate the requests. By default, this token is valid for 24 hours, after which you are expected to log in again.</p> <p>Important</p> <p>Since JWT authentication is stateless, it is currently impossible to explicitly revoke specific tokens. Therefore, even a deleted user may continue to request the API as long as they have a valid token.</p> <p>The Everest API uses the RSA algorithm to sign and verify the JWT. The RSA key pair used for this is automatically generated upon installation and stored in the <code>everest-jwt</code> Secret in the <code>everest-system</code> namespace.</p> <pre><code>    apiVersion: v1\n    data:\n        id_rsa: &lt;PRIVATE KEY&gt;\n        id_rsa.pub: &lt;PUBLIC KEY&gt;\n    kind: Secret\n    metadata:\n        name: everest-jwt\n        namespace: everest-system\n    type: Opaque\n</code></pre> <p>To reset the key pair:</p> <pre><code>everestctl accounts reset-jwt-keys\n</code></pre>"},{"location":"administer/rbac.html","title":"Role-based access control (RBAC)","text":"<p>Role-based access control (RBAC) restricts access to resources within Percona Everest. It establishes a framework that defines access permissions and privileges according to individual users\u2019 roles. With RBAC, only authorized individuals can access specific information or perform certain actions based on their assigned roles. This method improves security by minimizing the risk of unauthorized access and helps manage permissions more efficiently across Percona Everest.</p> <p>Warning</p> <p>RBAC will not work if you have configured Single sign-on (SSO) and your identity provider (IdP) is Microsoft Entra.</p>"},{"location":"administer/rbac.html#how-to-enable-rbac","title":"How to enable RBAC","text":"<p>To enable or disable RBAC in Percona Everest, you can use a configuration flag that allows switching between RBAC-enabled and RBAC-disabled modes. By default, RBAC is disabled.</p> <p>Important</p> <p>The RBAC configuration is stored in a <code>ConfigMap</code> named <code>everest-rbac</code> within the <code>everest-system</code> namespace.</p> <p>Here\u2019s how you can enable RBAC:</p> <pre><code>apiVersion: v1\ndata:\n  enabled: \"true\"\n  policy.csv: |\n    g, admin, role:admin\nkind: ConfigMap\nmetadata:\n  name: everest-rbac\n  namespace: everest-system\n</code></pre>"},{"location":"administer/rbac.html#policy-definition-in-rbac","title":"Policy definition in RBAC","text":"<p>RBAC policies are the rules and guidelines that define how roles, permissions, and users are managed within RBAC. These policies ensure that users have appropriate access to resources based on their roles within Percona Everest.</p> <p>The policy definition in Percona Everest is:</p> <pre><code>p, &lt;subject&gt;, &lt;resource-type&gt;, &lt;action&gt;, &lt;resource-name&gt;\n</code></pre> <p>Where:</p> <p>subject: Refers to the name of the role or user. For example, <code>role:admin</code> or <code>admin</code></p> <p>resource-type: Refers to the type of Everest resource, such as <code>namespaces</code>, <code>database-clusters</code>, <code>database-engines</code>, etc.</p> <p>For in-depth information on the actions that a subject can perform, see the resources and permissions section.</p> <p>action: Refers to the action the subject can perform. For example, <code>read</code>, <code>update</code>, <code>delete</code>, <code>create</code>, or <code>*</code></p> <p>resource-name: Refers to a specific instance of the given resource-type. The argument should be prefixed with the namespace in which the resource is present <code>&lt;namespace&gt;/&lt;resource-name&gt;</code>. For example, <code>my-namespace/my-cluster-1</code>, <code>my-namespace-2/my-backup-1</code>, etc. You may also use a wildcard, such as <code>*</code>, <code>*/*</code>, or <code>my-namespace/*</code></p> <p>Important</p> <p>If you have permission for specific namespaces or resources, you can perform read, update, create, or delete actions only on those resources or only within those namespaces. However, if you have permission for all the resources or namespaces, you can carry out these actions across all the resources and namespaces.</p> <p>Example:</p> <p><code>p, example-user, database-clusters, read, example-namespace/example-db</code></p> <p>In this case, the <code>example-user</code> user has permissions to read a database called <code>example-db</code> in the <code>example-namespace</code>namespace.</p>"},{"location":"administer/rbac.html#rbac-resources-and-permissions","title":"RBAC resources and permissions","text":"<p>Below is a comprehensive table outlining the permissions available for various resources:</p> Permissions for resources <p>Important</p> <p> Represents an action that\u2019s not supported by the Percona Everest API.</p> <p>Table: Permissions for the various resources in Percona Everest</p> Resource Read Create Update Delete namespaces You can view namespaces database-engines  (MySQL, MongoDB, PostgreSQL) You can view database engines when you create databases Note: This policy must at least be read all so the users can create databases. Modify database engines database-clusters You can view databases You can create databases You can modify databases You can delete databases database-cluster-backups You can view database cluster backups You can create database cluster backups You can delete database cluster backups database-cluster-restores You can view database cluster restores You can create database cluster restores You can modify database cluster restores You can delete database cluster restores backup-storages and monitoring-instances You can view backups and monitoring endpoints You can create backups and monitoring endpoints You can modify backups and monitoring endpoints You can delete backups and monitoring endpoints database-cluster-credentials View database data (credentials)  Note: If no policy is defined: * You cannot see the credentials and the connection string. * You also cannot create a database from any backup."},{"location":"administer/rbac.html#key-considerations-for-rbac","title":"Key considerations for RBAC","text":"<p>Before you start defining the different roles, there are some important things to consider when it comes to Role-Based Access Control (RBAC).</p> Namespaces DB clustersResourcesBackupsRestoresUpgrades <p>Read <code>namespaces</code> permissions are required for all the roles. </p> <p>To create, update and delete database clusters, backups, schedules, monitoring instances, and restores it is recommended to explicitly grant <code>read</code> permissions as well for the <code>database clusters</code>. Without these permissions, you would not be able to view these resources, which would not be practical.</p> <p>To create, update and delete the resources, it is recommended to explicitly grant <code>read</code> permissions for these resources as well. Without these permissions, you would not be able to view these resources, which would not be practical.</p> <p>Example: To manage <code>backup schedules</code> (create, update, delete a schedule), it is recommended to explicitly grant <code>read</code> permissions for the <code>backup schedules</code> as well as <code>backup storages</code>.</p> <p>For on-demand backups and schedules, you should grant <code>read</code> permissions for <code>backup storages</code> as well.</p> <p>For restores, to new and existing databases, you should grant the following permisssions as well:</p> <ul> <li>Read <code>backups</code> (of the old DB)</li> <li>Read <code>MonitoringConfig</code> (if the old DB has monitoring enabled)</li> <li>Read <code>database cluster credentials</code> (of the old DB)</li> <li>Create <code>backups</code> (if backup schedules are enabled)</li> </ul> <p>For upgrades, the following permissions must be granted:</p> <ul> <li>Read Namespaces</li> <li>Read all <code>database engines</code> in that namespace</li> <li>Read all <code>database clusters</code> in that namespace</li> <li>Update <code>database clusters</code> in that namespace</li> </ul>"},{"location":"administer/rbac.html#roles-in-rbac","title":"Roles in RBAC","text":"<p>In Role-Based Access Control (RBAC), a Role is a set of permissions that define what actions (like read, write, update, delete) can be performed on specific resources within Percona Everest. In RBAC, roles are assigned to users, allowing them to interact with the resources according to the permissions defined by their roles.</p> <p>Note</p> <p>It is recommended to prefix role names with role: to prevent confusion between role names and user names.</p>"},{"location":"administer/rbac.html#built-in-role","title":"Built-in role","text":"<p>In Percona Everest, the only predefined role is <code>role:admin</code>. A user with this role has unrestricted access to Percona Everest. However, the RBAC (Role-Based Access Control) configuration can define and allocate specific roles based on individual requirements and access privileges.</p> <p>This built-in <code>role:admin</code> definition is equivalent to the following:</p> <pre><code>p, role:admin, namespaces, *, *\np, role:admin, pod-scheduling-policies, *, *\np, role:admin, database-engines, *, */*\np, role:admin, database-clusters, *, */*\np, role:admin, database-cluster-backups, *, */*\np, role:admin, database-cluster-restores, *, */*\np, role:admin, database-cluster-credentials, *, */*\np, role:admin, backup-storages, *, */*\np, role:admin, monitoring-instances, *, */*\n</code></pre>"},{"location":"administer/rbac.html#rbac-examples","title":"RBAC examples","text":"<p>In this section, we will explore some examples that demonstrate how to create policy definitions for the required roles.</p> Examples <p>Let\u2019s dive into some role definitions for RBAC:</p> Namespace admin roleRead only roleDatabase admin role <p>Admin role for a single namepsace</p> <p>Let\u2019s set up an admin role with unrestricted privileges to all the resources in a single namespace called <code>namespaceA</code>.</p> <pre><code>p, role:namespaceAadmin, namespaces, *, namespaceA\np, role:namespaceAadmin, database-engines, *, namespaceA/*\np, role:namespaceAadmin, database-clusters, *, namespaceA/*\np, role:namespaceAadmin, database-cluster-backups, *, namespaceA/*\np, role:namespaceAadmin, database-cluster-restores, *, namespaceA/*\np, role:namespaceAadmin, database-cluster-credentials, *, namespaceA/*\np, role:namespaceAadmin, backup-storages, *, namespaceA/*\np, role:namespaceAadmin, monitoring-instances, *, namespaceA/*\n</code></pre> Let\u2019s dive into decoding this! <p>The <code>namespaceAadmin</code> role has the following privileges within the <code>namespaceA</code> namespace:</p> <ul> <li>namespace: <code>Read</code> access to the <code>namespaceA</code></li> <li>Database engines: <code>Read</code> and <code>update</code> access</li> <li>Database clusters: <code>All</code> access (read, create, update, delete)</li> <li>Database cluster backups: <code>All</code> access (read, create, delete) </li> <li>Database cluster rstores: <code>All</code> access (read, create, update, delete) </li> <li>Database clusters credentials: <code>Read</code> acccess</li> <li>Backup storages: <code>All</code> access (read, create, update, delete)</li> <li>Monitoring instances: <code>All</code> access (read, create, update, delete)</li> </ul> <p>1. Read only role without access to the database credentials</p> <p>Let\u2019s set up a read only role with access to all resources in all namespaces with the exception of database credentials:</p> <pre><code>p, role:readonly, namespaces, read, *\np, role:readonly, database-engines, read, */*\np, role:readonly, database-clusters, read, */*\np, role:readonly, database-cluster-backups, read, */*\np, role:readonly, database-cluster-restores, read, */*\np, role:readonly, backup-storages, read, */*\np, role:readonly, monitoring-instances, read, */*\n</code></pre> Let\u2019s dive into decoding this! <p>The <code>readonly</code>role has the following privileges in all the namespaces:</p> <ul> <li>namespace:  <code>Read</code> access to all the namespaces</li> <li>Database engines: <code>Read</code> access</li> <li>Database clusters: <code>Read</code> access</li> <li>Database cluster backups: <code>Read</code> access</li> <li>Database cluster restores: <code>Read</code> access</li> <li>Backup storages: <code>Read</code> access</li> <li>Monitoring instances: <code>Read</code> access</li> </ul> <p>2. Read only role with access to the database credentials</p> <p>Let\u2019s set up a read only role that has read-only access to all resources in all namespaces, including access to the database credentials.</p> <pre><code>p, role:readonlywithcreds, namespaces, read, *\np, role:readonlywithcreds, database-engines, read, */*\np, role:readonlywithcreds, database-clusters, read, */*\np, role:readonlywithcreds, database-cluster-backups, read, */*\np, role:readonlywithcreds, database-cluster-restores, read, */*\np, role:readonlywithcreds, backup-storages, read, */*\np, role:readonlywithcreds, monitoring-instances, read, */*\np, role:readonlywithcreds, database-cluster-credentials, read, */*\n</code></pre> Let\u2019s dive into decoding this! <p>The <code>readonlywithcreds</code> role has the following privileges in all the namespaces:</p> <ul> <li>namespace: <code>Read</code> access to all the namespaces</li> <li>Database engines: <code>Read</code> access</li> <li>Database clusters: <code>Read</code> access</li> <li>Database cluster backups: <code>Read</code> access</li> <li>Database cluster restores: <code>Read</code> access</li> <li>Backup storages: <code>Read</code> access</li> <li>Monitoring instances: <code>Read</code> access</li> <li>Database clusters credentials: <code>Read</code> acccess</li> </ul> <p>1. Database admin role with read access to certain resources</p> <p>Let\u2019s set up a role that has read only access to the <code>database-engines</code>, <code>backup-storages</code> and <code>monitoring-instances</code>. This means that users assigned to this role can manage the databases without restriction but cannot manage the database Kubernetes operators\u2019 versions. They also cannot create, update, or delete <code>backup-storages</code> and <code>monitoring-instances</code>.</p> <pre><code>p, role:dbadmin, namespaces, *, *\np, role:dbadmin, database-engines, read, */*\np, role:dbadmin, database-clusters, *, */*\np, role:dbadmin, database-cluster-backups, *, */*\np, role:dbadmin, database-cluster-restores, *, */*\np, role:dbadmin, database-cluster-credentials, *, */*\np, role:dbadmin, backup-storages, read, */*\np, role:dbadmin, monitoring-instances, read, */*\n</code></pre> Let\u2019s dive into decoding this! <p>The <code>dbadmin</code> role has the following privileges in all the namespaces:</p> <ul> <li>namespace: <code>Read</code> access in all the namespaces.</li> <li>Database engines: <code>Read</code> access to all the database engines</li> <li>Database clusters: <code>All</code> access (read, create, update, delete)</li> <li>Database cluster backups: <code>All</code> access (read, create, delete)</li> <li>Database cluster restores: <code>All</code> access (read, create, update, delete)</li> <li>Database clusters credentials: <code>Read</code> acccess for all the databases       </li> <li>Backup storages: <code>Read</code> access to all the backup storages</li> <li>Monitoring instances: <code>Read</code> access to all the monitoring instances</li> </ul> <p>2. Database admin role for a single database</p> <p>Let\u2019s set up a role that has access to only a single database called <code>databaseA</code>:</p> <pre><code>p, role:dbadminDatabaseA, namespaces, *, namespaceA\np, role:dbadminDatabaseA, database-engines, read, namespaceA/*\np, role:dbadminDatabaseA, database-clusters, *, namespaceA/databaseA\np, role:dbadminDatabaseA, database-cluster-backups, *, namespaceA/databaseA\np, role:dbadminDatabaseA, database-cluster-restores, *, namespaceA/databaseA\np, role:dbadminDatabaseA, database-cluster-credentials, *, namespaceA/databaseA\np, role:dbadminDatabaseA, backup-storages, read, namespaceA/*\np, role:dbadminDatabaseA, monitoring-instances, read, namespaceA/*\n</code></pre> Let\u2019s dive into decoding this! <p>This role has the following privileges:</p> <ul> <li>namespace: <code>Read</code> access in the namespace <code>namespaceA</code>.</li> <li>Database engines: <code>Read</code> access in the namespace <code>namespaceA</code></li> <li>Database clusters: <code>All</code> access (read, create, update, delete) in namespace <code>namespaceA</code> only for database <code>databaseA</code></li> <li>Database cluster backups: <code>All</code> access (read, create, delete) in the namespace <code>namespaceA</code></li> <li>Database cluster restores: <code>All</code> access (read, create, update, delete) in the namespace <code>namespaceA</code></li> <li>Database clusters credentials: <code>Read</code> acccess for all the databases       </li> <li>Backup storages: <code>Read</code> access to all the backup storagesin the namespace <code>namespaceA</code></li> <li>Monitoring instances: <code>Read</code> access to all the monitoring instances in the namespace <code>namespaceA</code></li> </ul>"},{"location":"administer/rbac.html#more-insights-into-backups-and-restore-policies","title":"More insights into backups and restore policies","text":"<p>Let\u2019s dive into different backup and restore policies for Percona Everest.</p>"},{"location":"administer/rbac.html#read-only-role-for-a-single-namespace","title":"Read only role for a single namespace","text":"<p>Let\u2019s start with a read only role for a single namespace:</p> <pre><code>p, role:exampleA, namespaces, read, namespaceA\np, role:exampleA, database-engines, read, namespaceA/*\np, role:exampleA, database-clusters, read, namespaceA/*\np, role:exampleA, database-cluster-backups, read, namespaceA/*\np, role:exampleA, database-cluster-restores, read, namespaceA/*\np, role:exampleA, backup-storages, read, namespaceA/*\np, role:exampleA, monitoring-instances, read, namespaceA/*\n</code></pre>"},{"location":"administer/rbac.html#permissions-to-create-on-demand-backups","title":"Permissions to create on-demand backups","text":"<p>In the policy mentioned above, just add permissions to create on-demand backups.</p> <p><code>p, role:exampleA, database-cluster-backups, create, namespaceA/*</code></p>"},{"location":"administer/rbac.html#permissions-to-manage-backup-schedules","title":"Permissions to manage backup schedules","text":"<p>In the policy mentioned above, just add permissions to manage backup schedules.Backup schedules are part of the database cluster spec, so we require update permissions for the database clusters:</p> <pre><code>p, role:exampleA, database-cluster-backups, create, namespaceA/*\np, role:exampleA, database-clusters, update, namespaceA/*\n</code></pre>"},{"location":"administer/rbac.html#permissions-to-restore-a-backup-to-an-existing-database","title":"Permissions to restore a backup to an existing database","text":"<p>In the policy mentioned above, just add permissions to restore a backup to an existing database:</p> <pre><code>p, role:exampleA, database-cluster-restores, create, namespaceA/*\np, role:exampleA, database-cluster-credentials, read, namespaceA/*\n</code></pre> <p>Note</p> <p>You cannot restore the backup to an existing database without having read permissions to the database cluster credentials.</p>"},{"location":"administer/rbac.html#permissions-to-restore-a-backup-to-a-new-database","title":"Permissions to restore a backup to a new database","text":"<p>In the policy mentioned above, just add permissions to restore a backup to a new database:</p> <pre><code>p, role:exampleA, database-cluster-restores, create, namespaceA/*\np, role:exampleA, database-cluster-credentials, read, namespaceA/*\np, role:exampleA, database-clusters, create, namespaceA/*\n</code></pre>"},{"location":"administer/rbac.html#assigning-roles-to-users","title":"Assigning roles to users","text":"<p>In order for roles to take effect, they need to be assigned to users. The syntax for this is as follows:</p> <pre><code>g, username, rolename\n</code></pre> <p>A new user in Percona Everest will initially have no permissions. To grant permissions, you must edit your RBAC configuration stored in the <code>everest-rbac</code> <code>ConfigMap</code> in the <code>everest-system</code> namespace:</p> <pre><code>kubectl edit cm everest-rbac -n everest-system\n</code></pre> <p>A text editor will open, and you can edit the <code>ConfigMap</code> as follows. You just have to add the new user and assign it the desired role.</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: everest-rbac\ndata:\n  policy.csv: |\n    g, admin, role:admin\n    g, &lt;newuser&gt;, role:admin\n</code></pre> Example <p>Let\u2019s assign the role <code>team-dev</code> to a new user named <code>john</code>:</p> <pre><code>p, role:team-dev, namespaces, read, dev\np, role:team-dev, database-engines, read, dev/*\np, role:team-dev, database-clusters, read, dev/*\np, role:team-dev, database-clusters, update, dev/*\np, role:team-dev, database-clusters, create, dev/*\np, role:team-dev, database-clusters, delete, dev/*\np, role:team-dev, database-cluster-credentials, read, dev/*\ng, john, role:team-dev\n</code></pre> <p>The <code>team-dev</code> role has the following privileges only within the <code>dev</code> namespace:</p> <ul> <li>namespace:  <code>Read</code> access to <code>dev</code></li> <li>Database engines: <code>Read</code> access</li> <li>Database clusters: <code>Read</code> access</li> <li>Database clusters: <code>Update</code> access</li> <li>Database clusters: <code>Create</code> access</li> <li>Database clusters: <code>Delete</code> access</li> <li>Database cluster credentials: <code>Read</code> access</li> </ul>"},{"location":"administer/rbac.html#validate-your-rbac-policy","title":"Validate your RBAC policy","text":"<p>You can verify whether your Role-based access control (RBAC) policies are functioning correctly by executing the following command:</p> <pre><code>everestctl settings rbac validate --policy-file &lt;file_path&gt;\n</code></pre> <p>Where:</p> <p><code>policy-file</code> is an optional flag that takes the policy file path. If you do not specify the path to this file, it will look for the configuration file inside your existing Percona Everest installation, that is, under RBAC <code>ConfigMap</code>.</p> Policy validation <p>The following example demonstrates that this is a valid policy.</p> <p><pre><code>everestctl settings rbac validate --policy-file ./pkg/rbac/testdata/policy-1-good.csv\n</code></pre> Output:</p> <pre><code>\u2713 Valid\n</code></pre> <p>The following example demonstrates that this is an invalid policy.</p> <pre><code>everestctl settings rbac validate --policy-file ./pkg/rbac/testdata/policy-bad.csv\n</code></pre> <p>output:</p> <pre><code>\u00d7 Invalid\npolicy syntax error - unknown resource name 'non-existent-resource'\n</code></pre> <p>You can also use the same command with the YAML file path containing the everest-rbac ConfigMap. For example:</p> <pre><code>everestctl settings rbac validate --policy-file ./rbac-config.yaml\n</code></pre>"},{"location":"administer/rbac.html#test-your-rbac-policy","title":"Test your RBAC policy","text":"<p>You can verify if a role or individual (such as a group or a local user) has the necessary privileges to perform particular operations on designated resources. </p> <p>We have a straightforward command that can be used to test the RBAC (Role-Based Access Control) policies:</p> <pre><code>everestctl settings rbac can --policy-file &lt;file_path&gt;\n</code></pre> <p>Where:</p> <p><code>policy-file</code> is an optional flag that takes the policy file path. If you do not specify the path to this file, it will look for the configuration file inside your existing Percona Everest installation, that is, under RBAC <code>ConfigMap</code>.</p> Test your policy <p>The following example tests whether a user, Alice, can create database clusters:</p> <p><pre><code>everestctl settings rbac can alice create database-clusters '*' --policy-file ./pkg/rbac/testdata/policy-1-bad.csv\n</code></pre> Output</p> <pre><code>No\n</code></pre> <p>The following example tests whether an Admin user can create database clusters:</p> <pre><code>everestctl settings rbac can admin create database-clusters '*' --policy-file ./pkg/rbac/testdata/policy-1-good.csv\n</code></pre> <p>Output:</p> <pre><code>Yes\n</code></pre>"},{"location":"administer/rbac.html#breaking-api-changes-for-rbac","title":"Breaking API changes for RBAC","text":"<p>Starting from Percona Everest v1.2.0, breaking changes are being implemented to the API for <code>monitoring-instances</code> and <code>backup-storages</code>resources. Explore further by checking out the section on Breaking API changes for a deep dive into this topic.</p>"},{"location":"administer/rbac_pod_scheduling.html","title":"Pod scheduling policies with RBAC","text":"<p>As an admin in Percona Everest, you can restrict access to configuring or applying specific Pod scheduling policies for certain users. To achieve this, you can define access policies usingPercona Everest\u2019s Role-Based Access Control (RBAC) functionality.</p> <p>RBAC policies in Percona Everest apply to the entire Pod scheduling policy, including all the affinity rules defined within it. </p> <p>Note</p> <p>Assigning RBAC permissions to individual affinity rules within a policy is impossible\u2014access is managed at the policy level as a whole.</p>"},{"location":"administer/rbac_pod_scheduling.html#use-cases-for-pod-scheduling-policies-with-rbac","title":"Use cases for Pod Scheduling policies with RBAC","text":""},{"location":"administer/rbac_pod_scheduling.html#limited-access-to-pod-scheduling-policy-configuration","title":"Limited access to Pod scheduling policy configuration","text":"<p>As a Percona Everest Admin, you can allow only specific users to manage Pod Scheduling Policies (create, edit, read, and delete) while restricting other users to read-only access. These users can view and apply the existing policies to database clusters but cannot modify or delete them.</p> Example <p>Here\u2019s an example of RBAC policy displaying how to grant full access to one user (e.g., alice) and read-only access to others:</p> <pre><code>p, alice, pod-scheduling-policies, *, *\np, role:team-dev, pod-scheduling-policies, read, *\n</code></pre>"},{"location":"administer/rbac_pod_scheduling.html#limited-usage-of-pod-scheduling-policy-by-users","title":"Limited usage of Pod scheduling policy by users","text":"<p>As a Percona Everest Admin, you can allow a particular user to use a specific Pod scheduling policy. The rest of the users are not allowed to use this policy at all (that is, they cannot see it in the system and cannot assign it to DB clusters that they create or modify).</p> Example <p>Here\u2019s an example of RBAC policy that grants limited access to just one user (e.g., bob):</p> <pre><code>p, bob, pod-scheduling-policies, read, pod-scheduling-policy-1\n</code></pre>"},{"location":"administer/use_cases.html","title":"Use cases for Pod scheduling policies","text":"<p>Here are several detailed use cases for affinity that highlight its diverse applications and the numerous benefits it offers across various contexts.</p>"},{"location":"administer/use_cases.html#node-affinity-regional-scheduling","title":"Node affinity: Regional scheduling","text":"<p>Let\u2019s consider a use case in which workloads are distributed based on performance requirements, fault tolerance, and regional specifications across designated zones or areas.</p> <p>You need to run a workload in the <code>us-west2 region</code> for latency optimization and to meet specific compliance requirements.</p> <p></p> What happens under the hood <ul> <li>It ensures that the pod is scheduled only on nodes in the us-west-2 region, as defined by the <code>topology.kubernetes.io/region</code> node label.</li> <li>For the rule to be applicable, it is essential that the node possesses a label such as <code>topology.kubernetes.io/region: us-west-2</code>. If no nodes correspond to the specified label, the pod will remain unscheduled.</li> </ul>"},{"location":"administer/use_cases.html#pod-anti-affinity-pods-scheduled-apart","title":"Pod anti-affinity: Pods scheduled apart","text":"<p>Let\u2019s consider a use case that ensures the scheduler distributes the different database pods across various Kubernetes nodes, which enhances fault tolerance in the event of node failure.</p> <p></p> What happens under the hood <ul> <li>The pod will not be scheduled on nodes that contain pods labeled with <code>app=haproxy</code>.</li> <li>If no nodes match, the pod will not be scheduled until a suitable node becomes available.</li> </ul>"},{"location":"administer/use_cases.html#pod-affinity-pods-scheduled-on-the-same-node","title":"Pod affinity: Pods scheduled on the same node","text":"<p>Let\u2019s consider a use case that ensures that the scheduler distributes the different database pods on the same Kubernetes node.</p> <p></p> What happens under the hood <p>The scheduler will prefer to place this pod on a node where other pods with the label <code>app=backend</code> are already running.</p>"},{"location":"backups_and_restore/AboutBackups.html","title":"About backups","text":""},{"location":"backups_and_restore/AboutBackups.html#why-its-important-to-create-backups","title":"Why it\u2019s important to create backups","text":"<p>Databases (DBs) may get damaged due to a variety of reasons, including disk crashes, power outages, software errors, or even virus attacks.  </p> <p>To ensure that you can recover data in such events, it is critical to back up your databases. With Everest, you can do this with zero downtime and minimal performance impact.</p>"},{"location":"backups_and_restore/AboutBackups.html#supported-setups","title":"Supported setups","text":"<p>Everest enables you to create and restore on-demand, scheduled and Point-in-Time-Recovery (PITR) backups.</p>"},{"location":"backups_and_restore/AboutBackups.html#start-here","title":"Start here","text":"<p>Prepare a backup storage location </p>"},{"location":"backups_and_restore/RestoreBackup.html","title":"Restore the database from a previously saved backup","text":"<p>Database backups and data replication are complementary components of an effective disaster recovery strategy.</p> <p>Everest enables you to use backups to either create a new database or restore the backup data to the original database. Choosing between these two options often depends on the specific scenario, the urgency of recovery, the impact on ongoing operations, the need for data isolation, and the purpose of the restoration (such as testing, recovery from corruption, or analysis).</p>"},{"location":"backups_and_restore/RestoreBackup.html#restore-database-from-backup","title":"Restore database from backup","text":"<p>Restoring to the same cluster is useful in the following scenarios:</p> <ul> <li>For faster recovery: It\u2019s typically quicker to restore data to an existing database as it eliminates the need for creating a new database deployment.</li> <li>Database consistency: Maintains the same database ID, configurations, and dependencies, ensuring consistency within the existing environment.</li> </ul> <p>To restore a database from a backup:</p> <ol> <li>In the  Databases view, select the database you want to restore.</li> <li>Click the  Actions menu next to the backup you want to restore from, then click Restore from a backup.</li> <li> <p>In the Restore database pop-up, select  From a backup.</p> <p></p> </li> <li> <p>Click Restore.</p> </li> </ol>"},{"location":"backups_and_restore/RestoreBackup.html#post-restore-step-for-mongodb","title":"Post-Restore step for MongoDB","text":"<p>PITR restores alter the timeline of MongoDB oplog events. As a result, MongoDB oplog slices created after the restore timestamp and before the last backup become invalid.</p> <p>To seamlessly resume PITR after a restore, make sure to run a new full backup. This new backup will serve as the starting point for oplog updates, ensuring the continuity and integrity of your data.</p>"},{"location":"backups_and_restore/RestoreBackup.html#restore-to-a-point-in-time-recovery","title":"Restore to a point-in-time recovery","text":"<p>Warning</p> <p>For PostgreSQL, point-in-time recovery (PITR) can get stuck in a Restoring state when you attempt to recover the database after the last transaction. See the Limitation for PostgreSQL section for a workaround.</p> <p>To restore to a point-in-time recovery:</p> <ol> <li>In the  Databases view, select the database you want to replicate.</li> <li>Click the  Actions menu next to the backup you want to replicate from, then click Restore from a backup. The Restore database dialogue box opens.</li> <li> <p>In the Restore database pop-up, select From a Point-in-time (PITR). Click on the calendar icon, choose the specific time to which you would like to restore the database.</p> <p></p> </li> <li> <p>Click Restore.</p> </li> </ol>"},{"location":"backups_and_restore/backup_importers_rbac.html","title":"RBAC for external backup imports in Percona Everest","text":"<p>When importing external backups into Percona Everest, it is essential to consider Role-Based Access Control(RBAC) permissions. This ensures only authorized users have the required permissions to access and manage the data.</p>"},{"location":"backups_and_restore/backup_importers_rbac.html#required-roles-and-permissions","title":"Required roles and permissions","text":"<p>The following RBAC permissions are supported for <code>DataImporters</code> and <code>DataImportJobs</code>:</p> <p>Important</p> <p> Represents an action that\u2019s not supported by the Percona Everest API.</p> Resource Read Create Update Delete <code>data-importers</code> [name] <code>data-import-jobs</code> [namespace]/[db name]"},{"location":"backups_and_restore/backup_importers_rbac.html#example-rbac-policy-for-importing-a-mysql-backup","title":"Example: RBAC policy for importing a MySQL backup","text":"<p>To import a MySQL backup using a <code>DataImporter</code>, a user with the <code>dbadmin</code> role needs the following permissions within the <code>a2</code> namespace :</p> <pre><code>p, role:dbadmin, namespaces, read, *\np, role:dbadmin, database-engines, read, a2/*\np, role:dbadmin, database-clusters, *, a2/*\np, role:dbadmin, backup-storages, read, a2/*\np, role:dbadmin, database-cluster-backups, *, a2/*\np, role:dbadmin, monitoring-instances, read, a2/*\np, role:dbadmin, data-importers, read, everest-percona-pxc-operator\np, role:dbadmin, data-import-jobs, read, a2/*\n</code></pre> Let\u2019s dive into decoding this! Resource Action Description <code>namespaces</code> read You can view all namespaces in the cluster. <code>database-engines</code> read You can view the available database engine types within the <code>a2</code> namespace. <code>database-clusters</code> * Full access to manage database clusters in the <code>a2</code> namespace. <code>backup-storages</code> read You can view configured external storage targets (e.g., S3, GCS). <code>database-cluster-backups</code> * Grants complete control over database backups. You can create new backups, restore from existing ones, and delete them as needed. <code>monitoring-instances</code> read You can view monitoring configuration for clusters <code>data-importers</code> read You can view and use a specific <code>DataImporter</code> (in this case, everest-percona-pxc-operator) during the backup import workflow. Without this, the importer will not appear in the UI or CLI. <code>data-import-jobs</code> read You can monitor the status of import jobs triggered via the <code>DataImporter</code>. <p>Note</p> <p>For MongoDB and PostgreSQL, the importer names will be\u00a0<code>everest-percona-psmdb-operator</code>\u00a0and\u00a0<code>everest-percona-pg-operator</code>, respectively.</p>"},{"location":"backups_and_restore/createBackups/CreateOnDemand.html","title":"On-demand and scheduled backups","text":"<p>Initiate an immediate backup for hands-on control, or schedule one if you prefer the automated reliability of scheduled backups.</p>"},{"location":"backups_and_restore/createBackups/CreateOnDemand.html#create-on-demand-backups","title":"Create on-demand backups","text":"<p>On-demand backups give you immediate control over when and what data to back up. One-time backups can be particularly useful when you need to safeguard critical information before making significant changes to your database.</p> <p>Important</p> <p>There are few limitations to consider when working with PostgreSQL\u2019s on-demand backups. For detailed information, refer to the limitations section.</p> <p>To create a backup now:</p> <ol> <li>Go to  Settings &gt; Backup Storages and check that you have an available S3-compatible location for storing backups. Otherwise, create a backup location so Everest can store backup artifacts for the database.</li> <li>Go to the  Databases view and select the database which you want to back up.</li> <li>Navigate to the Backups tab and click Create backup &gt; Now.</li> <li>In the Create Backup pop-up, change the default backup name if required, select an available backup location, and then click Create.</li> </ol>"},{"location":"backups_and_restore/createBackups/CreateOnDemand.html#schedule-a-backup","title":"Schedule a backup","text":"<p>Schedule a backup when you want your backups to occur automatically at predetermined intervals. This automation reduces the risk of human error and ensures that your data is consistently backed up without requiring your constant intervention.</p> <p>Important</p> <p>There are few limitations to consider when working with PostgreSQL\u2019s scheduled backups. For detailed information, refer to the limitations section.</p> <p>To configure a backup schedule:</p> <ol> <li>Go to  Settings &gt; Backup Storages and check that you have an available AWS S3-compatible location for storing backups. Otherwise, create a backup location so Everest can store backup artifacts for the database.</li> <li>Go to the  Databases view and select the database which you want to back up.</li> <li>Navigate to the Backups tab and click Create backup &gt; Schedule.</li> <li> <p>Change the default backup name if required, and configure the frequency and start time for the backups.</p> <p>Important</p> <p>Make sure that the schedule you specify here does not create overlapping jobs or overhead on the production environment. Also, check that your specified schedule does not overlap with production hours.</p> </li> <li> <p>Click Create. All scheduled backups for the current DB will be listed at the top so you can review the schedules that are currently generating backup artifacts.</p> </li> </ol>"},{"location":"backups_and_restore/createBackups/CreateOnDemand.html#edit-a-scheduled-backup","title":"Edit a scheduled backup","text":"<p>To edit a schedule that is currently generating backup artifacts:</p> <ol> <li>Go to the  Databases view and select the DB for which backups have been scheduled.  </li> <li>Select the Backups tab and expand the Schedule box.</li> <li>Select the schedule you want to update, click the ellipsis  and select Edit.</li> <li>Update the schedule and click Save.</li> </ol>"},{"location":"backups_and_restore/createBackups/CreateOnDemand.html#next-step","title":"Next step","text":"<p>Enable PITR  Restore backups </p>"},{"location":"backups_and_restore/createBackups/EnablePITR.html","title":"Point-in-time recovery (PITR) backups","text":"<p>PITR maintains versions of your database from past timestamps, serving as a safeguard against data loss during various disasters, including database crashes, accidental data deletions, table drops, or unintended updates to multiple fields instead of a single one.</p> <p>PITR complements on-demand and scheduled backup strategies by providing finer backup granularity with more specific recovery points for restoring data to the same cluster.</p>"},{"location":"backups_and_restore/createBackups/EnablePITR.html#how-it-works","title":"How it works","text":"<p>Restoring databases up to a specific moment in time involves retrieving data from a backup snapshot and replaying all subsequent events that occurred until a specified moment using log slices.</p> <p>When PITR and backups are enabled (either on-demand or scheduled), Percona Everest starts capturing successive database logs at predefined intervals. As soon as the initial full backup is available, Everest can start restoring the database from these PITR logs.</p> <p>Since Everest saves logs and streams them into your storage between scheduled task runs, scheduling frequent backups is not necessary. You can use the available logs in your storage to restore a backup to any moment between snapshots.</p>"},{"location":"backups_and_restore/createBackups/EnablePITR.html#pitr-upload-intervals","title":"PITR upload intervals","text":"<p>By default, Everest uploads PITR logs every minute for MySQL databases and every ten minutes for MongoDB databases. If you wish to adjust these default intervals, you can easily do so through the Everest API.</p>"},{"location":"backups_and_restore/createBackups/EnablePITR.html#enable-point-in-time-recovery","title":"Enable Point-in-time recovery","text":""},{"location":"backups_and_restore/createBackups/EnablePITR.html#prerequisites","title":"Prerequisites","text":"<p>Before enabling PITR, go to  Settings &gt; Backup Storages and check that you have an available S3-compatible location for storing backups. Otherwise, create a backup location so Everest can store PITR artifacts for the database.</p> <p>To enable PITR:</p> When creating a new databaseWhen editing an existing database <ol> <li>On the Everest homepage, click Create database to display the database creation wizard.</li> <li>Fill in the details of your database on the first steps of the wizard.</li> <li>Navigate to the Backups page, and make sure to enable and configure a backup schedule. </li> <li>Click Next to go to the Point-in-time recovery (PITR) page where you can enable PITR and specify a location for storing the PITR backups and logs. </li> <li>Complete the setup wizard to create the new database with PITR enabled. </li> </ol> <ol> <li>On the  Databases view page, select the database for which you want to enable PITR. The Overview tab will be displayed.</li> <li>Navigate to Backups &amp; PITR &gt; Point-in-time Recovery (PITR) widget.</li> <li>Click Edit. The Edit PITR pop-up will be displayed.</li> <li>Toggle the switch on or off based on whether you want to enable or disable PITR. Click Save.</li> </ol>"},{"location":"backups_and_restore/createBackups/EnablePITR.html#limitations","title":"Limitations","text":"<p>There are some limitations associated with the PITR functionality. For a comprehensive list of known limitations, see the known Limitations section.</p>"},{"location":"backups_and_restore/createBackups/EnablePITR.html#next-step","title":"Next step","text":"<p>Restore backups </p>"},{"location":"backups_and_restore/createBackups/create_new_database.html","title":"Create new database from backup or PITR","text":"<p>To create a new database, you can restore from a previously taken backup or perform a point-in-time recovery.</p>"},{"location":"backups_and_restore/createBackups/create_new_database.html#create-a-new-database-from-backup","title":"Create a new database from backup","text":"<p>When you need to recreate a database from a known state, such as when recovering from data loss or corruption, or when setting up a new environment, this method is useful.</p> <p>There are specific situations that require the creation of a new database from a backup:</p> <ul> <li> <p>When the original database is compromised: Restoring a backup directly to a compromised DB could reintroduce the same issues. Creating a new database from the backup ensures that the restored data is isolated from the original database, preserving data integrity.</p> </li> <li> <p>When you want to debug a problem: In a disaster recovery situation, it\u2019s essential to understand the root problem that led to the need for recovery. Creating a new database allows you to examine the original database for vulnerabilities or issues before restoring the data. This can help identify weaknesses that need to be addressed.</p> </li> <li> <p>When you want to validate backup data before restore: By creating a new database, you can test the integrity and consistency of the backup data before making it the primary production data. This validation process ensures that the backup is clean and free from corruption, reducing the risk of propagating issues from the backup to the new database.</p> </li> <li> <p>Before upgrading or patching: In some cases, a disaster recovery event might coincide with the need to upgrade or patch the database software. Creating a new database allows you to apply the necessary upgrades or patches to the new environment, ensuring that the production environment is up-to-date and secure.</p> </li> <li> <p>To create a safety net for rollbacks: Restoring the backup directly to the original database leaves little room for rolling back the recovery process if issues are discovered later. Creating a new database provides a safety net, as you can decide whether to promote the new database to the production environment or keep the original one if necessary.</p> </li> </ul> <p>To create a new database from backup:</p> <ol> <li>In the  Databases view, select the database you want to replicate.</li> <li> <p>Click on the  menu next to the database you want to replicate from, then click Create DB from a backup. The Create database dialogue box opens.</p> <p></p> </li> <li> <p>On the Create database pop-up, select From a backup.</p> </li> <li> <p>From the dropdown list, select the backup that you want to use for creating a database.</p> <p></p> </li> <li> <p>Click Create.</p> </li> <li> <p>On the Basic information page, change the default backup name if required, then select one of the classes created by your Kubernetes administrator. Storage classes define what storage configuration and features will be used for storing your database data. Different classes map to different quality-of-service levels, backup policies, persistent volumes, or to arbitrary policies determined by your cluster administrator. For more information, see Storage Classes in the Kubernetes documentation. </p> </li> <li>On the Resources page, select the number of nodes and set the resources. For more information see, Provision a database.</li> <li>(Optional) Enable scheduled backups on the Scheduled Backups page. Provide a name, select a schedule interval, and choose a backup storage from the dropdown.</li> <li> <p>On the Point-in-time Recovery (PITR) page, you may enable PITR with the toggle, provided you have previously enabled scheduled backups. Select the Backup storage from the dropdown.</p> </li> <li> <p>On the Advanced Configurations page, enable external access and database engine parameters by turning the toggle button on. For more information on configuring specific database parameters, see the MySQL, MongoDB, and PostgreSQL configuration documentation.</p> </li> <li> <p>If you\u2019ve added a monitoring endpoint, this option will show as active on the Monitoring page, and you can turn it off if required.</p> </li> <li>Click Create database.</li> </ol>"},{"location":"backups_and_restore/createBackups/create_new_database.html#create-a-new-database-from-pitr","title":"Create a new database from PITR","text":"<p>Warning</p> <p>For PostgreSQL, point-in-time recovery (PITR) can get stuck in a Restoring state when you attempt to recover the database after the last transaction. See the Limitation for PostgreSQL section for a workaround.</p> <p>This approach can prove advantageous when you need to revert the database to a particular state, such as reversing unintended modifications to data or restoring from a system breakdown while minimizing data loss.</p> <p>To create a new database from PITR:</p> <ol> <li> <p>In the  Databases view, select the database you want to replicate.</p> </li> <li> <p>Click on the  menu next to the database you want to replicate from, then click Create DB from a backup. The Create database dialogue box opens.</p> </li> <li> <p>On the Create database pop-up, select the option From a Point-in-time (PITR). Click on the calendar icon and choose the specific time for which you would like to create the database.</p> <p></p> </li> <li> <p>Follow the steps 4 to 12 from the Create a new database from backup section.</p> </li> </ol>"},{"location":"backups_and_restore/createBackups/backup_storage/CreateStorage.html","title":"Create backup storage","text":"<p>Before working with backups, create a backup storage location as a backup destination for creating and storing your backup artifacts.  </p> <p>Everest supports S3-compatible backup locations, which means you can use AWS S3 or any other storage solutions that support S3 API, like min.io.</p> <p>Important</p> <ul> <li> <p>Currently, Everest does not support S3 buckets with S3 Object Lock. Make sure your backup destination you are registering does not have S3 Object Lock enabled.</p> </li> <li> <p>Make sure you have read/write/delete permissions to the S3 bucket.</p> </li> </ul> <p>To create a backup storage location:</p> <ol> <li> <p>Go to Backup storage settings:</p> <p>Navigate to Percona Everest home page and select  Settings &gt; Backup storages. Then click Add Backup storage.</p> </li> <li> <p>Fill in the Required Fields:</p> <ul> <li>Name: Enter a name using only lowercase letters, numbers, or hyphens.</li> <li>Description: (Optional) Add a short description for this backup storage.</li> <li>Namespace: Select where this backup storage will be available.</li> <li>Type: Choose S3 Compatible.</li> <li>Bucket Name: Provide the S3 bucket name where backups will be stored.</li> <li>Region: Specify the bucket\u2019s region (e.g., us-east-1).</li> <li>Endpoint: Enter the S3-compatible URL (e.g., https://s3.us-east-1.amazonaws.com).</li> <li>Access Key: Input the access key for your S3 account.</li> <li>Secret Key: Input the corresponding secret key.</li> </ul> </li> <li> <p>Additional Options:</p> <ul> <li>Verify TLS Certificate: Enable this to validate secure connections.</li> <li>Force Path-Style URL Access: Use this if your storage provider uses path-style URLs.</li> </ul> </li> <li> <p>Click Add to save your configuration.</p> </li> </ol>"},{"location":"backups_and_restore/createBackups/backup_storage/CreateStorage.html#next-steps","title":"Next steps","text":"<p>Create backups  Enable PITR </p>"},{"location":"backups_and_restore/createBackups/backup_storage/EditStorage.html","title":"Manage backup storage","text":"<p>Managing backup storage allows you to edit or remove existing S3 storage configurations used for database backups, helping you keep your backup environment organized, secure, and up-to-date.</p>"},{"location":"backups_and_restore/createBackups/backup_storage/EditStorage.html#edit-backup-storage","title":"Edit backup storage","text":"<p>To edit a backup storage configuration:</p> <ol> <li> <p>Go to Backup storage settings:</p> <p>Navigate to Percona Everest home page and select  Settings &gt; Backup storages. Then click on the ellipsis (three dots) next to the storage you want to modify.</p> </li> <li> <p>Click Edit. The Edit Backup storage pop-up will open.</p> <p></p> </li> <li> <p>Make your changes and click Edit to save your configuration.</p> </li> </ol>"},{"location":"backups_and_restore/createBackups/backup_storage/EditStorage.html#delete-backup-storage","title":"Delete backup storage","text":"<p>To delete a backup storage:</p> <ol> <li> <p>Go to Backup storage settings:</p> <p>Navigate to Percona Everest home page and select  Settings &gt; Backup storages. Then click on the ellipsis (three dots) next to the storage you want to delete.</p> </li> <li> <p>Click Delete. The Delete storage confirmation pop-up will open.</p> </li> <li> <p>Click Delete. The backup storage will be deleted.</p> </li> </ol>"},{"location":"backups_and_restore/dataimporters/overview.html","title":"Import external database backups into Percona Everest","text":"<p>Important</p> <p>The external backup import feature in Percona Everest is currently in Technical Preview. Early adopters are advised to use this feature only for testing purposes and not in production environments.</p> <p>This new feature in Percona Everest enables you to import database backups stored in external object storage into clusters managed by Percona Everest using an extensible design.</p>"},{"location":"backups_and_restore/dataimporters/overview.html#objectives","title":"Objectives","text":"<p>This feature can help you achieve the following objectives:</p> <ul> <li> <p>Allow you to import backup data stored in external storage like Amazon S3 into database cluster managed by Percona Everest.</p> </li> <li> <p>Allow you to customize the import process using your preferred tools, such as <code>mongodump</code>, <code>pg_dump</code>, or <code>mysqldump</code>.</p> </li> <li> <p>Provide a pluggable and extensible framework that can adapt to different import needs and workflows.</p> </li> </ul>"},{"location":"backups_and_restore/dataimporters/overview.html#dataimporters","title":"DataImporters","text":""},{"location":"backups_and_restore/dataimporters/overview.html#what-are-dataimporters","title":"What are DataImporters?","text":"<p>Important</p> <p>Percona Everest includes three pre-installed DataImporters (<code>everest-percona-pg-operator,</code> <code>everest-percona-pxc-operator</code>, and <code>everest-percona-psmdb-operator</code>), designed to restore external backups created using Percona operators.</p> <p>A DataImporter is a cluster-scoped CRD (Custom Resource Definition). It represents a self-contained, reusable blueprint for importing data into a newly created database cluster managed by Percona Everest. It defines:</p> <ul> <li>The container to be run for your data restore logic.</li> <li>The database engines it supports.</li> <li>The input configurations it requires (e.g., S3 path, credentials, and custom inputs).</li> <li>Any constraints that your database cluster must meet, such as engine version requirements.</li> </ul>"},{"location":"backups_and_restore/dataimporters/overview.html#what-is-a-dataimport-job","title":"What is a DataImport job?","text":"<p><code>DataImportJob</code> is a namespace-scoped CRD that represents a single execution of a DataImporter. Percona Everest automatically creates it when a user initiates a backup import using a specified <code>DataImporter</code>. Internally, it runs a Kubernetes Job that runs the specified import logic on a newly created <code>DatabaseCluster</code>, using the credentials and configuration provided by the user (e.g., S3 bucket, file path, access keys).</p>"},{"location":"backups_and_restore/dataimporters/overview.html#why-use-dataimporters","title":"Why use DataImporters?","text":"<p>Organizations use different backup/restore tools, such as <code>pg_dump</code>, <code>mysqldump</code>, <code>mongodump</code>, physical snapshots, or vendor-specific tools. While Percona Everest does not natively offer support for such tools, with DataImporters, you can write custom restore logic for your preferred backup tools or formats, and Percona Everest executes them.</p> <p>The benefits of using DataImporters are:</p> <ul> <li> <p>Reusable: You can define it once and use it across various environments.</p> </li> <li> <p>Flexible: You can perform imports using any scripting or programming language and restore tool.</p> </li> <li> <p>Extensible: It supports custom backup formats or workflows.</p> </li> <li> <p>Decoupled: Percona Everest manages the infrastructure while you focus on the data logic.</p> </li> </ul> <p>Do you want to customize your import process? You can create a custom <code>DataImporter</code> tailored to your specific use case. See the documentation for detailed instructions.</p>"},{"location":"backups_and_restore/dataimporters/overview.html#use-cases","title":"Use cases","text":"<p>Here are some common scenarios for importing database backups into Percona Everest.</p> PG restore from S3Custom DataImporter"},{"location":"backups_and_restore/dataimporters/overview.html#restore-a-postgresql-cluster-from-an-s3-backup","title":"Restore a PostgreSQL cluster from an S3 backup","text":"<p>You have a logical backup of a PostgreSQL database, created using <code>pg_dump</code>, stored in an Amazon S3 bucket. You want to use this backup to initialize a new PostgreSQL cluster managed by Percona Everest.</p>"},{"location":"backups_and_restore/dataimporters/overview.html#build-your-own-dataimporter","title":"Build your own DataImporter","text":"<p>You can create your own <code>DataImporter</code> to implement custom restore logic using any language or tool. This allows for seamless integration into the cluster provisioning workflow.</p> <p>See the documentation for detailed instructions.</p>"},{"location":"backups_and_restore/dataimporters/overview.html#limitations","title":"Limitations","text":"<p>There are a few limitations to be aware of when importing external database backups:</p> <ul> <li> <p>This feature only supports backups created using Percona Operators. Backups created by other tools directly in an S3 bucket are not supported.</p> Example <p>Supported</p> <ul> <li>Backups created via Percona Operator for MySQL, PostgreSQL, or MongoDB</li> <li>Stored in S3-compatible storage</li> </ul> <p>Unsupported</p> <ul> <li>Backups taken by third-party tools</li> <li>Direct uploads to S3 without using Percona Operator</li> </ul> </li> <li> <p>Percona Everest 1.8.0 does not guarantee successful imports for physical backups because it lacks an encryption key configuration. Although some cases may work depending on the backup method and environment, there is currently no official support for this feature.</p> </li> <li> <p>Certain import methods require database user credentials that exactly match those from the source system. Since Percona Everest does not validate these credentials, you must ensure they are accurate before starting the import.</p> </li> <li> <p>Percona Everest does not verify the compatibility of imported data with the version of the target <code>DatabaseCluster</code>. Ensure that the backup is compatible with the database version managed by Percona Everest.</p> </li> </ul>"},{"location":"backups_and_restore/dataimporters/overview.html#next-steps","title":"Next steps","text":"<p>DataImporter: Percona Operator for MySQL (XtraDB) </p> <p>DataImporter: Percona MongoDB Operator </p> <p>DataImporter: Percona Operator for PostgreSQL </p>"},{"location":"backups_and_restore/dataimporters/pg_dataimporter.html","title":"DataImporter: Percona Operator for PostgreSQL","text":"<p>The <code>everest-percona-pg-operator</code> dataimporter allows you to import backups taken using the Percona PostgreSQL Operator.</p>"},{"location":"backups_and_restore/dataimporters/pg_dataimporter.html#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Backup taken only using the Percona PostgreSQL operator stored in an S3-compatible storage bucket</p> <p>Note</p> <p>Backups created by other tools directly in an S3 bucket are not supported.</p> </li> <li> <p>Credentials to access the S3 bucket (<code>AccessKeyID</code> and <code>SecretAccessKey</code>)</p> </li> </ul>"},{"location":"backups_and_restore/dataimporters/pg_dataimporter.html#how-to-import-external-postgresql-backups-using-the-percona-everest-ui","title":"How to import external PostgreSQL backups using the Percona Everest UI","text":"<p>This section outlines the step-by-step process for importing backups using the Percona Everest UI.</p> <ol> <li> <p>Log in to the Percona Everest UI.</p> </li> <li> <p>From the Percona Everest homepage, click Import. Select the database type you want to import(MySQL, PostgreSQL, or MongoDB). The Basic Information page will be displayed.</p> </li> <li> <p>Fill in the details on the Basic information page and click Continue. This will take you to the Import information page.</p> </li> <li> <p>Select the <code>DataImporter</code> from the dropdown on the Import information page. </p> <p></p> <ul> <li> <p>Click Fill details to provide your S3 storage details. The S3 details page will open. Enter the following:     </p> <ul> <li>Bucket name:  Enter the unique name identifying your S3 storage bucket.</li> <li>Region: Select the geographical AWS region where your bucket is hosted (e.g., us-east-1, eu-west-1)</li> <li>Access key: Enter your AWS Access Key ID (like a username for API access).</li> <li>Secret key: Enter your AWS Secret Access Key (like a password for secure API access).</li> </ul> <p>Click Save.</p> <p></p> </li> <li> <p>In the File directory section, specify the path within your S3 bucket where the backup files are stored. Click Save.</p> <p>Important</p> <p>Percona Everest does not validate file paths or verify the existence of files in the specified storage buckets. Make sure that the backup directory path is correct and accessible.</p> <p>To verify that the specified path exists, you can use the AWS CLI:</p> <pre><code>aws s3 ls s3://&lt;bucket-name&gt;/&lt;path-to-backup&gt; --region &lt;region&gt;\n</code></pre> </li> </ul> Find the file path using AWS CLI <p>Find the file path using AWS CLI</p> <p>Prerequisites: Ensure AWS CLI is installed and configured on your system. To install AWS CLI, refer to the AWS CLI installation guide.</p> <ol> <li> <p>Run the following command:</p> <pre><code>cat &gt; ~/.aws/credentials\n[default]\naws_access_key_id = SECRET\naws_secret_access_key = SECRET\n</code></pre> </li> <li> <p>Navigate your S3 bucket structure:</p> <pre><code># List the folders in the bucket\naws s3 ls &lt;S3 bucket-name&gt;\n\n# Output\nPRE postgresql-nf9/\n\n# List the subfolders:\naws s3 ls &lt;S3 bucket-name&gt;/postgresql-nf9/\n\n# Output\nPRE bd68c303-33eb-4368-b564-2cc4b9c71163/\n\n# Drill down further:\naws s3 ls &lt;S3 bucket-name&gt;/postgresql-nf9/bd68c303-33eb-4368-b564-2cc4b9c71163/\n\n# Output\nPRE archive/\nPRE backup/\n\n\n# Go into the backup folder\naws s3 ls &lt;S3 bucket-name&gt;/postgresql-nf9/bd68c303-33eb-4368-b564-2cc4b9c71163/backup/\n\n# Output\nPRE db/\n\n\n# Go into the db folder\naws s3 ls &lt;S3 bucket-name&gt;/postgresql-nf9/bd68c303-33eb-4368-b564-2cc4b9c71163/backup/db/\n\n# Output\nPRE 20250702-085755F/\nPRE backup.history/\n2025-07-02 14:28:53   1174 backup.info\n2025-07-02 14:28:53   1174 backup.info.copy\n\n\nThe full file path for PostgreSQL will be:\n/postgresql-nf9/bd68c303-33eb-4368-b564-2cc4b9c71163/backup/db/20250702-085755F/\n</code></pre> </li> </ol> <p></p> </li> <li> <p>Click Continue. You will see the basic information page for your target database.</p> </li> <li> <p>Enter the information and click Continue until you reach the end of the wizard.</p> <p>Your backup import process will now start. Once the import is successful, the database status will eventually change to Up.</p> <p></p> </li> </ol>"},{"location":"backups_and_restore/dataimporters/psmdb_dataimporter.html","title":"DataImporter: Percona Operator for MongoDB","text":"<p>The <code>everest-percona-psmdb-operator</code> data importer allows you to import backups taken using the Percona Operator for MongoDB.</p>"},{"location":"backups_and_restore/dataimporters/psmdb_dataimporter.html#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Backups taken only using the Percona MongoDB Operator stored in an S3-compatible storage bucket</p> <p>Note</p> <p>Backups created by other tools directly in an S3 bucket are not supported.</p> </li> <li> <p>Credentials to access the S3 bucket (<code>AccessKeyID</code> and <code>SecretAccessKey</code>)</p> </li> <li>System user credentials from the source cluster. For more details, refer to the Percona Operator for MongoDB user documentation.</li> </ul>"},{"location":"backups_and_restore/dataimporters/psmdb_dataimporter.html#how-to-import-external-mongodb-backups-using-the-percona-everest-ui","title":"How to import external MongoDB backups using the Percona Everest UI","text":"<p>This section outlines the step-by-step process for importing backups using the Percona Everest UI.</p> <ol> <li> <p>Log in to the Percona Everest UI.</p> </li> <li> <p>From the Percona Everest homepage, click Import. Select the database type as MongoDB. The Basic Information page will be displayed.</p> </li> <li> <p>Fill in the details on the Basic information page and click Continue. This will take you to the Import info page.</p> </li> <li> <p>Select the data importer from the dropdown on the Import information page.</p> <p></p> <ul> <li> <p>Click Fill details to provide your S3 storage details. The S3 details page will open. Enter the following:</p> <ul> <li>Bucket name:  Enter the unique name identifying your S3 storage bucket.</li> <li>Region: Select the geographical AWS region where your bucket is hosted (e.g., us-east-1, eu-west-1)</li> <li>Access key: Enter your AWS Access Key ID (like a username for API access).</li> <li>Secret key: Enter your AWS Secret Access Key (like a password for secure API access).</li> </ul> <p>Click Save.</p> <p></p> </li> <li> <p>In the File directory section, specify the path within your S3 bucket where the backup files are stored. Click Save.</p> <p>Important</p> <p>Percona Everest does not validate file paths or verify the existence of files in the specified storage buckets. Make sure that the backup directory path is correct and accessible.</p> <p>To verify that the specified path exists, you can use the AWS CLI:</p> <pre><code>aws s3 ls s3://&lt;bucket-name&gt;/&lt;path-to-backup&gt; --region &lt;region&gt;\n</code></pre> Find the file path using AWS CLI <p>Prerequisites: </p> <p>Ensure AWS CLI is installed and configured on your system. To install AWS CLI, refer to the AWS CLI installation guide.</p> <ol> <li> <p>Run the following command:</p> <pre><code>cat &gt; ~/.aws/credentials\n[default]\naws_access_key_id = SECRET\naws_secret_access_key = SECRET\n</code></pre> </li> <li> <p>Navigate your S3 bucket structure:</p> <pre><code># List the folders in the bucket            \naws s3 ls &lt;S3 bucket-name&gt;\n\n# Output           \nPRE mongodb-zh5/\nPRE postgresql-6az/\n\n# List the subfolders                \naws s3 ls &lt;S3 bucket-name&gt;/mongodb-zh5/\n\n# Output                \nPRE 02d0a297-16ca-4b9f-8073-2f16607de3c9/\n\n# Drill down further\naws s3 ls &lt;S3 bucket-name&gt;/mongodb-zh5/02d0a297-16ca-4b9f-8073-2f16607de3c9/\n\n# Output               \nPRE 2025-07-01T07:13:32Z/\n\n# Dig deeper            \naws s3 ls &lt;S3 bucket-name&gt;/mongodb-zh5/02d0a297-16ca-4b9f-8073-2f16607de3c9/2025-07-01T07:13:32Z/\n\n# Output\nPRE rs0/\n\nThe file path for MongoDB will be:\n/mongodb-zh5/02d0a297-16ca-4b9f-8073-2f16607de3c9/2025-07-01T07:13:32Z/\n</code></pre> </li> </ol> <p></p> </li> <li> <p>In the\u00a0DB Credentials\u00a0section, enter the key-value pairs of the user secrets.</p> Retrieve the credentials from the Kubernetes secret <p>Run the following command to decode the credentials stored in the Kubernetes secret:</p> <pre><code>kubectl get secret everest-secrets-mongodb-zh5 -n everest -o jsonpath=\"{.data}\" | jq 'map_values(@base64d)'\n\nReplace `everest-secrets-mongodb-zh5` with your secret name.\n\nOutput\n\n{\n    \"MONGODB_BACKUP_PASSWORD\": \"3mBRT5XuJSrMzwhB\",\n    \"MONGODB_BACKUP_USER\": \"backup\",\n    \"MONGODB_CLUSTER_ADMIN_PASSWORD\": \"hE1M5Eaut93uWJGCykd\",\n    \"MONGODB_CLUSTER_ADMIN_USER\": \"clusterAdmin\",\n    \"MONGODB_CLUSTER_MONITOR_PASSWORD\": \"4ICXY35dqCfjZYR2p7\",\n    \"MONGODB_CLUSTER_MONITOR_USER\": \"clusterMonitor\",\n    \"MONGODB_DATABASE_ADMIN_PASSWORD\": \"5aQbEZEDjhoAWoSbc03\",\n    \"MONGODB_DATABASE_ADMIN_USER\": \"databaseAdmin\",\n    \"MONGODB_USER_ADMIN_PASSWORD\": \"a9pb12A09pSNchldzq\",\n    \"MONGODB_USER_ADMIN_USER\": \"userAdmin\"\n    }\n</code></pre> <p> </p> </li> </ul> </li> <li> <p>Click Continue to proceed. You will see the basic information page for your target database.</p> </li> <li> <p>Enter the information and click Continue until you reach the end of the wizard.</p> <p>Your backup import process will now start. Once the import is successful, the database status will change to Up.</p> <p></p> </li> </ol>"},{"location":"backups_and_restore/dataimporters/pxc_dataimporter.html","title":"DataImporter: Percona Operator for MySQL (XtraDB)","text":"<p>The <code>everest-percona-pxc-operator</code> dataimporter allows you to import backups taken using the Percona Operator for MySQL (XtraDB).</p>"},{"location":"backups_and_restore/dataimporters/pxc_dataimporter.html#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Backups taken only using the Percona Operator for MySQL (XtraDB) stored in an S3-compatible storage bucket.</p> <p>Note</p> <p>Backups created by other tools directly in an S3 bucket are not supported.</p> </li> <li> <p>Credentials to access the S3 bucket (<code>AccessKeyID</code> and <code>SecretAccessKey</code>)</p> </li> <li>System user credentials from the source cluster. For more details, refer to the Percona Operator for MySQL user documentation.</li> </ul>"},{"location":"backups_and_restore/dataimporters/pxc_dataimporter.html#how-to-import-external-mysql-backups-using-the-percona-everest-ui","title":"How to import external MySQL backups using the Percona Everest UI","text":"<p>This section outlines the step-by-step process for importing backups using the Percona Everest UI.</p> <ol> <li> <p>Log in to the Percona Everest UI.</p> </li> <li> <p>From the Percona Everest homepage, click Import. Select the database as MySQL. The Basic Information page will then be displayed.</p> </li> <li> <p>Fill in the details on the Basic information page and click Continue. This will take you to the Import information page.</p> </li> <li> <p>Select the data importer from the dropdown on the Import information page.</p> <p></p> <ul> <li> <p>Click Fill details to provide your S3 storage details. The S3 details page will open. Enter the following:</p> <ul> <li>Bucket name:  Enter the unique name identifying your S3 storage bucket.</li> <li>Region: Select the geographical AWS region where your bucket is hosted (e.g., us-east-1, eu-west-1)</li> <li>Access key: Enter your AWS Access Key ID (like a username for API access).</li> <li>Secret key: Enter your AWS Secret Access Key (like a password for secure API access).</li> </ul> <p>Click Save.</p> <p></p> </li> <li> <p>In the File directory section, specify the path within your S3 bucket where the backup files are stored. Click Save.</p> <p>Important</p> <p>Percona Everest does not validate file paths or verify the existence of files in the specified storage buckets. Make sure that the backup directory path is correct and accessible.</p> <p>To verify that the specified path exists, you can use the AWS CLI:</p> <pre><code>aws s3 ls s3://&lt;bucket-name&gt;/&lt;path-to-backup&gt; --region &lt;region&gt;\n</code></pre> Example <p>Find the file path using AWS CLI</p> <p>Prerequisites: Ensure AWS CLI is installed and configured on your system. To install AWS CLI, follow the AWS CLI installation guide.</p> <ol> <li> <p>Run the following command:</p> <pre><code>cat &gt; ~/.aws/credentials\n[default]\naws_access_key_id = SECRET\naws_secret_access_key = SECRET\n</code></pre> </li> <li> <p>Navigate your S3 bucket structure:</p> <pre><code># List the folders in the bucket\naws s3 ls &lt;S3 bucket-name&gt;\n\n\n# Output\nPRE mongodb-zh5/\nPRE mysql-wih/\n\n\n# List the subfolders\naws s3 ls &lt;S3 bucket-name&gt;/mysql-wih/\n\n# Output\nPRE 515f9e1b-301d-4b34-b2bd-959713bc70d0/\n\n\n# Drill down further\naws s3 ls &lt;S3 bucket-name&gt;/mysql-wih/515f9e1b-301d-4b34-b2bd-959713bc70d0/\n\n\n# Output\nPRE mysql-wih-2025-07-01-11:40:18-full.sst_info/\nPRE mysql-wih-2025-07-01-11:40:18-full/\n2025-07-01 17:10:49  \n25765 mysql-wih-2025-07-01-11:40:18-full.md5\n2025-07-01 17:10:36  \n128 mysql-wih-2025-07-01-11:40:18-full.sst_info.md5\n\nThe full file path for MySQL will be:\n/mysql-wih/515f9e1b-301d-4b34-b2bd-959713bc70d0/mysql-wih-2025-07-01-11:40:18-full/\n</code></pre> </li> </ol> <p></p> </li> <li> <p>In the DB Credentials section, enter the key-value pairs of the user secrets.</p> <p></p> Retrieve the DB credentials from the Kubernetes secrets <p>Run the following command to decode the credentials stored in the Kubernetes secret:</p> <pre><code>kubectl get secret everest-secrets-mysql-wih -n everest -o jsonpath=\"{.data}\" | jq 'map_values(@base64d)'\n</code></pre> <p>Output</p> <pre><code>{\n    \"monitor\": \"hgL3^_P*LE$4,b.Z=\",\n    \"operator\": \"480.GqWs&amp;K&gt;!~$Di\",\n    \"proxyadmin\": \"tud&amp;9[9gVSMMNt+6pj.\",\n    \"replication\": \"q!&lt;76&lt;X}F.S2mA._%w\",\n    \"root\": \"_bvt*Ip*@r-JOpz&gt;q@1\",\n    \"xtrabackup\": \"icR#jAwr0V-UW##73o\"\n}\n</code></pre> </li> </ul> </li> <li> <p>Click Continue. You will see the basic information page for your target database.</p> </li> <li> <p>Enter the information and click Continue until you reach the end of the wizard.</p> <p>Your backup import process will now start. Once the import is successful, the database status will change to Up.</p> <p></p> </li> </ol>"},{"location":"install/eks.html","title":"Create Kubernetes cluster on Amazon Elastic Kubernetes Service (EKS)","text":"<p>This guide will walk you through creating a Kubernetes cluster on Amazon Elastic Kubernetes Service (EKS). You\u2019ll learn how to configure your environment, create a cluster, and set up your nodes.</p>"},{"location":"install/eks.html#prerequisites","title":"Prerequisites","text":"<p>Before creating an EKS cluster, ensure the following tools are set up:</p> <ol> <li> <p>AWS Command Line Interface (AWS CLI): This tool allows you to interact with AWS services from your terminal. Install the AWS CLI.</p> </li> <li> <p>eksctl: A command-line tool to simplify the creation and management of EKS clusters. Install eksctl.</p> </li> <li> <p>kubectl: The Kubernetes command-line tool for managing and deploying applications. Install kubectl.</p> </li> <li> <p>Configure AWS CLI: Ensure your AWS CLI is configured with your credentials. AWS CLI.</p> </li> </ol>"},{"location":"install/eks.html#create-the-eks-cluster","title":"Create the EKS cluster","text":"<p>Warning</p> <p>To run a 3-node PXC cluster, you need at least a 3-node EKS cluster with 2 vCPUs available per node. The database will not be created if you attempt to create a database cluster in a Kubernetes cluster without sufficient resources.</p> <p>To create the EKS cluster, do the following steps:</p> <ol> <li> <p>Set up your cluster details</p> <p>Before creating your cluster, determine the following details:</p> <ul> <li>Cluster Name: Choose a name for your EKS cluster.</li> <li>AWS Region: Specify the AWS region where you want to deploy your cluster.</li> <li>Number of Nodes: Decide how many nodes you need.</li> <li>On-Demand and Spot Instances:  Determine the desired ratio between on-demand         and spot instances in the total number of nodes.</li> </ul> <p>Note</p> <p>Spot instances are not recommended for production environment but may be useful for testing purposes.</p> </li> <li> <p>Create Your EKS Cluster</p> <p>Use the following <code>eksctl</code> command to create your cluster:</p> <p>Example:</p> <pre><code>eksctl create cluster --name my-cluster --region region-code --version 1.28 --vpc-private-subnets subnet-ExampleID1,subnet-ExampleID2 --without-nodegroup\n</code></pre> <ul> <li>name: The name of your cluster.</li> <li>region: The AWS region where the cluster will be deployed.</li> <li>version: The Kubernetes version for your cluster.</li> <li>vpc-private-subnets: The private subnets where the nodes will be deployed.</li> <li>without-nodegroup: Creates the cluster without a default node group. You will add nodes later.</li> </ul> <p>For more detailed options and instructions, refer to the official EKS cluster creation documentation.</p> </li> <li> <p>Install the Amazon EBS CSI driver on your cluster.</p> <p>See the official documentation on adding it as an Amazon EKS add-on.</p> <p>3.1 Create your Amazon EBS CSI plugin IAM role with eksctl    </p> <pre><code>eksctl create iamserviceaccount \\\n--name ebs-csi-controller-sa \\\n--namespace kube-system \\\n--cluster $cluster_name \\\n--role-name AmazonEKS_EBS_CSI_DriverRole \\\n--role-only \\\n--attach-policy-arn arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy \\\n--approve\n</code></pre> <p>3.2 Add the Amazon EBS CSI add-on using eksctl. (Replace 111122223333 with your account ID)</p> <pre><code>eksctl create addon --name aws-ebs-csi-driver --cluster my-cluster --service-account-role-arn arn:aws:iam::111122223333:role/AmazonEKS_EBS_CSI_DriverRole --force\n</code></pre> </li> <li> <p>Add nodes to your EKS cluster</p> <p>Here\u2019s an example using a managed node group:</p> <pre><code>eksctl create nodegroup \\\n--cluster my-cluster \\\n--region region-code \\\n--name my-mng \\\n--node-ami-family ami-family \\\n--node-type m5.large \\\n--nodes 3 \\\n--nodes-min 2 \\\n--nodes-max 3 \\\n--ssh-access \\\n--ssh-public-key my-key\n</code></pre> </li> </ol>"},{"location":"install/eks.html#remove-the-eks-cluster","title":"Remove the EKS cluster","text":"<p>To delete your cluster, you will need the following data:</p> <ul> <li>Name of your EKS cluster</li> <li>AWS region in which you have deployed your cluster.</li> </ul> <p>You can clean up the cluster with the <code>eksctl</code> command as follows (with real names instead of  and  placeholders): <pre><code>$ eksctl delete cluster --region=&lt;region&gt; --name=\"&lt;cluster name&gt;\"\n</code></pre> <p>The cluster deletion may take time.</p> <p>Warning</p> <p>After deleting the cluster, all data stored in it will be lost.</p>"},{"location":"install/eks.html#next-steps","title":"Next Steps","text":"<p>Now that your Kubernetes cluster is running, you might want to deploy Percona Everest. Follow our quick install guide to get started quickly and easily.</p> <p>Quick install </p>"},{"location":"install/gke.html","title":"Create Kubernetes cluster on Google Kubernetes Engine (GKE)","text":"<p>This guide will walk you through creating a Kubernetes cluster on Google Kubernetes Engine (GKE).</p> <p>All commands from this guide can be run either in the Google Cloud shell or your local shell.</p>"},{"location":"install/gke.html#prerequisites","title":"Prerequisites","text":"<ul> <li>A Google Cloud account with billing enabled.</li> <li>Basic understanding of Kubernetes concepts.</li> </ul>"},{"location":"install/gke.html#environment-setup","title":"Environment Setup","text":""},{"location":"install/gke.html#google-cloud-shell","title":"Google Cloud Shell","text":"<p>To use Google Cloud shell, you need only a modern web browser. Open the Google Cloud Console and click on the Cloud Shell icon at the top-right corner.</p> <p></p>"},{"location":"install/gke.html#local-shell","title":"Local Shell","text":"<p>If you would like to use your local shell, install the following:</p> <ol> <li> <p>gcloud. This tool is    part of the Google Cloud SDK. To install it, select your operating    system on the official Google Cloud SDK documentation page    and then follow the instructions.</p> </li> <li> <p>kubectl.    It is the Kubernetes command-line tool you will use to manage and deploy    applications. To install the tool, run the following command:</p> </li> </ol> <pre><code>$ gcloud auth login\n$ gcloud components install kubectl\n</code></pre>"},{"location":"install/gke.html#create-and-configure-the-gke-cluster","title":"Create and configure the GKE cluster","text":"<p>You can configure the settings using the <code>gcloud</code> tool. You can run it either in the Cloud Shell or in your local shell (if you have installed Google Cloud SDK locally on the previous step).</p>"},{"location":"install/gke.html#step-1-create-the-cluster","title":"Step 1: Create the Cluster","text":"<p>The following command will create a cluster named <code>my-cluster-name</code>:</p> <pre><code>$ gcloud container clusters create my-cluster-name --project &lt;project ID&gt; --zone us-central1-a --cluster-version 1.27 --machine-type n1-standard-4 --num-nodes=3\n</code></pre> <p>Note</p> <ul> <li>Replace  with your actual Google Cloud project ID (see available projects with <code>gcloud projects list</code> command). <li>You may also need to edit the zone location, which is set to us-central1-a in the example above.</li> <p>This command creates a cluster with 3 nodes, each with a machine type of n1-standard-4 (4 vCPUs). The creation process may take a few minutes.</p> <p>You may wait a few minutes for the cluster to be generated.</p> When the process is over, you can see it listed in the Google Cloud console <p>Select Kubernetes Engine \u2192 Clusters in the left menu panel:</p> <p></p>"},{"location":"install/gke.html#step-2-configure-command-line-access","title":"Step 2: Configure Command-Line Access","text":"<p>Now you should configure the command-line access to your newly created cluster to make <code>kubectl</code> be able to use it.</p> <p>In the Google Cloud Console, select your cluster and then click the Connect shown on the above image. You will see the connect statement which configures the command-line access. You need to run the command in your local shell:</p> <pre><code>$ gcloud container clusters get-credentials my-cluster-name --zone us-central1-a --project &lt;project name&gt;\n</code></pre>"},{"location":"install/gke.html#step-3-set-up-cluster-role-binding","title":"Step 3: Set Up Cluster Role Binding","text":"<p>Finally, use your Cloud Identity and Access Management (Cloud IAM) to control access to the cluster. The following command will give you the ability to create Roles and RoleBindings:</p> <pre><code>kubectl create clusterrolebinding cluster-admin-binding --clusterrole cluster-admin --user $(gcloud config get-value core/account)\n</code></pre> Expected output <pre><code>clusterrolebinding.rbac.authorization.k8s.io/cluster-admin-binding created\n</code></pre> <p>Congratulations! You have successfully created and configured a Kubernetes cluster on Google Kubernetes Engine (GKE).</p>"},{"location":"install/gke.html#remove-the-gke-cluster","title":"Remove the GKE cluster","text":"<p>Once you are done with your cluster, cleaning up the resources is a good practice to avoid unnecessary charges You can clean up the cluster with the <code>gcloud</code> command as follows:</p> <pre><code>$ gcloud container clusters delete &lt;cluster name&gt; --zone us-central1-a --project &lt;project ID&gt;\n</code></pre> <p>This command will prompt you to confirm the deletion. Type <code>y</code> to confirm.</p> Also, you can delete your cluster via the Google Cloud console <p>Just click the <code>Delete</code> popup menu item in the clusters list:</p> <p></p> <p>The cluster deletion may take time.</p> <p>Warning</p> <p>After deleting the cluster, all data stored in it will be lost!</p>"},{"location":"install/gke.html#next-steps","title":"Next Steps","text":"<p>Now that your Kubernetes cluster is running, you might want to deploy Percona Everest. Follow our quick install guide to get started quickly and easily.</p> <p>Quick install </p>"},{"location":"install/installEverest.html","title":"Install Percona Everest using everestctl","text":"<p>ACTION REQUIRED: Percona Everest and Bitnami Container Catalog changes</p> <p>Bitnami is restructuring its container catalog on September 29, 2025. To avoid potential failures in Percona Everest operations, follow the steps outlined in this post.</p>"},{"location":"install/installEverest.html#before-you-start","title":"Before you start","text":"<p>Before running the commands in the Installation section, note that Everest will search for the kubeconfig file in the <code>~/.kube/config</code> path. If your file is located elsewhere, use the export command below to set the <code>KUBECONFIG</code> environment variable: </p> <pre><code>export KUBECONFIG=~/.kube/config\n</code></pre> <p>Important</p> <p>If you installed Percona Everest using <code>everestctl</code>, make sure to uninstall it exclusively through <code>everestctl</code> for a seamless removal.</p>"},{"location":"install/installEverest.html#install-percona-everest","title":"Install Percona Everest","text":"<p>Important</p> <p>Starting from version 1.4.0, <code>everestctl</code> now uses the Helm chart to install Percona Everest. To configure chart parameters during installation through <code>everestctl</code>, you can:</p> <ul> <li>Use the <code>--helm-.set</code> flag to specify individual parameter values.</li> <li>Provide a values file with the <code>--helm.values</code> flag for bulk configuration.</li> </ul> <p>To install and provision Percona Everest to Kubernetes:</p> <ol> <li> <p>Download the latest release of everestctl to provision Percona Everest. For detailed installation instructions, see everestctl installation documentation.</p> </li> <li> <p>You can install Percona Everest using either the wizard or the headless mode.</p> <p>Note</p> <ul> <li>If you do not specify a namespace, the <code>everest</code> namespace gets provisioned by default.</li> <li> <p>You can skip provisioning the database namespace during initial installation by using the flag <code>--skip-db-namespace</code>.</p> <p><pre><code>everestctl install --skip-db-namespace\n</code></pre> To explore namespaces management in details, refer to the section on namespace management.</p> </li> </ul> <ul> <li> <p>Install Percona Everest using the wizard</p> <ol> <li> <p>Run the following command.     <pre><code>everestctl install\n</code></pre></p> </li> <li> <p>Enter the specific names for the namespaces you want Percona Everest to manage, separating each name with a comma. These namespaces are restricted and cannot be used for deploying databases.</p> </li> <li> <p>If you skip adding the namespaces while installing Percona Everest, you can add them later using the following command.</p> <pre><code>everestctl namespaces add &lt;NAMESPACE&gt;\n</code></pre> </li> </ol> </li> <li> <p>Install Percona Everest using the headless mode</p> <ol> <li> <p>Run the following command. You can set multiple namepaces in the headless mode. Replace <code>&lt;namespace-name&gt;</code> with the desired name for your namespace.     <pre><code>everestctl install --namespaces &lt;namespace-name1&gt;,&lt;namespace-name2&gt; --operator.mongodb=true --operator.postgresql=true --operator.mysql=true --skip-wizard\n</code></pre></p> <p>Note</p> <p>The flag <code>--operator.xtradb-cluster</code> has been deprecated and will be removed in the subsequent releases. While it will continue to function for now,  users will receive a warning message asking them to use <code>--operator.mysql</code> instead.</p> Example <pre><code>everestctl install --namespaces dev,prod --operator.mongodb=true --operator.postgresql=true --operator.mysql=true --skip-wizard\n</code></pre> <p>Optional installation flags</p> Flags Description Helm flag PMM deployment Deploy Percona Monitoring and Management (PMM) as a sub-chart. PMM will be automatically deployed within the <code>everest-system</code> namespace. <code>--helm.set pmm.enabled=true</code> TLS enabled Enable TLS encryption for secure communication between Percona Everest components. <code>--helm.set server.tls.enabled=true</code> Examples <p>Install with PMM enabled  </p> <pre><code>helm install everest-core percona/everest --namespace=everest-system --create-namespace --helm.set pmm.enabled=true\n</code></pre> <p>Install Percona Everest with TLS enabled:</p> <pre><code>helm install everest-core percona/everest \\\n--namespace everest-system \\\n--create-namespace\n--helm.set server.tls.enabled=true\n</code></pre> <pre><code>everestctl install --namespaces &lt;namespace-name1&gt;,&lt;namespace-name2&gt; --operator.mongodb=true --operator.postgresql=true --operator.mysql=true --helm.set server.tls.enabled=true --skip-wizard\n</code></pre> <p>For comprehensive instructions on enabling TLS for Percona Everest, see the section TLS setup with Percona Everest.</p> </li> <li> <p>If you skip adding the namespaces while installing Percona Everest, you can add them later using the following command.</p> <pre><code>everestctl namespaces add &lt;NAMESPACE&gt;\n</code></pre> </li> </ol> </li> </ul> </li> <li> <p>Update the password for the <code>admin</code> user:</p> <pre><code>everestctl accounts set-password --username admin\n</code></pre> <p>Important</p> <p>You can retrieve the automatically generated password by running\u00a0the <code>everestctl accounts initial-admin-password</code> command. However, this password isn\u2019t stored securely.</p> <p>To access detailed information about user management, see the Manage users in Percona Everest section.</p> </li> <li> <p>Access the Everest UI/API using one of the following options for exposing it, as Everest is not exposed with an external IP by default:</p> Load BalancerNode PortPort forwarding <ol> <li> <p>Use the following command to change the Everest service type to <code>LoadBalancer</code>:</p> <pre><code>everestctl install \\\n--helm.set service.type=LoadBalancer\n</code></pre> </li> <li> <p>Retrieve the external IP address for the Everest service. This is the address where you can then launch Everest at the end of the installation procedure. In this example, the external IP address used is <code>http://34.175.201.246</code>.</p> <pre><code>kubectl get svc/everest -n everest-system\n</code></pre> Expected output <pre><code>NAME      TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE\neverest   LoadBalancer   10.43.172.194   34.175.201.246       8080:8080/TCP    10s\n</code></pre> When TLS is enabled <pre><code>NAME      TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE\neverest   LoadBalancer   10.43.172.194   34.175.201.246       443:8080/TCP    10s\n</code></pre> </li> </ol> <p>A <code>NodePort</code> is a service that makes a specific port accessible on all nodes within the cluster. It enables external traffic to reach services running within the Kubernetes cluster by assigning a static port to each node\u2019s IP address.</p> <ol> <li> <p>Run the following command to change the Everest service type to <code>NodePort</code>:</p> <pre><code>helm install percona-everest percona/everest \\\n--set service.type=NodePort\n</code></pre> </li> <li> <p>The following command displays the port assigned by Kubernetes to the everest service, which is <code>32349</code> in this case.</p> <pre><code>kubectl get svc/everest -n everest-system\nNAME      TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\neverest   NodePort   10.43.139.191   &lt;none&gt;        8080:32349/TCP   28m\n</code></pre> When TLS is enabled <pre><code>kubectl get svc/everest -n everest-system\nNAME      TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\neverest   NodePort   10.43.139.191   &lt;none&gt;        443:32349/TCP   28m\n</code></pre> </li> <li> <p>Retrieve the external IP addresses for the kubernetes cluster nodes.</p> Expected output <pre><code>kubectl get nodes -o wide\nNAME                   STATUS   ROLES    AGE   VERSION             \nINTERNAL-IPEXTERNAL-IP  OS-IMAGE                        KERNEL-VERSION   \nCONTAINER-RUNTIME\ngke-everest-test-default-pool-8bbed860-65gx   Ready    &lt;none&gt;   3m35s   \nv1.30.3-gke.1969001   10.204.15.199   34.175.155.135   Container- \nOptimized OS from Google   6.1.100+         containerd://1.7.19\ngke-everest-test-default-pool-8bbed860-pqzb   Ready    &lt;none&gt;   3m35s   \nv1.30.3-gke.1969001   10.204.15.200   34.175.120.50    Container- \nOptimized OS from Google   6.1.100+         containerd://1.7.19\ngke-everest-test-default-pool-8bbed860-s0hg   Ready    &lt;none&gt;   3m35s   \nv1.30.3-gke.1969001   10.204.15.201   34.175.201.246   Container- \nOptimized OS from Google   6.1.100+         containerd://1.7.19\n</code></pre> </li> <li> <p>To launch the Percona Everest UI and create your first database cluster, go to the IP address/port found in steps 2 and 3. In this example, the external IP address used is <code>http://34.175.155.135:32349</code>. Nevertheless, you have the option to use any node IP specified in the above steps.</p> <p>Note</p> <p>If TLS is enabled, the external IP address will be <code>https://34.175.155.135:32349</code>.</p> </li> </ol> <p>Run the following command to setup a port-forward to the Percona Everest server service:</p> <pre><code>kubectl port-forward svc/everest 8080:8080 -n everest-system\n</code></pre> <p>To launch the Percona Everest UI and create your first database cluster, go to your localhost IP address <code>http://127.0.0.1:8080</code>.</p> When TLS is enabled <pre><code>kubectl port-forward svc/everest 8443:443 -n everest-system\n</code></pre> <p>Percona Everest will be available at <code>https://127.0.0.1:8443</code>.                    </p> </li> </ol>"},{"location":"install/installEverest.html#next-steps","title":"Next steps","text":"<p>Provision a database </p>"},{"location":"install/install_everest_and_expose_via_ingress.html","title":"Install Percona Everest and expose via Ingress controller","text":"<p>This section explains how to install Percona Everest using Helm or  <code>everestctl</code> and expose Percona Everest using Ingress.</p> <p>An Ingress Controller is a Kubernetes component that manages external access to services within a cluster, usually over HTTP and HTTPS. It is responsible for processing Ingress resources, which are rules that define how traffic should be routed to different services within the cluster.</p>"},{"location":"install/install_everest_and_expose_via_ingress.html#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>A <code>kubeconfig</code> file in the <code>~/.kube/config</code> path. If your file is located elsewhere, use the export command below to set the <code>KUBECONFIG</code> environment variable:            </p> <pre><code>export KUBECONFIG=~/.kube/config\n</code></pre> </li> <li> <p>An Ingress controller (e.g., Nginx) installed on your Kubernetes cluster</p> </li> <li> <p>(Optional but recommended for production) A TLS certificate stored in a Kubernetes Secret.</p> </li> </ul> Install Percona Everest using HelmInstall Percona Everest using everesctl <p>Percona Helm charts are in the percona/percona-helm-charts repository on GitHub.</p> <p>Here are the steps to install Percona Everest and deploy additional database namespaces:</p> <ol> <li> <p>Add the Percona Helm repository:</p> <pre><code>helm repo add percona https://percona.github.io/percona-helm-charts/\nhelm repo update\n</code></pre> </li> <li> <p>Install Percona Everest with Ingress enabled:</p> <pre><code>helm install everest percona/everest \\\n  -n everest-system \\\n  --set ingress.enabled=true \\\n  --set ingress.ingressClassName=\"\" \\\n  --set ingress.hosts[0].host=everest.example.com \\\n  --set ingress.hosts[0].paths[0].path=/ \\\n  --set  ingress.hosts[0].paths[0].pathType=ImplementationSpecific\n</code></pre> <p>Note</p> <p>Replace <code>everest.example.com</code> with your own domain.</p> What\u2019s happening under the hood <p>The command does the following:</p> <ol> <li> <p>Deploys the Percona Everest components in the <code>everest-system</code> namespace. Currently, specifying a different namespace for Percona Everest is not supported.</p> </li> <li> <p>Deploys a new namespace called\u00a0<code>everest</code>\u00a0for your databases and the database operators.</p> <p>You can override the name of the database namespace by using the <code>dbNamespace.namespaceOverride</code> parameter. If you prefer to deploy just the core components, set <code>dbNamespace.enabled=false</code></p> </li> </ol> </li> <li> <p>Verify the Ingress resource:</p> <pre><code>kubectl get ingress -n everest-system\n</code></pre> <p>Ensure the address provided is valid and correctly routes to the Percona Everest service.</p> Example: Using a Helm values file <pre><code>ingress:\n# -- Enable ingress for Everest server\n  enabled: true\n# -- Ingress class name. This is used to specify which ingress controller should handle this ingress.\n  ingressClassName: \"nginx\"\n# -- Additional annotations for the ingress resource.\n  annotations: {}\n# -- List of hosts and their paths for the ingress resource.\n  hosts:\n    - host: everest.example.com\n  paths:\n      - path: /\n      pathType: ImplementationSpecific\n# -- TLS configuration for the ingress resource.\n# -- Each entry in the list specifies a TLS certificate and the hosts it applies to.\n  tls: []\n#  - secretName: everest-tls\n#    hosts:\n#      - everest.example.com\n</code></pre> <p>Install Percona Everest using this <code>YAML</code> file:</p> <pre><code>helm install everest percona/everest \\\n  -n everest-system \\\n  -f everest-values.yaml\n</code></pre> \ud83d\udd12 Install Percona Everest with TLS enabled <p>Install Percona Everest with TLS enabled:</p> <pre><code>helm install everest-core percona/everest \\\n--namespace everest-system \\\n--create-namespace\n--set server.tls.enabled=true\n</code></pre> <p>For comprehensive instructions on enabling TLS for Percona Everest, see the section TLS setup with Percona Everest.</p> </li> <li> <p>Once the installation is complete, retrieve the <code>admin</code> password. </p> <pre><code>kubectl get secret everest-accounts -n everest-system -o jsonpath='{.data.users\\.yaml}' | base64 --decode  | yq '.admin.passwordHash'\n</code></pre> <ul> <li> <p>The default username for logging into the Everest UI is <code>admin</code>. You can set a different default admin password by using the <code>server.initialAdminPassword</code> parameter during installation.</p> <p>Important</p> <p>The default <code>admin</code> password is stored in plain text. It is highly recommended that the password be updated using\u00a0<code>everestctl</code>\u00a0to ensure that the passwords are hashed. Instructions for installing <code>everestctl</code> can be found in everestctl installation guide.</p> <p>To access detailed information on user management, see the manage users in Percona Everest section.</p> </li> </ul> </li> <li> <p>To access the Everest UI/API, open your browser and go to <code>https://everest.example.com</code>.</p> <p>Note</p> <p>Replace <code>everest.example.com</code> with your own domain.</p> </li> <li> <p>Deploy additional database namespaces:</p> <p>Once Percona Everest runs successfully, you can create additional database namespaces using the <code>everest-db-namespace</code> Helm chart. </p> <p>If you set <code>dbNamespaces.enabled=false</code> in step 2, you can deploy a database namespace with the following command:</p> <pre><code>helm install everest \\\npercona/everest-db-namespace \\\n--create-namespace \\\n--namespace &lt;DB namespace&gt;\n</code></pre> <p>Note</p> <ul> <li>All database operators are installed in your database namespace by default. You can override this by specifying one or more of the following options: <code>[dbNamespace.pxc=false, dbNamespace.pg=false, dbNamespace.psmdb=false]</code>.</li> <li>Installation without chart hooks (i.e, the use of <code>--no-hooks</code>) is currently not supported.</li> </ul> </li> </ol> <p>Important</p> <p>Starting from version 1.4.0, <code>everestctl</code> now uses the Helm chart to install Percona Everest. To configure chart parameters during installation through <code>everestctl</code>, you can:</p> <ul> <li>Use the <code>--helm-.set</code> flag to specify individual parameter values.</li> <li>Provide a values file with the <code>--helm.values</code> flag for bulk configuration.</li> </ul> <p>To install and provision Percona Everest to Kubernetes:</p> <ol> <li> <p>Download the latest release of everestctl to provision Percona Everest. For detailed installation instructions, see everestctl installation documentation.</p> </li> <li> <p>Install Percona Everest:</p> <pre><code>everestctl install \\\n--helm.set ingress.enabled=true \\\n--helm.set ingress.ingressClassName=\"\" \\\n--helm.set ingress.hosts[0].host=everest.example.com \\\n--helm.set ingress.hosts[0].paths[0].path=/ \\\n--helm.set ingress.hosts[0].paths[0].pathType=ImplementationSpecific\n</code></pre> <p>Replace <code>everest.example.com</code> with your own domain.</p> </li> <li> <p>Enter the specific names for the namespaces you want Percona Everest to manage, separating each name with a comma. These namespaces are restricted and cannot be used for deploying databases.   </p> </li> <li> <p>Verify Ingress:</p> <pre><code>kubectl get ingress -n everest-system\n</code></pre> <p>Make sure the address provided is valid and that it correctly routes to the Percona Everest service.</p> Example: Custom YAML configuration file <pre><code>ingress:\n# -- Enable ingress for Everest server\nenabled: true\n# -- Ingress class name. This is used to specify which ingress controller should handle this ingress.\ningressClassName: \"nginx\"\n# -- Additional annotations for the ingress resource.\nannotations: {}\n# -- List of hosts and their paths for the ingress resource.\nhosts:\n  - host: everest.example.com\n    paths:\n      - path: /\n      pathType: ImplementationSpecific\n    # -- TLS configuration for the ingress resource.\n    # -- Each entry in the list specifies a TLS certificate and the hosts to which it applies.\ntls: []\n        #  - secretName: everest-tls\n        #    hosts:\n        #      - everest.example.com\n</code></pre> <p>Install Percona Everest using this file:</p> <pre><code>everestctl install --helm.values everest-values.yaml\n</code></pre> </li> <li> <p>Once the installation is complete, retrieve the <code>admin</code> password. </p> <pre><code>everestctl accounts initial-admin-password\n</code></pre> <ul> <li> <p>The default username for logging into the Everest UI is <code>admin</code>. You can set a different default admin password by using the <code>server.initialAdminPassword</code> parameter during installation.</p> </li> <li> <p>The default <code>admin</code> password is stored in plain text.</p> <p>Important</p> <p>It is highly recommended that the password be updated using\u00a0<code>everestctl</code>\u00a0to ensure that the passwords are hashed.  Instructions for installing <code>everestctl</code> can be found at everestctl installation guide.</p> <p>To access detailed information on user management, see the manage users in Percona Everest section.</p> </li> </ul> </li> <li> <p>To access the Everest UI/API, open your browser and go to  <code>https://everest.example.com</code>.</p> <p>Note</p> <p>Replace <code>everest.example.com</code> with your own domain.</p> </li> <li> <p>If you skip adding the namespaces while installing Percona Everest, you can add them later using the following command.</p> <pre><code>everestctl namespaces add &lt;NAMESPACE&gt;\n</code></pre> </li> </ol>"},{"location":"install/install_everest_and_expose_via_ingress.html#next-steps","title":"Next steps","text":"<p>Provision a database </p>"},{"location":"install/install_everest_helm_charts.html","title":"Install Percona Everest using Helm","text":"<p>This section explains how to install Percona Everest using Helm as an alternative to <code>everestctl</code>. Helm charts simplify the deployment process by packaging all necessary resources and configurations, making them ideal for automating and managing installations in Kubernetes environments.</p> <p>Percona Helm charts can be found in percona/percona-helm-charts repository in Github.</p> <p>Important</p> <p>If you installed Percona Everest using Helm, make sure to uninstall it exclusively through Helm for a seamless removal.</p>"},{"location":"install/install_everest_helm_charts.html#install-percona-everest-and-deploy-database-namespaces","title":"Install Percona Everest and deploy database namespaces","text":"<p>Here are the steps to install Percona Everest and deploy additional database namespaces:</p> <ol> <li> <p>Add the Percona Helm repository:</p> <pre><code>helm repo add percona https://percona.github.io/percona-helm-charts/\nhelm repo update\n</code></pre> </li> <li> <p>Install Percona Everest:</p> <pre><code>helm install everest-core percona/everest \\\n--namespace everest-system \\\n--create-namespace\n</code></pre> What\u2019s happening under the hood <p>The command does the following:</p> <ol> <li> <p>Deploys the Percona Everest components in the <code>everest-system</code> namespace. Currently, specifying a different namespace for Percona Everest is not supported.</p> </li> <li> <p>Deploys a new namespace called\u00a0<code>everest</code>\u00a0for your databases and the database operators.</p> <p>You can override the name of the database namespace by using the <code>dbNamespace.namespaceOverride</code> parameter. If you prefer to deploy just the core components, set <code>dbNamespace.enabled=false</code></p> </li> </ol> <p>Optional installation flags</p> Flags Description Helm flag PMM deployment Deploy Percona Monitoring and Management (PMM) as a sub-chart. PMM will be automatically deployed within the <code>everest-system</code> namespace. <code>--set pmm.enabled=true</code> TLS enabled Enable TLS encryption for secure communication between Percona Everest components. <code>--set server.tls.enabled=true</code> Examples <p>Install with PMM enabled  </p> <pre><code>helm install everest-core percona/everest --namespace=everest-system --create-namespace --set pmm.enabled=true\n</code></pre> <p>Install Percona Everest with TLS enabled:</p> <pre><code>helm install everest-core percona/everest \\\n--namespace everest-system \\\n--create-namespace\n--set server.tls.enabled=true\n</code></pre> <p>For comprehensive instructions on enabling TLS for Percona Everest, see the section TLS setup with Percona Everest.</p> </li> <li> <p>Once the installation is complete, retrieve the <code>admin</code> password. </p> <pre><code>kubectl get secret everest-accounts -n everest-system -o jsonpath='{.data.users\\.yaml}' | base64 --decode  | yq '.admin.passwordHash'\n</code></pre> <ul> <li> <p>The default username for logging into the Everest UI is <code>admin</code>. You can set a different default admin password by using the <code>server.initialAdminPassword</code> parameter during installation.</p> </li> <li> <p>The default <code>admin</code> password is stored in plain text. It is highly recommended to update the password using <code>everestctl</code> to ensure that the passwords are hashed. Instructions for installing <code>everestctl</code> can be found at everestctl installation guide.</p> <p>To access detailed information on user management, see the manage users in Percona Everest section.</p> </li> </ul> </li> <li> <p>Access the Everest UI/API using one of the following options for exposing it, as Everest is not exposed with an external IP by default:</p> Load BalancerNode PortPort Forwarding <p>Use the following commands to change the Everest service type to <code>LoadBalancer</code>:</p> <ol> <li> <p>Run the following command:</p> <pre><code>helm install percona-everest percona/everest \\\n--set service.type=LoadBalancer\n</code></pre> </li> <li> <p>Retrieve the external IP address for the Everest service. This is the address where you can then launch Everest at the end of the installation procedure. In this example, the external IP address used is <code>http://34.175.201.246</code>.</p> <pre><code>kubectl get svc/everest -n everest-system\n</code></pre> Expected output <pre><code>NAME      TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE\neverest   LoadBalancer   10.43.172.194   34.175.201.246       8080:8080/TCP    10s\n</code></pre> When TLS is enabled <pre><code>NAME      TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE\neverest   LoadBalancer   10.43.172.194   34.175.201.246       443:8080/TCP    10s\n</code></pre> </li> </ol> <p>A NodePort is a service that makes a specific port accessible on all nodes within the cluster. It enables external traffic to reach services running within the Kubernetes cluster by assigning a static port to each node\u2019s IP address.</p> <ol> <li> <p>Run the following command to change the Everest service type to <code>NodePort</code>:</p> <p><pre><code>kubectl patch svc/everest -n everest-system -p '{\"spec\": {\"type\": \"NodePort\"}}\n</code></pre> The following output displays the port assigned by Kubernetes to the everest service, which is <code>32349</code> in this case.</p> <pre><code>kubectl get svc/everest -n everest-system\nNAME      TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\neverest   NodePort   10.43.139.191   &lt;none&gt;        8080:32349/TCP   28m\n</code></pre> When TLS is enabled <pre><code>kubectl get svc/everest -n everest-system\nNAME      TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\neverest   NodePort   10.43.139.191   &lt;none&gt;        443:32349/TCP   28m\n</code></pre> </li> <li> <p>Retrieve the external IP addresses for the kubernetes cluster nodes.</p> Expected output <pre><code>kubectl get nodes -o wide\nNAME                   STATUS   ROLES    AGE   VERSION             \nINTERNAL-IPEXTERNAL-IP  OS-IMAGE                        KERNEL-VERSION   \nCONTAINER-RUNTIME\ngke-everest-test-default-pool-8bbed860-65gx   Ready    &lt;none&gt;   3m35s   \nv1.30.3-gke.1969001   10.204.15.199   34.175.155.135   Container- \nOptimized OS from Google   6.1.100+         containerd://1.7.19\ngke-everest-test-default-pool-8bbed860-pqzb   Ready    &lt;none&gt;   3m35s   \nv1.30.3-gke.1969001   10.204.15.200   34.175.120.50    Container- \nOptimized OS from Google   6.1.100+         containerd://1.7.19\ngke-everest-test-default-pool-8bbed860-s0hg   Ready    &lt;none&gt;   3m35s   \nv1.30.3-gke.1969001   10.204.15.201   34.175.201.246   Container- \nOptimized OS from Google   6.1.100+         containerd://1.7.19\n</code></pre> </li> <li> <p>To launch the Percona Everest UI and create your first database cluster, go to the IP address/port found in step 1 and 3 (if TLS is enabled). In this example, the external IP address used is <code>http://34.175.155.135:32349</code>. Nevertheless, you have the option to use any node IP specified in the above steps.</p> </li> </ol> <p>Run the following command to setup a port-forward to the Percona Everest server service:</p> <pre><code>kubectl port-forward svc/everest 8080:8080 -n everest-system \n</code></pre> <p>To launch the Percona Everest UI and create your first database cluster, go to your localhost IP address <code>http://127.0.0.1:8080</code>.</p> When TLS is enabled <pre><code>kubectl port-forward svc/everest 8443:443 -n everest-system\n</code></pre> <p>Percona Everest will be available at <code>https://127.0.0.1:8443</code>.</p> </li> <li> <p>Deploy additional database namespaces:</p> <p>Once Percona Everest is successfully running, you can create additional database namespaces using the <code>everest-db-namespace</code> Helm chart. </p> <p>If you set <code>dbNamespaces.enabled=false</code> in step 2, you can deploy a database namespace with the following command:</p> <pre><code>helm install everest \\\npercona/everest-db-namespace \\\n--create-namespace \\\n--namespace &lt;DB namespace&gt;\n</code></pre> <p>Note</p> <ul> <li>All database operators are installed in your database namespace by default. You can override this by specifying one or more of the following options: <code>[dbNamespace.pxc=false, dbNamespace.pg=false, dbNamespace.psmdb=false]</code>.</li> <li>Installation without chart hooks (i.e, the use of <code>--no-hooks</code>) is currently not supported.</li> </ul> </li> </ol>"},{"location":"install/install_everest_helm_charts.html#configure-parameters","title":"Configure parameters","text":"<p>You can customize various parameters in the Percona Everest Helm charts for your deployment to meet your specific needs. Refer to the Helm documentation to discover how to configure these parameters.</p> <p>A few parameters are listed in the following table. For a detailed list of the parameters, see the README.</p> <p>percona/everest chart</p> Key Type Default Description <code>server.initialAdminPassword</code> string \u201d\u201c Initial password configured for admin user. If it is not set, a random password is generated. It is recommended to reset the admin password after installation. <code>server.oidc</code> object {} OIDC configuration for Everest. These settings are applied only during installation. To modify the settings after installation, you have to manually update the everest-settings <code>ConfigMap</code>. <p>percona/everest-db-namespace subchart</p> Key Type Default Description <code>pxc</code> bool true Installs the Percona XtraDB Cluster operator if set. everest-db-namespace <code>postgresql</code> bool true <code>psmdb</code> bool true Installs the Percona Server MongoDB operator if set."},{"location":"install/install_everest_helm_charts.html#next-steps","title":"Next steps","text":"<p>Provision a database </p>"},{"location":"install/install_everest_openshift.html","title":"Install Percona Everest on Openshift","text":"<p>This section explains how to install Percona Everest using Openshift.</p>"},{"location":"install/install_everest_openshift.html#install-percona-everest","title":"Install Percona Everest","text":"<p>Here are the steps to install Percona Everest with OpenShift compatibility enabled:</p> <ol> <li> <p>Run the following command:</p> <pre><code>helm install everest-core percona/everest \\\n    --namespace everest-system \\\n    --create-namespace \\\n    --set compatibility.openshift=true \\\n    --set dbNamespace.compatibility.openshift=true \\\n    --set kube-state-metrics.securityContext.enabled=false \\\n    --set kube-state-metrics.rbac.create=false\n</code></pre> </li> <li> <p>(Optional) Update RBAC for kube-state-metrics:</p> <p>If you\u2019re running a chart version prior to 1.5.0, it\u2019s essential to manually create a <code>ClusterRoleBinding</code> for <code>kube-state-metrics</code> to ensure proper functionality. Use the following YAML:</p> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n    name: ksm-openshift-cluster-role-binding\nroleRef:\n    kind: \"ClusterRole\"\n    apiGroup: \"rbac.authorization.k8s.io\"\n    name: kube-state-metrics\nsubjects:\n    - kind: \"ServiceAccount\"\n    name: kube-state-metrics\n    namespace: everest-monitoring\nEOF\n</code></pre> <p>Note</p> <p>Starting from version 1.5.0 and onwards, a <code>ClusterRoleBinding</code> is created automatically when you enable the setting <code>compatibility.openshift=true</code>.</p> </li> <li> <p>(Optional) Deploy additional database namespaces:</p> <p>If you need to add database namespaces, run the following command with OpenShift compatibility enabled:</p> <pre><code>helm install everest \\\n    percona/everest-db-namespace \\\n    --create-namespace \\\n    --namespace everest \\\n    --set compatibility.openshift=true\n</code></pre> <p>For detailed instructions, refer to the installation section and adjust the installation parameters according to the values specified here.</p> </li> <li> <p>Once the installation is complete, retrieve the <code>admin</code> password. </p> <pre><code>kubectl get secret everest-accounts -n everest-system -o jsonpath='{.data.users\\.yaml}' | base64 --decode  | yq '.admin.passwordHash'\n</code></pre> <p>The default username for logging into the Everest UI is <code>admin</code>. You can set a different default admin password by using the <code>server.initialAdminPassword</code> parameter during installation.</p> <p>The default <code>admin</code> password is stored in plain text. It is highly recommended to update the password using <code>everestctl</code> to ensure that the passwords are hashed.</p> <p>To access detailed information on user management, see the manage users in Percona Everest section.</p> </li> <li> <p>Access the Everest UI/API using one of the following options for exposing it, as Everest is not exposed with an external IP by default:</p> Load BalancerNode PortPort Forwarding <ol> <li> <p>Use the following command to change the Everest service type to <code>LoadBalancer</code>:</p> <pre><code>helm install percona-everest percona/everest \\\n--set service.type=LoadBalancer\n</code></pre> </li> <li> <p>Retrieve the external IP address for the Everest service. This is the address where you can then launch Everest at the end of the installation procedure. In this example, the external IP address used is <code>http://34.175.201.246</code>.</p> <pre><code>kubectl get svc/everest -n everest-system\n</code></pre> Expected output <pre><code>NAME      TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE\neverest   LoadBalancer   10.43.172.194   34.175.201.246       8080:8080/TCP    10s\n</code></pre> </li> </ol> <p>A NodePort is a service that makes a specific port accessible on all nodes within the cluster. It enables external traffic to reach services running within the Kubernetes cluster by assigning a static port to each node\u2019s IP address.</p> <ol> <li> <p>Run the following command to change the Everest service type to <code>NodePort</code>:</p> <pre><code>kubectl patch svc/everest -n everest-system -p '{\"spec\": {\"type\": \"NodePort\"}}\n</code></pre> </li> <li> <p>The following command displays the port assigned by Kubernetes to the everest service, which is <code>32349</code> in this case.</p> <pre><code>kubectl get svc/everest -n everest-system\nNAME      TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\neverest   NodePort   10.43.139.191   &lt;none&gt;        8080:32349/TCP   28m\n</code></pre> </li> <li> <p>Retrieve the external IP addresses for the kubernetes cluster nodes.</p> <pre><code>kubectl get nodes -o wide\nNAME                   STATUS   ROLES    AGE   VERSION             \nINTERNAL-IPEXTERNAL-IP  OS-IMAGE                        KERNEL-VERSION   \nCONTAINER-RUNTIME\ngke-everest-test-default-pool-8bbed860-65gx   Ready    &lt;none&gt;   3m35s   \nv1.30.3-gke.1969001   10.204.15.199   34.175.155.135   Container- \nOptimized OS from Google   6.1.100+         containerd://1.7.19\ngke-everest-test-default-pool-8bbed860-pqzb   Ready    &lt;none&gt;   3m35s   \nv1.30.3-gke.1969001   10.204.15.200   34.175.120.50    Container- \nOptimized OS from Google   6.1.100+         containerd://1.7.19\ngke-everest-test-default-pool-8bbed860-s0hg   Ready    &lt;none&gt;   3m35s   \nv1.30.3-gke.1969001   10.204.15.201   34.175.201.246   Container- \nOptimized OS from Google   6.1.100+         containerd://1.7.19\n</code></pre> </li> <li> <p>To launch the Percona Everest UI and create your first database cluster, go to the IP address/port found in steps 2 and 3. In this example, the external IP address used is <code>http://34.175.155.135:32349</code>. Nevertheless, you have the option to use any node IP specified in the above steps.</p> </li> </ol> <ol> <li> <p>Run the following command to setup a port-forward to the Everest server service:</p> <pre><code>kubectl port-forward svc/everest 8080:8080 -n everest-system\n</code></pre> <p>To launch the Percona Everest UI and create your first database cluster, go to your localhost IP address <code>http://127.0.0.1:8080</code>.</p> </li> <li> <p>(Recommended) When Transport Layer Security (TLS) is enabled, run the following command to connect to Percona Everest:       </p> <pre><code>kubectl port-forward svc/everest 8443:443 -n everest-system\n</code></pre> <p>Percona Everest will be available at <code>http://127.0.0.1:8443</code>.</p> <p>For comprehensive instructions on enabling TLS for Percona Everest, see the section TLS setup with Percona Everest.</p> </li> </ol> </li> </ol>"},{"location":"install/install_everest_openshift.html#next-steps","title":"Next steps","text":"<p>Provision a database </p>"},{"location":"install/install_everestctl.html","title":"Install everestctl","text":"<p>Important</p> <p>Installing <code>everestctl</code> is only necessary if you want to use it to install Percona Everest using <code>everestctl</code>; it is not required if you prefer to install Percona Everest with Helm.</p> <p>You can download the latest version of <code>everestctl</code> visiting the latest release page in this repository.</p> Linux and WSLmacOS (Apple Silicon)macOS (Intel CPU) <p>To install <code>everestctl</code> on Linux or WSL, run the following commands:</p> <ol> <li> <p>Download the latest version of <code>everestctl</code>.</p> <pre><code>curl -sSL -o everestctl-linux-amd64 https://github.com/percona/everest/releases/latest/download/everestctl-linux-amd64\n</code></pre> </li> <li> <p>Install <code>everestctl</code> binary to /usr/local/bin/.</p> <pre><code>sudo install -m 555 everestctl-linux-amd64 /usr/local/bin/everestctl\n</code></pre> </li> <li> <p>Remove <code>everestctl</code> binary to clean up.</p> <pre><code>rm everestctl-linux-amd64\n</code></pre> </li> </ol> <p>To install <code>everestctl</code> on macOS with Apple Silicon, run the following commands:</p> <ol> <li> <p>Download the latest version of <code>everestctl</code> for Apple Silicon.</p> <pre><code>curl -sSL -o everestctl-darwin-arm64 https://github.com/percona/everest/releases/latest/download/everestctl-darwin-arm64\n</code></pre> </li> <li> <p>Install <code>everestctl</code> binary to /usr/local/bin/.</p> <pre><code>sudo install -m 555 everestctl-darwin-arm64 /usr/local/bin/everestctl\n</code></pre> </li> <li> <p>Remove <code>everestctl</code> binary to clean up</p> <pre><code>rm everestctl-darwin-arm64\n</code></pre> </li> </ol> <p>To install <code>everestctl</code> on macOS with an Intel CPU, run the following commands:</p> <ol> <li> <p>Download the latest version of <code>everestctl</code> for Intel CPUs.</p> <pre><code>curl -sSL -o everestctl-darwin-amd64 https://github.com/percona/everest/releases/latest/download/everestctl-darwin-amd64\n</code></pre> </li> <li> <p>Install <code>everestctl</code> binary to /usr/local/bin/.</p> <pre><code>sudo install -m 555 everestctl-darwin-amd64 /usr/local/bin/everestctl\n</code></pre> </li> <li> <p>Remove <code>everestctl</code> to clean up.</p> <pre><code>rm everestctl-darwin-amd64\n</code></pre> </li> </ol>"},{"location":"install/install_everestctl.html#next-steps","title":"Next steps","text":"<p>Start by installing Percona Everest:</p> <p>Install Everest </p>"},{"location":"install/prerequisites.html","title":"Prerequisites","text":"<p>Before getting started with Percona Everest, we recommend that you:</p> <ol> <li> <p>Install Helm v3   to install Percona Everest using Helm.</p> </li> <li> <p>Install yq  to install Percona Everest using Helm.</p> </li> <li> <p>Verify that you have access to the Kubernetes cluster that you want to use with Everest. By default, Everest uses the kubeconfig file available under ~/.kube/config. Run the following command:</p> <pre><code>kubectl get nodes\n</code></pre> Expected output <pre><code>    NAME                                       STATUS   ROLES    AGE   VERSION\n    gke-&lt;name&gt;-default-pool-75d48bfc-bx8g      Ready    &lt;none&gt;   11h   v1.26.7-gke.500\n    gke-&lt;name&gt;-default-pool-75d48bfc-c2df      Ready    &lt;none&gt;   11h   v1.26.7-gke.500\n    gke-&lt;name&gt;-default-pool-75d48bfc-zl7k      Ready    &lt;none&gt;   11h   v1.26.7-gke.500\n</code></pre> </li> </ol>"},{"location":"install/prerequisites.html#before-you-install-percona-everest","title":"Before you install Percona Everest","text":"<p>You can install Percona Everest using one of the following methods:</p> <ul> <li> <p>Helm charts</p> </li> <li> <p>everestctl, which connects Percona Everest to your Kubernetes cluster.</p> </li> </ul> <p>Once you\u2019ve installed Percona Everest, you can easily log into the Percona Everest UI by following the setup instructions in the next section.</p> <p>Important</p> <p>Percona Everest assists with installing all the necessary operators and required packages, but does not currently help with spinning up a publicly accessible Kubernetes cluster.</p> <p>We recommend setting up Percona Everest on the Amazon Elastic Kubernetes Service (EKS) or Google Kubernetes Engine (GKE). Percona Everest may not work as expected on local Kubernetes installations (minikube, kind, k3d, or similar products) due to network issues.</p> <p>Create EKS cluster  Create GKE cluster </p>"},{"location":"install/prerequisites.html#next-steps","title":"Next steps","text":"<p>Start by installing Percona Everest:</p> <p>Install Percona Everest </p>"},{"location":"install/supported_operators_k8s.html","title":"Supported operators and K8s clusters","text":"<p>Percona Everest provides support for various operators and Kubernetes clusters. The following is a list of the specific operators and Kubernetes clusters that are compatible with Percona Everest:</p>"},{"location":"install/supported_operators_k8s.html#operators","title":"Operators","text":"<ul> <li>Percona Operator for MySQL Based on Percona XtraDB Cluster (PXC) 1.16.1, 1.17.0</li> <li>Percona Operator for MongoDB (PSMDB) 1.18.0, 1.19.1</li> <li>Percona Operator for PostgreSQL (PG) 2.5.0, 2.6.0</li> </ul>"},{"location":"install/supported_operators_k8s.html#k8s-clusters","title":"k8s clusters","text":"<p>Percona Everest works on most of the cloud K8s and on most of the on-prem vanilla K8s.</p> <p>However, not all the many combinations of K8s distributions and K8s versions might be fully tested and certified. Refer to the matrix below and reach out to us should you have any questions.</p> Platform Kubernetes Version State Google GKE 1.30 - 1.32 Fully tested and certified Amazon EKS 1.30 - 1.32 Fully tested and certified OpenShift 4.16 - 4.18 Fully tested and certified Azure AKS - Works but not fully certified yet DigitalOcean - Works but not fully certified yet Vanilla K8s (kubeadm) - Works but not fully certified yet Other cloud K8s - Should work but not fully certified yet <p>Note</p> <p>Air-gapped environments (i.e. environments physically isolated from unsecured networks such as the public Internet) are not currently supported. Their support is coming soon.</p>"},{"location":"networking/load_balancer.html","title":"Load balancer configuration in Percona Everest","text":""},{"location":"networking/load_balancer.html#overview","title":"Overview","text":"<p>Provisioning external access to Kubernetes clusters can be challenging, since cloud providers like AWS, GCP, and Azure each have their own annotations and configurations for load balancers. As a result, users often have to manually adjust settings for each environment, leading to a lack of a unified approach.</p>"},{"location":"networking/load_balancer.html#why-use-load-balancer","title":"Why use load balancer?","text":"<p>Percona Everest simplifies the process by enabling administrators to define reusable load balancer configurations. This includes cloud provider-specific settings that can be applied consistently across clusters, ensuring:</p> <ul> <li> <p>Consistency across cloud and on-prem environments</p> </li> <li> <p>Reduced manual effort when provisioning external access</p> </li> <li> <p>Flexibility to support multiple cloud providers with a unified approach</p> </li> </ul>"},{"location":"networking/load_balancer.html#understanding-some-key-terms","title":"Understanding some key terms","text":"Term Definition ClusterIP In Kubernetes, a service type that exposes an application on a virtual IP address within the cluster. LoadBalancer In Kubernetes, a service type that exposes your application to the internet using a cloud provider\u2019s load balancing infrastructure. Load balancer Config A preset in Percona Everest that contains a set of key-value pairs representing annotations applied to the appropriate LoadBalancer. Percona Everest user A user of Percona Everest who manages database clusters. Percona Everest admin A user with full permissions to configure and maintain Percona Everest."},{"location":"networking/load_balancer.html#use-cases-for-load-balancer-configuration","title":"Use cases for load balancer configuration","text":""},{"location":"networking/load_balancer.html#standardized-configurations","title":"Standardized configurations","text":"<p>Reuse a predefined <code>LoadBalancerConfig</code> across multiple clusters to ensure consistent networking behavior. This is useful for organizations with strict compliance or networking policies.</p>"},{"location":"networking/load_balancer.html#quick-environment-provisioning","title":"Quick environment provisioning","text":"<p>Enable Database-as-a-Service (DBaaS) users to quickly create clusters with external access in a single step, eliminating the need for platform teams to manually patch services.</p>"},{"location":"networking/load_balancer_config.html","title":"Creating and managing load balancer configurations","text":"<p>Important</p> <p>Before you begin, take a moment to explore the important limitations of load balancer configuration.</p>"},{"location":"networking/load_balancer_config.html#create-a-load-balancer-configuration","title":"Create a load balancer configuration","text":"<p>Here\u2019s how you can create a load balancer configuration:</p> <ol> <li> <p>Navigate to the Percona Everest home page and go to  Settings &gt; Policies.</p> <p></p> </li> <li> <p>In the Load Balancer Configuration section, click Configure. The Load Balancer Configuration page opens.</p> <p></p> </li> <li> <p>Click Create configuration. A pop-up window appears.</p> <p></p> </li> <li> <p>Enter a Configuration name and click Create.</p> </li> <li> <p>Click Add new.</p> <p></p> </li> <li> <p>Enter the annotations (key-value pairs) for your load balancer configuration. </p> <p></p> <p>Note</p> <p>The key and value in a Load Balancer configuration for Percona Everest are derived from your Kubernetes environment and the load balancer implementation by your cloud provider.</p> Examples of keys and values used for Load balancer configuration <pre><code>service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\"                    # Use Network Load Balancer (NLB)\nservice.beta.kubernetes.io/aws-load-balancer-scheme: \"internet-facing\"        # Internet-facing vs. internal\nservice.beta.kubernetes.io/aws-load-balancer-internal: \"true\"                   # Internal LB\nservice.beta.kubernetes.io/aws-load-balancer-ssl-cert: \"arn:aws:acm:...\"        # Attach ACM SSL cert\nservice.beta.kubernetes.io/aws-load-balancer-ssl-ports: \"443\"                   # SSL termination ports\nservice.beta.kubernetes.io/aws-load-balancer-backend-protocol: \"http\"        # Protocol between LB and pods\n</code></pre> </li> <li> <p>Click Save configuration.</p> </li> <li> <p>Click Back to view the newly created load balancer configuration.</p> <p></p> </li> </ol>"},{"location":"networking/load_balancer_config.html#manage-load-balancer-configuration","title":"Manage load balancer configuration","text":"<p>Here\u2019s how you can edit the load balancer configuration:</p> <ol> <li> <p>Navigate to the Percona Everest home page and go to  Settings &gt; Policies.</p> </li> <li> <p>In the Load Balancer configuration section, click Configure. The list of existing configurations appears.</p> </li> <li> <p>To add new annotations or for an existing load balancer configuration, click on the configuration you want to update and click Edit configuration.</p> </li> <li> <p>Click Add new and add the annotations. Click Save configuration.</p> </li> <li> <p>To modify an existing configuration, click on the specific configuration and click Edit configuration. Modify the annotations and click Save configuration.</p> <p></p> <p>Note</p> <p>eks-default is the default load configuration and cannot be edited.</p> </li> </ol>"},{"location":"networking/load_balancer_config.html#delete-load-balancer-configuration","title":"Delete load balancer configuration","text":"<p>Here\u2019s how you can delete the load balancer configuration:</p> <ol> <li> <p>Navigate to the Percona Everest home page and go to  Settings &gt; Policies </p> </li> <li> <p>In the Load Balancer configuration section, click Configure. The list of existing configurations appears.</p> </li> <li> <p>Click on the ellipsis next to the load balancer configuration you want to delete.</p> </li> <li> <p>Click on Delete. A confirmation pop-up will be displayed for deleting the load balancer configuration.</p> </li> <li> <p>Enter the Config name in the text box and click Delete.</p> <p></p> <p>Note</p> <p>eks-default is the default load balancer configuration and cannot be deleted.</p> </li> </ol>"},{"location":"networking/load_balancer_config.html#expose-your-database-cluster","title":"Expose your database cluster","text":"<p>Use the comparison table below to determine whether to expose your database in Percona Everest using <code>ClusterIP</code> or <code>LoadBalancer</code>.</p> Criteria ClusterIP Load balancer Purpose Keeps the database accessible only inside the Kubernetes cluster. Makes the database accessible from outside the cluster. Accessibility Available only to in-cluster pods and services. Available to external clients through a cloud or external load balancer. Best suited for Applications that run within the same cluster as the database. Applications, monitoring tools, or clients that need external connectivity. Security Keeps access internal by default, reducing exposure. Requires strict access controls to prevent unauthorized access. Load balancer configuration Not supported. Allows you to apply custom annotations to control load balancer behavior. Limitations No external access possible. Inherits all the limitations for load balancer configuration."},{"location":"networking/load_balancer_config.html#configure-load-balancer-for-external-database-access","title":"Configure load balancer for external database access","text":"<p>You can expose a database cluster outside of the Kubernetes network during database creation:</p> <ol> <li> <p>Log in to the Percona Everest UI.</p> </li> <li> <p>On the Percona Everest homepage, click Create database. Select the database that you wish to provision.</p> </li> <li> <p>Continue through the setup until you reach the Advanced Configurations page.</p> </li> <li> <p>In the Enable External Access section, select Load balancer as the Exposure method from the dropdown.</p> <p></p> </li> <li> <p>Select the desired Load balancer configuration from the dropdown.</p> </li> <li> <p>(Optional) In the Source range field, enter trusted IP addresses to restrict access.</p> <ul> <li> <p>To add multiple Source ranges, click Add new. Enter the specific IP addresses separately.</p> </li> <li> <p>You must always provide a CIDR block (for example, 203.0.113.25/32 to allow only one IP, or 203.0.113.0/24 to allow an entire subnet).</p> </li> <li> <p>Without a network mask (/xx), the configuration is invalid.</p> </li> <li> <p>Using restrictive IP ranges reduces the risk of unauthorized access and data breaches.</p> </li> </ul> <p>Note</p> <p>Leaving the Source range blank will expose the database to all the IP addresses (0.0.0.0/0). This is not recommended for production environments.</p> </li> <li> <p>Click Continue until you reach the end of the wizard, and then click Create database.</p> </li> </ol>"},{"location":"networking/load_balancer_scenarios.html","title":"Load balancer scenarios","text":"<p>This section outlines the various scenarios around managing load balancer configurations.</p>"},{"location":"networking/load_balancer_scenarios.html#create-load-balancer-configuration","title":"Create load balancer configuration","text":"<p>Percona Everest administrators can predefine load balancer configurations suitable for their infrastructure, allowing all Percona Everest users to use them later without having to define rules for each database cluster creation.</p> <p>Key characteristics:</p> <ul> <li> <p>Load balancer configuration has a globally unique name across the entire Percona Everest deployment.</p> </li> <li> <p>It can be applied to the DB Proxy component for any supported database engine.</p> </li> <li> <p>It is not associated with a specific namespace, so the resource is cluster-scoped.</p> </li> <li> <p>It consists of a set of key-value pairs representing annotations that need to be applied to the appropriate load balancer.</p> </li> </ul> <p>After all required values are configured, the Percona Everest administrator saves the configuration to make it available for use throughout the platform.</p>"},{"location":"networking/load_balancer_scenarios.html#restrict-access-to-load-balancer-configurations-with-role-based-access-control-rbac-policies","title":"Restrict access to load balancer configurations with Role-based access control (RBAC) policies","text":"<p>For security, the Percona Everest administrator can limit access to specific load balancer configs, including the ability to apply or modify them. This is achieved using Percona Everest\u2019s RBAC (Role-Based Access Control) system.</p> <p>Key characteristics:</p> <p>RBAC policies apply to the entire load balancer configuration, including all key-value pairs in the template.</p> <p>It is not possible to assign access control to individual key-value pairs within a specific load balancer configuration.</p>"},{"location":"networking/load_balancer_scenarios.html#restrict-usage-of-load-balancer-configs","title":"Restrict usage of load balancer configs","text":"<p>Here\u2019s the most common Role-Based Access Control (RBAC) scenario for LoadBalancer configuration and how you can set it up:</p> <p>The Percona Everest administrator can manage (create/edit/read/delete) load balancer configuration for specific Percona Everest users only. The rest of the users can only read load balancer config content and can apply existing configs when provisioning database clusters, but cannot modify them.</p> <p>To achieve this, the following RBAC policy is defined:</p> <pre><code>p, alice, load-balancer-configs, *, *\np, role:team-dev, load-balancer-configs, read, *\n</code></pre>"},{"location":"networking/load_balancer_scenarios.html#apply-load-balancer-configuration-to-a-new-database-cluster","title":"Apply load balancer configuration to a new database cluster","text":"<p>Important</p> <p>Only one load balancer configuration can be applied to a load balancer at any given time.</p> <p>While creating a new database cluster, a user can expose it using the load balancer and apply the configuration to it.</p> <p></p> <ul> <li> <p>If RBAC is disabled: The system will display all existing load balancer configurations.</p> </li> <li> <p>If RBAC is enabled: The system will only show the load balancer configurations that the user can access (with read permissions).</p> </li> </ul> <p>For more information, see the Creating and managing load balancer configurations section.</p>"},{"location":"networking/load_balancer_scenarios.html#apply-load-balancer-configuration-to-an-existing-database-cluster","title":"Apply load balancer configuration to an existing database cluster","text":"<p>Important</p> <p>Only one load balancer configuration can be applied to a load balancer at any given time.</p> <p>Users may want to change the load balancer configuration applied to an existing load balancer.</p> <p></p> <p>For detailed information, see the Manage load balancer configurations section.</p> <p>Within the load Balancer configuration section, users can select a different config:</p> <ul> <li>If RBAC is disabled: All existing load Balancer Configs are visible.</li> <li>If RBAC is enabled: Only the load Balancer Configs the user has read access to will be displayed.</li> </ul> <p>After selecting a new load Balancer config, the user can save the changes:</p> <ul> <li> <p>If a new config is selected, the system applies it to the load balancer.</p> <p>Note</p> <p>This change does not trigger a database restart.</p> </li> <li> <p>If the user cancels the changes, no updates are applied.</p> </li> </ul>"},{"location":"networking/load_balancer_scenarios.html#manage-load-balancer-configuration","title":"Manage load balancer configuration","text":"<p>As infrastructure requirements or usage patterns change, there may be a need to modify or remove existing load Balancer Configurations. Percona Everest enables administrators, as well as any users with the appropriate RBAC permissions, to update or delete load Balancer Configurations directly from the Percona Everest UI.</p>"},{"location":"networking/load_balancer_scenarios.html#modify-load-balancer-configuration","title":"Modify load balancer configuration","text":"<p>A Percona Everest Admin may need to adjust a load Balancer config by adding, modifying, or removing annotations.</p> <p>If a LoadBalancer configuration (LBC) is used by any existing database, any changes made to the LBC will automatically apply to all database clusters that use it.</p>"},{"location":"networking/load_balancer_scenarios.html#delete-load-balancer-configuration","title":"Delete load balancer configuration","text":"<p>When a load Balancer configuration is no longer needed, the Percona Everest admin can delete the load balancer configuration.</p> <p>If a LoadBalancer configuration (LBC) is used by any existing database, any changes made to the LBC will automatically apply to all database clusters that use it.</p>"},{"location":"networking/load_balancer_scenarios.html#next-steps","title":"Next steps","text":"<p>Creating and managing load balancer configurations </p>"},{"location":"reference/AI_disclaimer_for_docs.html","title":"Use of Artificial Intelligence (AI) in Percona Everest documentation","text":"<p>The writers of this documentation use generative AI in content creation, language refinement, and formatting optimization, especially in the new additions to the documentation.</p> <p>We take full responsibility for reviewing and refining all content to ensure it is accurate, clear, and consistent, regardless of how it was created. Our committed team carefully reviews every piece to maintain Percona\u2019s high standards.</p>"},{"location":"reference/copyright.html","title":"Copyright and licensing information","text":""},{"location":"reference/copyright.html#documentation-licensing","title":"Documentation licensing","text":"<p>Percona Everest documentation is (C)2009-2025 Percona LLC and/or its affiliates and is distributed under the Creative Commons Attribution 4.0 International License.</p>"},{"location":"reference/known_limitations.html","title":"Known limitations in Percona Everest","text":"<p>This section describes the known limitations associated with Percona Everest:</p>"},{"location":"reference/known_limitations.html#passwords","title":"Passwords","text":"<p>Refrain from changing the password of administrative users (e.g., root, monitor, or operator) manually in the database. This action may cause inconsistencies with the secrets stored in Kubernetes, which are crucial for the proper functioning of the cluster. Such modifications have the potential to disrupt your cluster.</p> <p>We are developing a new feature that will allow you to modify these settings directly from the user interface (UI).</p>"},{"location":"reference/known_limitations.html#load-balancer-configuration","title":"Load balancer configuration","text":"<ul> <li> <p>Once annotations are added to a service by the database operators, they cannot be entirely removed.</p> </li> <li> <p>After applying a Load Balancer Configuration (LBC), you cannot revert to the <code>-No Configuration-</code> option.</p> </li> <li> <p>If a service is changed from LoadBalancer to ClusterIP, the previously applied annotations remain on the service.</p> </li> <li> <p>When you apply a new Load Balancer configuration, all existing annotations in the service are replaced by those defined in the selected Load Balancer configuration.</p> </li> </ul>"},{"location":"reference/known_limitations.html#mongodb-sharding","title":"MongoDB sharding","text":"<ul> <li> <p>Once MongoDB sharding is enabled, it cannot be disabled.</p> </li> <li> <p>After you enable sharding for a cluster, you need to take another backup to ensure you can restore. </p> </li> <li> <p>Since MongoDB sharding is in Tech Preview, there may be issues with backups and restores. Therefore, using sharded PSMDB clusters in production environments is not recommended.</p> <ul> <li> <p>If your restore fails or is stuck, use this workaround: </p> <p>On the Percona Everest UI, navigate to the Restores tab, locate the latest restore object, click <code>...</code>, and delete it. Then, attempt to restore it again.</p> </li> </ul> </li> </ul>"},{"location":"reference/known_limitations.html#manual-storage-scaling","title":"Manual storage scaling","text":"<ul> <li> <p>When manually scaling storage in Percona Everest, resource quotas are not automatically validated during the volume expansion process. If the requested storage exceeds the defined quota, the PVC resize operation will fail, leaving the database in the Resizing Volumes state.</p> <p>To avoid such issues, ensure you verify your namespace\u2019s resource quotas before initiating a resize:</p> <pre><code>kubectl describe quota &lt;resource-quota-name&gt; -n &lt;namespace&gt;\n</code></pre> </li> <li> <p>If scaling fails for any reason, the database will remain in the Resizing Volumes state, and the operation will be continuously retried.</p> </li> <li> <p>Consult your CSI driver documentation for important details regarding volume resizing restrictions or limitations. This is essential for ensuring smooth operations.</p> </li> <li> <p>In previous versions of Percona Everest, users were able to create clusters with decimal storage sizes (for example, 1.2 GiB). However, database operators rounded these values up when provisioning PersistentVolumeClaims (PVCs)\u2014meaning that 1.2 GiB would be provisioned as 2 GiB. Percona Everest would then display the original value in a different unit (such as 1.2 GiB shown as 1288490188800 m), which caused confusion.</p> <p>In version 1.6.0, Percona Everest introduces support for scaling up storage. However, when attempting to scale a cluster to a size that does not exceed the larger rounded PVC size (for instance, trying to scale from 1.2 GiB to 2 GiB, which still rounds to 2 GiB), the cluster may become stuck in the Resizing Volumes state. This issue affects MySQL and MongoDB clusters; however, PostgreSQL clusters are not impacted.</p> <p>Workaround </p> <p>When scaling storage on clusters created with decimal sizes, make sure the new size exceeds the next whole GiB value (for example, scale from 1.2 GiB to 3 GiB).</p> </li> </ul>"},{"location":"reference/known_limitations.html#databases","title":"Databases","text":"<ul> <li> <p>MongoDB 4.4 will no longer be supported, preventing users from upgrading the PSMDB operator if any database is running version 4.4.</p> </li> <li> <p>Do not perform a full backup of an empty MongoDB database. Instead, ensure that you add some data to the database before creating a full backup.</p> </li> <li> <p>If you attempt to delete a MongoDB cluster stuck in the initializing state due to insufficient resources, the cluster will remain in the deleting state indefinitely. This issue is caused by a bug in the PSMDB operator.</p> </li> <li> <p>If you attempt to delete a MongoDB and MySQL cluster stuck in the initializing state due to insufficient resources, the cluster will remain in the deleting state indefinitely. This issue is caused by a bug in the PSMDB operator.</p> <p>Workaround</p> <ol> <li> <p>Run the command:</p> <p><code>kubectl edit psmdb/&lt;DBName&gt; -n &lt;Namespace&gt;</code></p> </li> <li> <p>Delete the finalizer called <code>delete-pods-in-order</code>.</p> </li> </ol> </li> <li> <p>When you delete a PostgreSQL (PG) cluster, the associated backup files will not be automatically removed from S3. Instead, these files will remain in S3 storage. Therefore, you need to manually delete any backup files that you no longer need.</p> </li> </ul>"},{"location":"reference/known_limitations.html#upgrading-operators","title":"Upgrading operators","text":"<ul> <li>When you upgrade PostgreSQL operators to version 2.4.1, the database transitions to the Initializing state as part of the upgrade process. However, this Initializing state does not cause any downtime.</li> <li>Since the PostgreSQL operator does not support major version upgrades, you cannot directly upgrade PostgreSQL 12.19 to 13.16. This limitation also prevents upgrading the PG operator itself. Morever, there is no built-in mechanism for transferring data from PostgreSQL 12.19 to 13.16, making migration a challenge.</li> <li>When you upgrade PXC operators to version 1.15.0, single node MySQL databases will be restarted, resulting in downtime. However, it is worth noting that single node databases should not be used in production environments.</li> </ul>"},{"location":"reference/known_limitations.html#backups-storage","title":"Backups storage","text":"<p>The backup storage you choose for your initial backup schedule will be used for all subsequent schedules and point-in-time recovery (PITR).</p>"},{"location":"reference/known_limitations.html#on-demand-backups","title":"On-demand backups","text":"<p>Let\u2019s delve into the limitations of on-demand backups in Percona Everest.</p>"},{"location":"reference/known_limitations.html#postgresql-limitations-for-on-demand-backups","title":"PostgreSQL limitations for on-demand backups","text":"<ul> <li> <p>When attempting to delete a PostgreSQL database that contains backups created with Everest versions older than 1.0.0, the database may become stuck in the Deleting state. </p> <p>Workaround: To prevent this, manually delete any backups created with versions prior to 1.0.0 by using the Delete action on the Backups page before deleting the database.</p> </li> <li> <p>You cannot change the bucket name and region for a specific backup storage. Doing so will make any backups taken for that bucket unusable.</p> </li> <li> <p>You can use any of the existing backup storages across on-demand backups and schedules, as long as the total number of storages in use (by existing on-demand backups and schedules) does not exceed three.</p> <p>If you have created two schedules using backup storage <code>bucket-1</code> and <code>bucket-2</code>, and an on-demand backup using backup storage <code>bucket-3</code>, you can only utilize one of these three backup storages to create the next on-demand backup or a schedule.</p> </li> </ul>"},{"location":"reference/known_limitations.html#mongodb-backup-failures","title":"MongoDB backup failures","text":"<p>There maybe instances when your MongoDB backups may encounter unexpected failures. </p> <p>Let\u2019s check the reason for these failures by running the following command:</p> <pre><code>kubectl get psmdb-backup &lt;BACKUP_NAME&gt; -n &lt;YOUR_NAMESPACE&gt; -o yaml | grep error\n</code></pre> <p>Here are some potential errors you could encounter:</p> <ul> <li><code>starting deadline exceeded</code></li> <li><code>'couldn''t get response from all shards: convergeClusterWithTimeout:</code></li> </ul>"},{"location":"reference/known_limitations.html#workarounds-for-mongodb-backup-failures","title":"Workarounds for MongoDB backup failures","text":"<p>In the following table, we have compiled a list of workarounds to ensure that your backups function properly again.</p> Workaround Impact on the cluster Action Procedure 1 No downtime Delete the locks 1. Connect to your MongoDB database.  2. Run the command: <code>db.getSiblingDB(\"admin\").pbmLock.find()</code> to see the list of database locks. If the list is empty, the scenario is not applicable.  3. If the list was not empty, run the command<code>db.pbmLock.deleteMany({})</code>.  4. Run another backup. If the backup still fails, check the workaround 2. 2 Shorter downtime Restart config server (sharded clusters only) 1. Get the list of config server pods:<code>kubectl get po -n &lt;YOUR_NAMESPACE&gt; -l app.kubernetes.io/component=cfg,app.kubernetes.io/instance=&lt;YOUR_DB_CLUSTER_NAME&gt;</code>.  2. For each pod name in the list, run <code>kubectl delete pod &lt;POD_NAME&gt; -n &lt;YOUR_NAMESPACE&gt;</code> 3. Wait until your database cluster is up.  4. Run another bakckup. If the backup still fails, check workaround 3. 3 Longer downtime Restart the DB server 1. On Percona Everest UI, click Actions \u00bb Restart.  2. When the database cluster is up, take another backup."},{"location":"reference/known_limitations.html#scheduled-backups","title":"Scheduled backups","text":"<p>Let\u2019s explore the constraints of scheduled backups in Percona Everest.</p>"},{"location":"reference/known_limitations.html#postgresql-limitations-for-schedules","title":"PostgreSQL Limitations for schedules","text":"<p>Due to PostgreSQL limitations, the following functionality is unavailable for PostgreSQL:</p> <ul> <li>Modifying the storage location in existing schedules</li> <li>Using the same backup storage for different schedules</li> <li>Creating more than three schedules for PostgreSQL</li> <li>Using more than three different backup storages in total, including those used in existing on-demand backups.</li> </ul> <p>Everest does not allow these actions to be performed because they could corrupt previously taken backups, making it impossible to restore from them.</p>"},{"location":"reference/known_limitations.html#point-in-time-recovery-pitr","title":"Point-in-time-recovery (PITR)","text":"<p>Point-In-Time Recovery (PITR) can only be used after a certain time has elapsed since the latest backup. This interval of time is referred to as the PITR upload interval. During this interval, PITR restore won\u2019t be available.</p> <p>The default uploadInterval values for different databases are as follows:  </p> <ul> <li>MySQL = 1 minute</li> <li>MongoDB = 10 minutes</li> <li>PostgreSQL = 1 minute</li> </ul>"},{"location":"reference/known_limitations.html#postgresql-limitation-for-pitr","title":"PostgreSQL limitation for PITR","text":"<p>When performing point-in-time recovery (PITR) for PostgreSQL, it is important to consider the following limitations:</p> <ul> <li> <p>The Edit button for PITR in the UI is always disabled for PostgreSQL. However, PITR is automatically enabled once a backup or backup schedule is created.</p> </li> <li> <p>You may encounter issues with point-in-time recovery (PITR) when attempting to recover the database after the last transaction. PITR can get stuck in the Restoring state.</p> </li> </ul> <p>Check the timestamp of the last transaction</p> <p>Connect to your database and run the following command:</p> <p><code>select pg_last_committed_xact();</code></p> Expected output <p><pre><code>(768,\u201c2024-03-13 15:52:25.122746+00\u201d,0);\n</code></pre> It contains the global transaction identifier (<code>GTID</code>), <code>timestamp</code> and the status of the last transaction.</p> <p>Warning</p> <p>You can only recover data for the dates prior to this specific date.</p> <p>Workaround</p> <p>You can follow these steps if your database cluster is stuck in the Restoring state:</p> <ol> <li> <p>Check if your database cluster has been stuck because you have used a date after the last transaction:</p> <p>a. Find the recovery pod:</p> <pre><code>kubectl get pod -n your-namespace\n</code></pre> <p>The format of the recovery pod name is <code>&lt;cluster_name&gt;-pgbackrest-restore-&lt;XYZ&gt;</code>. The status of the recovery pod should be Running.</p> <p>b. Check the logs for the recovery pod:</p> <pre><code>kubectl logs &lt;restore_pod_name&gt; -n your-namespace\n</code></pre> Example <pre><code>kubectl logs postgresql-kbi-pgbackrest-restore-8b95v -n your-namespace\n</code></pre> <p>Check whether the log contains the following:</p> <pre><code>FATAL: recovery ended before configured recovery target was reached\n</code></pre> <p>In this case, the cluster is stuck during restoration because you used a date that was after the last transaction.</p> </li> <li> <p>Start an interactive bash shell inside the recovery pod:</p> <pre><code>kubectl -n your-namespace exec &lt;restore_pod_name&gt; -it -- bash\n</code></pre> Example <pre><code>kubectl -n your-namespace exec postgresql-kbi-pgbackrest-restore-8b95v -it -- bash\n</code></pre> <p>Delete the <code>recovery.signal</code>file:</p> <pre><code>rm pgdata/pg16/recovery.signal\n</code></pre> <p>After a certain period, the recovery pod will self-destruct. The database cluster status will change from Restoring to Initializing and eventually to Up.</p> </li> </ol>"},{"location":"reference/known_limitations.html#oidc-integration-with-microsoft-entra","title":"OIDC integration with Microsoft Entra","text":"<p>When integrating Microsoft Entra ID as your OIDC provider for Percona Everest, it\u2019s essential to ensure that the access tokens issued are compatible with Percona Everest\u2019s token validation logic.</p> <p>Problem</p> <p>By default, Microsoft Entra issues access tokens intended for use with Microsoft\u2019s own APIs (e.g., Microsoft Graph). These tokens have the following characteristics:</p> <ul> <li> <p>Audience (aud): \u201c<code>00000003-0000-0000-c000-000000000000</code>\u201d (Microsoft Graph)</p> </li> <li> <p>Signature: Uses a proprietary mechanism that cannot be validated by Percona Everest</p> </li> </ul> <p>Microsoft Entra generates access tokens using a proprietary signature mechanism, which Percona Everest cannot validate. This results in signature verification failures when integrating Percona Everest with Entra-generated tokens.</p> <p>Solution</p> <p>To obtain access tokens that Percona Everest can validate, request tokens explicitly scoped for the registered application in Microsoft Entra using the <code>&lt;application-client-id&gt;/.default scope</code>. This ensures:</p> <ul> <li> <p>Audience (aud): Set to your application\u2019s client ID</p> </li> <li> <p>Signature: Standard JWT, verifiable using the issuer\u2019s public keys</p> </li> </ul> <p>Everest Configuration</p> <p>When configuring Everest\u2019s OIDC settings via <code>everestctl</code>, ensure you specify the correct scope:</p> <pre><code>everestctl settings oidc configure \\\n--issuer-url=http://url.com \\\n--client-id=&lt;your-app-client-id&gt; \\\n--scopes=openid,profile,email,&lt;your-app-client-id&gt;/.default\n</code></pre> <p>Note</p> <p>Note: Replace <code>&lt;your-app-client-id&gt;</code> with your actual Microsoft Entra application (client) ID, and ensure the issuer-url points to the correct tenant.</p> <p>With this configuration, the access token will include <code>\"aud\": \"&lt;your-app-client-id&gt;\"</code>, and it will have a valid signature that Percona Everest can verify.</p>"},{"location":"reference/migration_guide.html","title":"Migration: PMM DBaaS to Percona Everest","text":"<p>Migrating from Percona Monitoring and Management (PMM) DBaaS to Percona Everest has many benefits, such as decreased operational overhead, improved scalability, and enhanced flexibility. However, planning and executing the migration is crucial to minimize downtime and ensure data integrity. </p> <p>Here\u2019s a comprehensive guide to help you through the process.</p>"},{"location":"reference/migration_guide.html#before-you-migrate","title":"Before you migrate","text":"<p>Here are some key differences between Percona Everest and PMM DBaaS:</p> <ol> <li> <p>Percona Everest has a separate and configurable namespace for running operators and database clusters, whereas PMM/DBaaS uses a default namespace.</p> </li> <li> <p>Percona <code>everestctl</code> is a tool that helps you install and configure operators and monitoring features, whereas this function was previously handled by PMM.</p> </li> <li> <p>Percona Everest has revamped its backup/restore feature, which means that old backups/restores cannot be used.</p> </li> </ol>"},{"location":"reference/migration_guide.html#prerequisites","title":"Prerequisites","text":"<p>Before getting started with Percona Everest:</p> <ol> <li> <p>Install Docker Engine (1.13.0 and higher) with the Docker compose plugin.</p> </li> <li> <p>Install curl.</p> </li> <li> <p>Install jq.</p> </li> <li> <p>Set up a publicly accessible Kubernetes cluster. </p> <p>Percona Everest assists with installing all the necessary operators and required packages, but does not currently help with spinning up a publicly accessible Kubernetes cluster.</p> <p>We recommend setting up Percona Everest on the Amazon Elastic Kubernetes Service (EKS) or Google Kubernetes Engine (GKE), as Percona Everest may not work as expected on local Kubernetes installations (minikube, kind, k3d, or similar products) due to network issues.</p> <p>Create EKS cluster  Create GKE cluster </p> </li> <li> <p>Verify that you have access to the Kubernetes cluster that you want to use with Percona Everest. By default, Percona Everest uses the kubeconfig file available under <code>~/.kube/config</code>. </p> <p>To verify access to the Kubernetes cluster, run:</p> <pre><code>kubectl get nodes\n</code></pre> Expected output <pre><code>NAME                                    STATUS   ROLES    AGE   VERSION\ngke-&lt;name&gt;-default-pool-75d48bfc-bx8g   Ready    &lt;none&gt;   11h   v1.26.7-gke.500\ngke-&lt;name&gt;-default-pool-75d48bfc-c2df   Ready    &lt;none&gt;   11h   v1.26.7-gke.500\ngke-&lt;name&gt;-default-pool-75d48bfc-zl7k   Ready    &lt;none&gt;   11h   v1.26.7-gke.500\n</code></pre> </li> </ol>"},{"location":"reference/migration_guide.html#migration-procedure","title":"Migration procedure","text":"<p>To migrate from PMM DBaaS to Percona Everest:</p> <ol> <li>Install Everest.</li> <li> <p>Migrate backup storages from PMM to Percona Everest:</p> <ul> <li>Log in to the PMM UI and navigate to the Backup &gt; Storage Locations section. The Storage Location page opens. You can see the storage locations configured on this page.</li> <li>Click the downward arrow to see the details of the storage location that are configured.</li> <li>Log in to Percona Everest and go to the Backup Storages section on the UI.</li> <li>Copy-paste the values from the details on the configured storage locations in PMM and paste it to Add backup storage page in Percona Everest.</li> </ul> </li> <li> <p>Migrate secrets for database clusters from one Kubernetes cluster to a new cluster using the pattern <code>everest-secrets-dbclusterName</code>. </p> <p>Example:</p> <pre><code>export DBNAME=mysql-btknhj\nexport DBTYPE=pxc\n</code></pre> <p>Note</p> <p>The DBTYPE can be <code>pxc</code> or <code>psmdb</code> depending on whether it is a MySQL or MongoDB database.</p> <p>Get the secret from the kubernetes cluster registered in PMM:</p> <pre><code>kubectl get secret \"dbaas-$DBNAME-$DBTYPE-secrets\" -o yaml | sed \"s/name: dbaas-$DBNAME-.*-\nsecrets/name: everest-secrets-$DBNAME/\" | sed \"s/namespace: default/namespace: percona-everest/\" &gt; \nsecret.yaml\n</code></pre> <p>Apply the secret in the kubernetes cluster registered in Everest:</p> <pre><code>kubectl apply -f secret.yaml\n</code></pre> <p>Note</p> <p>Keep the naming consistent across the two Kubernetes clusters.</p> </li> <li> <p>Create a new database cluster using the webUI. Run through the creation wizard to select resources, set the name, and configure the backup storage and monitoring of the cluster.</p> </li> <li> <p>Restore data for your database clusters using the operator\u2019s backup and restore features.</p> <p>Note</p> <ul> <li> <p>The restoration won\u2019t be available for you in the web UI, you\u2019ll need to refer to the corresponding operator\u2019s documentation for instructions on how to do this.</p> <ul> <li>For PXC</li> <li>For PSMDB</li> <li>For PostgreSQL</li> </ul> </li> <li> <p>Each time you run a database cluster, repeat this step.</p> </li> </ul> </li> <li> <p>Disable the DBaaS feature in PMM by navigating to  Configuration \u2192  Settings \u2192 Advanced Settings on the PMM UI and toggling  the Database as a Service (DBaaS) option located in the Technical preview features section.</p> </li> </ol>"},{"location":"reference/migration_guide.html#whats-next","title":"What\u2019s next","text":"<p>After the migration, you can connect to the new database cluster to check if the data has been successfully migrated.</p>"},{"location":"reference/postgresql12_migration.html","title":"Migrate from PostgreSQL 12","text":"<p>Important</p> <p>Percona Everest 1.6.0 has officially discontinued support for PostgreSQL 12. To ensure compatibility, security, and access to new features, it is highly recommended to migrate to PostgreSQL 13 or later.</p>"},{"location":"reference/postgresql12_migration.html#preparation-before-migration","title":"Preparation before migration","text":"<p>Before migrating from PostgreSQL 12, it\u2019s important to prepare thoroughly to ensure a smooth transition. Here are the key steps:</p> <ol> <li> <p>Backup your data - Create a complete backup of your data before upgrading.</p> </li> <li> <p>Select a target version - Choose the PostgreSQL version you want to migrate to (e.g., 15 or 16). Select a stable, supported release compatible with Percona Everest\u2019s infrastructure requirements.</p> </li> <li> <p>Check Compatibility - Verify that your configurations are compatible with the new PostgreSQL version.</p> </li> <li> <p>Provision a new PostgreSQL database in Percona Everest \u2013 Use Percona Everest to deploy a new database with the desired PostgreSQL version.</p> </li> </ol>"},{"location":"reference/postgresql12_migration.html#choose-a-migration-option","title":"Choose a migration option","text":"<p>When upgrading from PostgreSQL 12, it is essential to choose a migration method that suits your environment. For a smooth transition, consider the following factors during migration:</p> <ul> <li> <p>Data size</p> </li> <li> <p>Downtime tolerance</p> </li> </ul> <p>PostgreSQL offers several migration options. Each method has its own benefits and trade-offs in terms of speed, complexity, and risk.</p> <p>Review PostgreSQL documentation to select the best option for your environment.</p> <p>\ud83d\udca1 Need assistance? Connect with Percona Everest community! </p> <p>Alternatively, you can always Talk to a Percona Expert.</p>  Expand for a detailed comparison between <code>logical dump and restore</code> vs <code>logical replication</code> Logical ReplicationLogical dump and restore <p>This option is recommended for minimal downtime.</p> <p>Use logical replication to continuously replicate data from your PostgreSQL 12 cluster into a PostgresQLG 13+ cluster with little to no downtime.</p> <p>\ud83d\udcda Learn more</p> <ul> <li>PostgreSQL documentation on logical replication.</li> </ul> <p>This option is recommended for smaller databases and one-time migrations.</p> <ol> <li> <p>Provision a new PostgreSQl database in Percona Everest.</p> </li> <li> <p>Perform a logical dump of the old database:</p> <ul> <li> <p>Use pg_dump or pg_dumpall to export your data from PostgreSQL 12.</p> Example: Source database (PostgreSQL 12) <p>Run the following command on the source database (PostgreSQL 12):</p> <pre><code>pg_dump -Fc -h &lt;old-db-host&gt; -U &lt;user&gt; &lt;db_name&gt; -f dump_file.dump\n</code></pre> </li> </ul> </li> <li> <p>Restore data to the new Percona Everest database:</p> <ul> <li> <p>Use pg_restore or psql to import data into the newly created Percona Everest cluster.</p> Example: Target database <p>Run the following command on the target PostgreSQL database:</p> <pre><code>pg_restore -U your_user -h new_db_host -d new_db_name -F c dump_file.dump\n</code></pre> </li> </ul> </li> <li> <p>Verify post-migration performance:</p> <ul> <li>Run queries to confirm data integrity and ensure compatibility.</li> </ul> </li> </ol> <p>\ud83d\udcda Reference</p> <ul> <li>PostgreSQL pg_dump documentation</li> <li>PostgreSQL pg_restore documentation</li> </ul>"},{"location":"reference/postgresql12_migration.html#logical-dump-and-restore-vs-logical-replication","title":"Logical dump and restore vs. Logical replication","text":"<p>Two commonly used approaches to migrating a PostgreSQL database are Logical Dump and Restore and Logical Replication. Both methods help move data from one instance to another, but they have different purposes and distinct advantages.</p> Feature Logical dump and restore Logical replication Setup complexity Simple and portable More complex, involves replication slots Best suited for One-time migrations, backups, and moving datasets across versions Continuous data synchronization Downtime Impact Requires application downtime during migration Minimal downtime Primary Keys requirement No primary keys required; exports full table data regardless of constraints Requires primary keys (or unique indexes) on tables Schema compatibility Allows schema modifications before restoration; supports cross-version migration Requires schema compatibility between source and target databases Performance Can be slow for large datasets due to full export/import More efficient for continuous updates, but may add replication overhead"},{"location":"reference/telemetry.html","title":"Telemetry on Percona Everest","text":"<p>In creating Percona Everest, we leveraged our years of experience in open-source database development, and collaborated closely with the Percona community through interviews to ensure our new product will meet your needs.</p> <p>Product telemetry fills-in the gaps in our understanding of how you are actually using Everest, to help us build the best-in-class cloud-native database platform for the open-source community.</p> <p>Participation in this anonymous program is optional, and you can opt-out if you prefer not to share any information. Read our privacy statement to learn more.</p>"},{"location":"reference/telemetry.html#what-information-is-collected","title":"What information is collected","text":"<p>Currently, Everest only collects information about the database technology used (MySQL, Mongo, PostgreSQL). Future releases will cover additional metrics.</p> <p>Rest assured, access to the raw data is rigorously controlled, and individual user identification within the dataset is impossible. The data is thoroughly anonymized and cannot be traced back to any specific user.</p>"},{"location":"reference/telemetry.html#disable-telemetry","title":"Disable telemetry","text":"<p>Starting with Everest 0.4.1, telemetry is enabled by default. If you don\u2019t want to send usage data to Percona, you can set the DISABLE_TELEMETRY environment variable to TRUE:</p> <p>To disable telemetry run:</p> <pre><code>kubectl -n everest-system patch deployment percona-everest --type strategic -p 'spec:\n  strategy:\n    rollingUpdate:\n      maxSurge: 0\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    spec:\n      containers:\n        - name: everest\n          env:\n          - name: DISABLE_TELEMETRY\n            value: \"true\"'\n</code></pre>"},{"location":"reference/telemetry.html#enable-telemetry","title":"Enable telemetry","text":"<p>If you want to enable telemetry again:</p> <pre><code>kubectl -n everest-system patch deployment percona-everest --type strategic -p 'spec:\n  strategy:\n    rollingUpdate:\n      maxSurge: 0\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    spec:\n      containers:\n        - name: everest\n          env:\n          - name: DISABLE_TELEMETRY\n            value: \"false\"'\n</code></pre>"},{"location":"reference/trademark-policy.html","title":"Trademark policy","text":"<p>This Trademark Policy is to ensure that users of Percona-branded products or services know that what they receive has really been developed, approved, tested and maintained by Percona. Trademarks help to prevent confusion in the marketplace, by distinguishing one company\u2019s or person\u2019s products and services from another\u2019s.</p> <p>Percona owns a number of marks, including but not limited to Percona, XtraDB, Percona XtraDB, XtraBackup, Percona XtraBackup, Percona Server, and Percona Live, plus the distinctive visual icons and logos associated with these marks. Both the unregistered and registered marks of Percona are protected.</p> <p>Use of any Percona trademark in the name, URL, or other identifying characteristic of any product, service, website, or other use is not permitted without Percona\u2019s written permission with the following three limited exceptions.</p> <p>First, you may use the appropriate Percona mark when making a nominative fair use reference to a bona fide Percona product.</p> <p>Second, when Percona has released a product under a version of the GNU General Public License (\u201cGPL\u201d), you may use the appropriate Percona mark when distributing a verbatim copy of that product in accordance with the terms and conditions of the GPL.</p> <p>Third, you may use the appropriate Percona mark to refer to a distribution of GPL-released Percona software that has been modified with minor changes for the sole purpose of allowing the software to operate on an operating system or hardware platform for which Percona has not yet released the software, provided that those third party changes do not affect the behavior, functionality, features, design or performance of the software. Users who acquire this Percona-branded software receive substantially exact implementations of the Percona software.</p> <p>Percona reserves the right to revoke this authorization at any time in its sole discretion. For example, if Percona believes that your modification is beyond the scope of the limited license granted in this Policy or that your use of the Percona mark is detrimental to Percona, Percona will revoke this authorization. Upon revocation, you must immediately cease using the applicable Percona mark. If you do not immediately cease using the Percona mark upon revocation, Percona may take action to protect its rights and interests in the Percona mark. Percona does not grant any license to use any Percona mark for any other modified versions of Percona software; such use will require our prior written permission.</p> <p>Neither trademark law nor any of the exceptions set forth in this Trademark Policy permit you to truncate, modify or otherwise use any Percona mark as part of your own brand. For example, if XYZ creates a modified version of the Percona Server, XYZ may not brand that modification as \u201cXYZ Percona Server\u201d or \u201cPercona XYZ Server\u201d, even if that modification otherwise complies with the third exception noted above.</p> <p>In all cases, you must comply with applicable law, the underlying license, and this Trademark Policy, as amended from time to time. For instance, any mention of Percona trademarks should include the full trademarked name, with proper spelling and capitalization, along with attribution of ownership to Percona Inc. For example, the full proper name for XtraBackup is Percona XtraBackup. However, it is acceptable to omit the word \u201cPercona\u201d for brevity on the second and subsequent uses, where such omission does not cause confusion.</p> <p>In the event of doubt as to any of the conditions or exceptions outlined in this Trademark Policy, please contact trademarks@percona.com for assistance and we will do our very best to be helpful.</p>"},{"location":"release-notes/Percona%20Everest%200.9.1%20%282024-04-02%29.html","title":"What\u2019s new in Percona Everest 0.9.1","text":"<p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p> <p>Percona Everest is an open source cloud native database platform that helps developers deploy code faster, scale deployments rapidly, and reduce database administration overhead. Plus, you can regain control over your data, database configuration, and DBaaS costs.</p> <p>Version 0.9.1 introduces the following changes:</p>"},{"location":"release-notes/Percona%20Everest%200.9.1%20%282024-04-02%29.html#release-highlights","title":"Release highlights","text":"<p>Warning</p> <p>Percona Everest introduces a breaking change that prevents you from directly upgrading to version 0.9.1.</p> <p>To install Percona Everest 0.9.1, make sure to uninstall any previous versions by running the command:</p> <pre><code>everestctl uninstall\n</code></pre>"},{"location":"release-notes/Percona%20Everest%200.9.1%20%282024-04-02%29.html#fixed-issues","title":"Fixed issues","text":"<ul> <li>EVEREST-949 - We have updated the quick install script to correct the URL for downloading the CLI (<code>everestctl</code>). Previously, the script failed because of an incorrect URL.</li> </ul>"},{"location":"release-notes/Percona-Everest-0.10.0-%282024-05-03%29.html","title":"What\u2019s new in Percona Everest 0.10.0","text":"<p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p> <p>Percona Everest is an open source cloud native database platform that helps provision and manage databases faster, scale deployments rapidly, and reduce database administration overhead. Plus, you can regain control over your data, database configuration, and DBaaS costs.</p> <p>Version 0.10.0 introduces the following changes:</p>"},{"location":"release-notes/Percona-Everest-0.10.0-%282024-05-03%29.html#release-highlights","title":"Release highlights","text":""},{"location":"release-notes/Percona-Everest-0.10.0-%282024-05-03%29.html#simplified-percona-everest-upgrades","title":"Simplified Percona Everest upgrades","text":"<p>Important</p> <ul> <li>You need to download CLI version &gt;=0.10.0 for the upgrade command to work.</li> <li>Upgrade works only if you have Percona Everest version 0.9.0 or higher installed. </li> </ul> <p>We\u2019re thrilled to announce that you can now upgrade your Percona Everest instance using our Command Line Interface (CLI). The CLI upgrade process is simple and straightforward, enabling you to quickly upgrade your Everest to the latest version.</p> <p>You can only upgrade one minor version at a time. For instance, you can upgrade from version 0.9.0 to version 0.10.0.</p> <p>For more information on upgrading Percona Everest, see our documentation.</p>"},{"location":"release-notes/Percona-Everest-0.10.0-%282024-05-03%29.html#streamlining-traffic-management-with-api-rate-limiting","title":"Streamlining traffic management with API rate limiting","text":"<p>Starting with Percona Everest 0.10.0 version, we have introduced a new feature called API rate limiting. </p> <p>API rate limiting is one of the key aspects of managing API\u2019s. With this you can set a threshold for the number of requests your API can receive within a specific period. This means you can take control and regulate the incoming traffic, mitigating the risk of server overload or abuse. </p> <p>The default rate limit for Percona Everest is 100 requests per second. However, you can customize these limits according to your usage patterns and requirements. To dive deep into this feature, see our comprehensive documentation.</p>"},{"location":"release-notes/Percona-Everest-0.10.0-%282024-05-03%29.html#added-control-for-tls-certificate-validation","title":"Added control for TLS certificate validation","text":"<p>With the release of Percona Everest 0.10.0, you can add backup storages and monitoring instances without verifying the Transport Layer Security (TLS) certificate. TLS certificate verifies the server\u2019s certificate chain and hostname, ensuring its authenticity.</p> <p>When using a self-signed TLS certificate, the TLS certificate validation will fail as the certificate has not been issued by a trusted authority. To overcome this issue, you may need to skip the TLS certificate validation. </p> <p>Skipping certificate validation is recommended only when there is no need to ensure the authenticity of the server holding the certificate. For example, if you have a private network where you have complete control over everything, the identity check may not be required.</p> <p></p>"},{"location":"release-notes/Percona-Everest-0.10.0-%282024-05-03%29.html#new-features-and-improvements","title":"New features and improvements","text":"<ul> <li> <p>EVEREST-793 - Starting with Percona Everest 0.10.0, you can upgrade your Percona Everest instance using the CLI (everestctl).</p> </li> <li> <p>EVEREST-396 - You can now add monitoring instances without verifying the TLS certificates. </p> </li> <li> <p>EVEREST-964 - Starting with Percona Everest 0.10.0, we have introduced a new feature called API rate limiting. With this you can set a threshold for the number of requests your API can receive within a specific period.</p> </li> <li> <p>EVEREST-935 - Previously, the cancel button was disabled while editing anything in the wizard. This button is now enabled.</p> </li> <li> <p>EVEREST-928 - We have updated all the labels on the buttons to sentence case for consistency.</p> </li> <li> <p>EVEREST-938 - Restoring a database using PITR now includes a backup storage name.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-0.10.0-%282024-05-03%29.html#backups","title":"Backups","text":"<ul> <li> <p>EVEREST-895 - You can now add backup storage without verifying the TLS certificates.</p> </li> <li> <p>EVEREST-919 - You can now access backup storage with path-style URLs.</p> </li> <li> <p>EVEREST-668 - We have introduced Retention copies while creating backup schedules. Retention copies refer to the number of backup instances that should be kept.</p> </li> <li> <p>EVEREST-819 - Due to the current limitation of PostgreSQL, you can only create up to 3 schedules. To avoid confusion, we have added a tooltip that states this limitation.</p> </li> <li> <p>EVEREST-911 - We added a new column to the database view displaying the time of the last backup.</p> </li> <li> <p>EVEREST-912 - We have added an icon and tooltip to the backups column.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-0.10.0-%282024-05-03%29.html#bugs-fixed","title":"Bugs fixed","text":"<ul> <li> <p>EVEREST-385 - Previously, there was an issue where the backup and pods associated with a database cluster were not being deleted when the cluster itself was deleted. The issue has been resolved now.</p> </li> <li> <p>EVEREST-846 - Fixed an issue where the new database contained the backups of the old database with the same name.</p> </li> <li> <p>EVEREST-921 - We have resolved an issue that prevented users from logging in immediately after logging out.</p> </li> <li> <p>EVEREST-947 - While attempting to uninstall Percona Everest, an error occurred which prevented the uninstallation process from completing successfully. The issue has now been resolved.</p> </li> <li> <p>EVEREST-948 - The actionable Alert button was not visible in the dark theme. The issue has been resolved now.</p> </li> <li> <p>EVEREST-967 - Fixed an issue where the last backup information was inaccurate.</p> </li> <li> <p>EVEREST-940 - The documentation link on Point-in-time recovery option for PostgreSQL was opening in the same tab. The issue has been resolved now.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-0.10.1-%282024-05-23%29.html","title":"What\u2019s new in Percona Everest 0.10.1","text":"<p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p> <p>Percona Everest is an open source cloud native database platform that helps provision and manage databases faster, scale deployments rapidly, and reduce database administration overhead. Plus, you can regain control over your data, database configuration, and DBaaS costs.</p> <p>Version 0.10.1 introduces the following changes:</p>"},{"location":"release-notes/Percona-Everest-0.10.1-%282024-05-23%29.html#fixed-issues","title":"Fixed issues","text":""},{"location":"release-notes/Percona-Everest-0.10.1-%282024-05-23%29.html#backups","title":"Backups","text":"<ul> <li>EVEREST-1061 - We fixed a race condition in the Everest operator where backups deleted due to retention policies were re-created. We fixed the issue and ensured that completed backups were not reconciled.</li> <li>EVEREST-1064 - While configuring a backup schedule for the MongoDB cluster, duplicate backups of the same data were generated in S3, whereas only a single backup was produced in Everest. The issue has been resolved now.</li> </ul>"},{"location":"release-notes/Percona-Everest-0.10.1-%282024-05-23%29.html#restores","title":"Restores","text":"<ul> <li> <p>EVEREST-1082 - Attempting to restore a MongoDB backup to a new database failed if the backup storage used a self-signed certificate. This issue has been resolved now.</p> </li> <li> <p>EVEREST-1054 - While restoring a PostgreSQL database cluster, we encountered an issue connecting to an S3-compatible bucket with a self-signed certificate. This problem caused the restored cluster to become unresponsive and enter an unknown state. The issue has been resolved now.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-0.10.1-%282024-05-23%29.html#retention-copies","title":"Retention copies","text":"<ul> <li>EVEREST-979 - When the retention were specified\u00a0in a backup schedule, the Everest operator successfully deleted the backup objects from Kubernetes. However, it failed to clean up the data on S3. This issue has been resolved now.</li> </ul>"},{"location":"release-notes/Percona-Everest-0.10.1-%282024-05-23%29.html#known-limitations","title":"Known limitations","text":"<p>Backups for PostgreSQL do not work with GCP S3 compatible API.</p>"},{"location":"release-notes/Percona-Everest-0.4.0-%282023-10-30%29.html","title":"What\u2019s new in Percona Everest 0.4.0","text":"<p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p> <p>Percona Everest is an open source private database-as-a-service that helps developers deploy code faster, scale deployments rapidly, and reduce database administration overhead. Plus, you can regain control over your data, database configuration, and DBaaS costs.</p>"},{"location":"release-notes/Percona-Everest-0.4.0-%282023-10-30%29.html#release-highlights","title":"Release highlights","text":"<p>Version 0.4.0 introduces several exciting features, enhancements, and notable changes:</p>"},{"location":"release-notes/Percona-Everest-0.4.0-%282023-10-30%29.html#breaking-changes-in-everest-040","title":"Breaking changes in Everest 0.4.0","text":"<p>This release introduces major changes to the core structure of Everest. As a result, some 0.3.0 components are not compatible with Everest 0.4.0, and migrating from the previous version is not possible.</p> <p>Make sure to uninstall Everest and install it again using the Quick Installation script or the manual installation procedure.</p>"},{"location":"release-notes/Percona-Everest-0.4.0-%282023-10-30%29.html#scheduled-backups","title":"Scheduled backups","text":"<p>You can now schedule automatic backups to run automatically at predefined times.</p> <p>Automatic backups will repeat within the time frame given, ensuring you have a backlog of database snapshots to roll back to if needed.</p> <p>To set up a backup schedule, head over to the Backups tab in the database view. Here, you\u2019ll find the option to initiate a backup right away, or schedule one for later. </p> <p>Keep an eye out for future releases, as we\u2019ll soon enable backup scheduling from the database creation wizard as well.</p> <p>For more information about working with backups, see Back up and restore databases.</p> <p></p>"},{"location":"release-notes/Percona-Everest-0.4.0-%282023-10-30%29.html#option-to-provide-anonymous-usage-statistics-enabled","title":"Option to provide anonymous usage statistics enabled","text":"<p>In creating Percona Everest, we\u2019ve leveraged our years of experience in open-source database development, and collaborated closely with the Percona community through interviews to ensure our new product will meet user needs.</p> <p>With our latest release, we\u2019re adding in product telemetry to fill-in the gaps in our understanding of how users are actually using Everest, and ultimately ensure that we\u2019re building the best-in-class cloud-native database platform for the open-source community.</p> <p>Participation in this anonymous program is optional, and you can opt-out if prefer not to share any information.</p> <p>Read our privacy statement and telemetry documentation to learn more.</p>"},{"location":"release-notes/Percona-Everest-0.4.0-%282023-10-30%29.html#enhanced-ux-for-backup-creation","title":"Enhanced UX for backup creation","text":"<p>We\u2019ve optimized the backup creation process, providing you with the flexibility to access Settings and set up a storage location when none is configured yet. This ensures that you can quickly generate the resources you need right when creating on-demand and scheduled backups.</p>"},{"location":"release-notes/Percona-Everest-0.4.0-%282023-10-30%29.html#option-to-install-everest-on-kubernetes-experimental","title":"Option to install Everest on Kubernetes (experimental)","text":"<p>There\u2019s also a new manual installation option for setting up Everest on Kubernetes. </p> <p>This new installation option is currently in a technical preview stage, and we recommend using it solely for testing purposes! For a more secure and recommended installation process, make sure to install Everest using the Docker Compose procedure, either using the Quick-Install script or the manual installation procedure.</p>"},{"location":"release-notes/Percona-Everest-0.4.0-%282023-10-30%29.html#known-limitations","title":"Known limitations","text":"<p>Here are the limitations associated with this release. Some of them you might encounter depending on your settings, and some of them will be addressed in a future release: </p> <ul> <li>If you\u2019re using PostgreSQL, make sure not to share the same backup storage location for multiple database clusters. Use a unique storage location for backing up PostgreSQL clusters.</li> <li>The options to define default database configuration will be available on the Settings view soon.</li> <li>No support for database cluster management via CLI yet.</li> <li>No support for adding backup storages via CLI yet.</li> <li>No current support for K8s clusters without a public API server.</li> <li>No current support for adding monitoring instances via the UI. </li> <li>Information regarding Percona Monitoring Management (PMM) monitoring is not yet visible on the UI.</li> <li>No current support for using https for connecting to PMM instances that use a self-signed certificate.</li> <li>Information regarding CPU/Memory resources doesn\u2019t clearly state that is applied per replica and not per database cluster.</li> </ul>"},{"location":"release-notes/Percona-Everest-0.5.0-%282023-11-28%29.html","title":"What\u2019s new in Percona Everest 0.5.0","text":"<p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p> <p>Percona Everest is an open source private database-as-a-service that helps developers deploy code faster, scale deployments rapidly, and reduce database administration overhead. Plus, you can regain control over your data, database configuration, and DBaaS costs.</p>"},{"location":"release-notes/Percona-Everest-0.5.0-%282023-11-28%29.html#release-highlights","title":"Release highlights","text":"<p>Version 0.5.0 introduces the following enhancements:</p>"},{"location":"release-notes/Percona-Everest-0.5.0-%282023-11-28%29.html#enhanced-installation-robustness","title":"Enhanced installation robustness","text":"<p>This Everest release streamlines the installation workflow by transitioning from Docker Compose to Kubernetes, for easier and more robust deployments. </p> <p>Previously confined to Docker containers through Docker Compose, Everest now operates directly within the Kubernetes cluster.  This eliminates complexities and restrictions associated with running Everest outside the K8 cluster. Consequently, Everest works not only on public K8 clusters but also on private ones, enhancing its accessibility and adaptability.</p> <p>To install Everest 0.5.0, check the updated installation procedure.</p>"},{"location":"release-notes/Percona-Everest-0.5.0-%282023-11-28%29.html#enhanced-backup-scheduling","title":"Enhanced Backup scheduling","text":"<p>Previously exclusively available from the Backups tab within the database view, backup scheduling is now seamlessly integrated into the database creation wizard as an added step.</p> <p>This completes the Backup Scheduling functionality and enables you to define a comprehensive setup for your new database from the get-go.</p> <p></p>"},{"location":"release-notes/Percona-Everest-0.5.0-%282023-11-28%29.html#option-to-copy-database-password","title":"Option to copy database password","text":"<p>We\u2019ve added a convenient way to copy database passwords. Since clipboard access is restricted in unsecured contexts, this option is only enabled when you access these pages via HTTPS or localhost.</p> Database cluster list Database cluster Overview page"},{"location":"release-notes/Percona-Everest-0.5.0-%282023-11-28%29.html#option-to-check-everest-version","title":"Option to check Everest version","text":"<p>You may notice there\u2019s now a Help icon in the upper right corner. It\u2019s a handy way to access the online Help and swiftly verify the current Everest version you\u2019re using.</p> <p></p>"},{"location":"release-notes/Percona-Everest-0.5.0-%282023-11-28%29.html#fixed-issue","title":"Fixed issue","text":"<p>In specific scenarios, when creating a new database, Everest would reset the specified database name, version, and storage class to automatically generated values. This issue is now fixed.</p>"},{"location":"release-notes/Percona-Everest-0.6.0-%282024-01-11%29.html","title":"What\u2019s new in Percona Everest 0.6.0","text":"<p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p> <p>Percona Everest is an open source private database-as-a-service that helps developers deploy code faster, scale deployments rapidly, and reduce database administration overhead. Plus, you can regain control over your data, database configuration, and DBaaS costs.</p>"},{"location":"release-notes/Percona-Everest-0.6.0-%282024-01-11%29.html#release-highlights","title":"Release highlights","text":"<p>Version 0.6.0 introduces the following enhancements:</p>"},{"location":"release-notes/Percona-Everest-0.6.0-%282024-01-11%29.html#point-in-time-recovery-pitr-for-finer-backup-granularity","title":"Point-in-Time Recovery (PITR) for finer backup granularity","text":"<p>In addition to on-demand and scheduled backups, Everest now also offers PITR functionality to restore databases from past timestamps on the same cluster.</p> <p>PITR works by constantly backing up your database transaction logs following an initial full backup of the database. This enables you to:</p> <ul> <li>Handle incorrect database writes by rolling back the database to a state before the error occurred</li> <li>Minimize the potential for data loss by enabling very specific recovery points  </li> <li>Fulfill historical data auditing requirements to comply with laws and regulations</li> </ul> <p>For now, PITR is only available for MySQL databases. Future releases will enable this functionality for MongoDB and PostgreSQL databases as well.</p> <p>To get started, enable the new PITR option on the database creation wizard:</p> <p></p> <p>For more information about working with PITR backups, see Enable Point-in-time Recovery.</p>"},{"location":"release-notes/Percona-Everest-0.6.0-%282024-01-11%29.html#secure-access-through-user-authentication","title":"Secure access through user authentication","text":"<p>We have taken a significant step towards ensuring the security of Percona Everest by introducing user authentication in our latest release. This feature is designed to restrict access to the databases hosted on Percona Everest, thereby safeguarding any sensitive information stored within them. With user authentication in place, only authorized users will be able to access the databases.</p> <p>If you\u2019re looking to dive deep into this feature, see our comprehensive documentation.</p>"},{"location":"release-notes/Percona-Everest-0.6.0-%282024-01-11%29.html#dark-mode","title":"Dark mode","text":"<p>We are excited to announce that the latest version of Percona Everest 0.6.0 introduces a new feature called Dark Mode. This feature enables you to switch the color scheme of the Percona Everest user interface from a predominantly light or white background to a predominantly dark one. </p> <p>Dark Mode gives you a more comfortable and easy-on-the-eyes visual experience while navigating through Percona Everest. To use this feature, simply toggle it on or off from the UI. Once enabled, the color palette of the user interface changes to a darker shade, enhancing the overall user experience.</p>"},{"location":"release-notes/Percona-Everest-0.6.0-%282024-01-11%29.html#enhanced-user-experience-for-database-restoration-from-backups","title":"Enhanced user experience for database restoration from backups","text":"<p>When restoring a backup to a new database, you no longer need to manually confirm that you\u2019re using the same secret as the selected backup. Everest now seamlessly handles this verification in the background.</p>"},{"location":"release-notes/Percona-Everest-0.7.0-%282024-01-31%29.html","title":"What\u2019s new in Percona Everest 0.7.0","text":"<p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p> <p>Percona Everest is an open source private database-as-a-service that helps developers deploy code faster, scale deployments rapidly, and reduce database administration overhead. Plus, you can regain control over your data, database configuration, and DBaaS costs.</p> <p>Version 0.7.0 introduces the following changes:</p>"},{"location":"release-notes/Percona-Everest-0.7.0-%282024-01-31%29.html#point-in-time-recovery-pitr-for-mongodb-databases","title":"Point-in-Time Recovery (PITR) for MongoDB databases","text":"<p>We\u2019re expanding Percona Everest\u2019s PITR capabilities to include MongoDB databases.</p> <p>You can now also restore MongoDB databases to specific points in time within the same cluster. This gives you more control over your MongoDB environments and more options for data recovery.</p> <p>Future releases will cover PITR support for PostgreSQL databases and PITR restores to different clusters.</p> <p></p>"},{"location":"release-notes/Percona-Everest-0.7.0-%282024-01-31%29.html#post-restore-step-for-mongodb","title":"Post-Restore step for MongoDB","text":"<p>PITR restores alter the timeline of MongoDB oplog events. As a result, MongoDB oplog slices created after the restore timestamp and before the last backup become invalid.</p> <p>To seamlessly resume PITR after a restore, make sure to run a new full backup. This new backup will serve as the starting point for oplog updates, ensuring the continuity and integrity of your data.</p>"},{"location":"release-notes/Percona-Everest-0.7.0-%282024-01-31%29.html#monitoring","title":"Monitoring","text":"<p>Percona Everest now comes with monitoring capabilities that will help ensure your database infrastructure is always reliable and secure. </p> <p>Here\u2019s what you\u2019ll get out of Percona Everest monitoring:</p> <ul> <li>Database availability and uptime tracking</li> <li>Insights into your database performance</li> <li>Proactive issue detection and addressing opportunities</li> <li>Continuous monitoring</li> </ul> <p></p> <p>If you\u2019re looking for in-depth insights into this feature, refer to our comprehensive documentation.</p>"},{"location":"release-notes/Percona-Everest-0.8.0-%282024-02-22%29.html","title":"What\u2019s new in Percona Everest 0.8.0","text":"<p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p> <p>Percona Everest is an open source cloud native database platform that helps developers deploy code faster, scale deployments rapidly, and reduce database administration overhead. Plus, you can regain control over your data, database configuration, and DBaaS costs.</p> <p>Version 0.8.0 introduces the following changes:</p>"},{"location":"release-notes/Percona-Everest-0.8.0-%282024-02-22%29.html#beta-release","title":"Beta release","text":"<p>We\u2019re excited to announce that Percona Everest is now in Beta!</p> <p>Under development for the past six months and in testing since October 2023, we\u2019re now taking Percona Everest public, making it open for anyone who wants to explore our Cloud Native database platform.</p> <p>Be an early adopter and join us in driving its progress!</p>"},{"location":"release-notes/Percona-Everest-0.8.0-%282024-02-22%29.html#release-highlights","title":"Release highlights","text":""},{"location":"release-notes/Percona-Everest-0.8.0-%282024-02-22%29.html#breaking-change-in-percona-everest-080","title":"Breaking change in Percona Everest 0.8.0","text":"<p>Warning</p> <p>Percona Everest introduces a breaking change that prevents you from directly upgrading to version 0.8.0.</p> <p>Before installing Percona Everest version 0.8.0, make sure to remove any previous version from your system. After uninstalling the previous version, you can install Percona Everest 0.8.0 using the Quick Installation script or the manual installation procedure.</p> <p>To uninstall the previous version of Percona Everest:</p> <ol> <li> <p>Identify the namespace:</p> <pre><code>export EVEREST_NS=percona-everest\n</code></pre> </li> <li> <p>Uninstall Everest:</p> <p>Important</p> <p>To uninstall Percona Everest, use the uninstall command with the old CLI binary.</p> <pre><code>everestctl uninstall\n</code></pre> </li> <li> <p>Remove ALL created database clusters:</p> <pre><code>kubectl delete db --all -n percona-everest\n</code></pre> </li> <li> <p>Remove ALL backups:</p> <pre><code>kubectl -n $EVEREST_NS delete job --all\nkubectl -n $EVEREST_NS delete pxc-backup --all\nkubectl -n $EVEREST_NS delete psmdb-backup --all\nkubectl -n $EVEREST_NS delete pg-backup --all\nkubectl -n $EVEREST_NS delete pod --all\n</code></pre> </li> <li> <p>Remove ALL PVCs:</p> <pre><code>kubectl delete pvc --all -n $EVEREST_NS\n</code></pre> </li> <li> <p>List CSVs and remove those with a percona and everest prefix, or remove ALL operators:</p> <pre><code>kubectl delete sub --all -n $EVEREST_NS\nkubectl delete ip --all -n $EVEREST_NS\nkubectl delete csv --all -n $EVEREST_NS\n</code></pre> </li> <li> <p>Remove Everest OLM catalog:</p> <pre><code>kubectl delete -f https://raw.githubusercontent.com/percona/percona-everest-cli/v0.7.0/data/crds/olm/percona-dbaas-catalog.yaml\n</code></pre> </li> <li> <p>Remove OLM installation (Do not delete it if it was installed without Everest support):</p> <pre><code>kubectl delete -f https://raw.githubusercontent.com/percona/percona-everest-cli/v0.7.0/data/crds/olm/crds.yaml\n</code></pre> <pre><code>kubectl delete -f https://raw.githubusercontent.com/percona/percona-everest-cli/v0.7.0/data/crds/olm/olm.yaml\n</code></pre> </li> <li> <p>Remove <code>percona-everest</code> namespace:</p> <pre><code>kubectl delete ns $EVEREST_NS\n</code></pre> </li> </ol>"},{"location":"release-notes/Percona-Everest-0.8.0-%282024-02-22%29.html#multiple-namespaces","title":"Multiple namespaces","text":"<p>Starting with Percona Everest 0.8.0, we have introduced a new feature called Multiple namespaces. With this feature, you can create separate groups of resources within a single cluster. Namespaces enable you to partition your clusters logically, organizing and managing the resources effectively without impacting the other resources in the same cluster.</p> <p>To view the list of configured namespaces, navigate to  Settings &gt; Namespaces on the Percona Everest UI.</p> <p></p> <p>To gain a deeper understanding of this feature, refer to our comprehensive documentation.</p>"},{"location":"release-notes/Percona-Everest-0.8.0-%282024-02-22%29.html#support-for-scheduled-backups-for-postgresql","title":"Support for scheduled backups for PostgreSQL","text":"<p>We\u2019re expanding Percona Everest\u2019s schedule backup functionality to include PostgreSQL databases. This enables you to run automatic backups at predefined times for PostgreSQL as well.</p> <p></p> <p>However, due to a limitation on the PostgreSQL Operator, you cannot add more than three backup schedules for the PostgreSQL databases.</p>"},{"location":"release-notes/Percona-Everest-0.8.0-%282024-02-22%29.html#new-features-and-improvements","title":"New features and improvements","text":"<ul> <li> <p>EVEREST-509 - We\u2019ve completed support for Scheduled Backups functionality, extending automated backup capabilities to PostgreSQL databases as well.</p> </li> <li> <p>EVEREST-821 - We\u2019ve added a copy button next to the Host string on the Connection Details panel to enable you to copy the host string easily.</p> </li> <li> <p>EVEREST-748 - The PostgreSQL operator has been upgraded to version 2.3.1.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-0.8.0-%282024-02-22%29.html#bugs-fixed","title":"Bugs fixed","text":"<ul> <li>EVEREST-802 - When editing a MongoDB database, the Storage location field on the Backups page is now disabled to prevent changes to the current location. This limitation stems from a restriction in Everest, which currently restricts MongoDB databases to utilizing a single storage location for backups.</li> <li>EVEREST-814 - While reinstalling Percona Everest, the login token was not displayed. To log in to Percona Everest, the token from the previous installation had to be used. We have resolved the issue, and now uninstalling Percona Everest removes the token also, which means that a new token will be generated upon subsequent installation.</li> <li>EVEREST-827 - When trying to set up a fourth scheduled backup for PostgreSQL databases, Everest now notifies that initiating another backup is not possible when three backup schedules are already in place. This restriction is due to a current limitation on the PostgreSQL Operator, which does not allow more than three backup schedules for the PostgreSQL databases.</li> <li>EVEREST-822 - Fixed an issue that sometimes occurred when restoring a Postgresql database from a backup.</li> <li>EVEREST-826  - When initiating an on-demand backup for PostgreSQL databases, Everest would incorrectly perform incremental backups instead of conducting a full backup. This issue is now fixed.</li> <li>EVEREST-833 - When creating a new database from a backup, Everest now pre-fills the database version inherited from the backup artifact, ensuring consistency and compatibility throughout deployments.</li> <li>EVEREST-854 - Fixed an issue where the default number of nodes on the Resources page for MySQL showed up as 1 instead of 3. </li> </ul>"},{"location":"release-notes/Percona-Everest-0.8.0-%282024-02-22%29.html#known-issues","title":"Known issues","text":"<ul> <li>EVEREST-819 - Due to a limitation on the PostgreSQL Operator, you cannot add more than three backup schedules for the PostgreSQL databases.</li> <li>EVEREST-820 - When performing a MongoDB database restore from a Point-in-Time (PITR), the displayed time in the UI does not align with the actual PITR creation time due to discrepancies between the PITR chunk creation time and the time at which chunks are uploaded to the S3 storage location.</li> </ul>"},{"location":"release-notes/Percona-Everest-0.9.0-%282024-04-01%29.html","title":"What\u2019s new in Percona Everest 0.9.0","text":"<p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p> <p>Percona Everest is an open source cloud native database platform that helps developers deploy code faster, scale deployments rapidly, and reduce database administration overhead. Plus, you can regain control over your data, database configuration, and DBaaS costs.</p> <p>Version 0.9.0 introduces the following changes:</p>"},{"location":"release-notes/Percona-Everest-0.9.0-%282024-04-01%29.html#release-highlights","title":"Release highlights","text":""},{"location":"release-notes/Percona-Everest-0.9.0-%282024-04-01%29.html#breaking-change-in-percona-everest-090","title":"Breaking change in Percona Everest 0.9.0","text":"<p>Warning</p> <p>Percona Everest introduces a breaking change that prevents you from directly upgrading to version 0.9.0.</p> <p>To install Percona Everest 0.9.0, make sure to uninstall any previous versions by running the command:</p> <pre><code>everestctl uninstall\n</code></pre>"},{"location":"release-notes/Percona-Everest-0.9.0-%282024-04-01%29.html#enhanced-point-in-time-recovery-for-databases","title":"Enhanced point-in-time recovery for databases","text":"<p>We\u2019ve taken a step forward in enhancing Percona Everest\u2019s point-in-time (PITR) capabilities for PostgreSQL, MySQL as well as MongoDB databases. </p> <p>You can now restore your databases to specific points in time within the same cluster as well as a new cluster. This gives you more control over your database environments and more options for data recovery.</p> <p>If you\u2019re looking for in-depth insights into this feature, refer to the sections Create new database from a point-in-time recovery and Restore to a point-in-time recovery in our documentation.</p> <p></p> <p></p>"},{"location":"release-notes/Percona-Everest-0.9.0-%282024-04-01%29.html#new-features-and-improvements","title":"New features and improvements","text":"<ul> <li> <p>EVEREST-618, EVEREST-620 - Starting with Percona Everest 0.9.0, you can now create a new database using point-in-time recovery for your MySQL and MongoDB databases. If you\u2019re looking to explore this feature further, see our comprehensive documentation.</p> </li> <li> <p>EVEREST-914 - We have added a Kubernetes cluster ID to the VMAgent configuration, enabling you to use the same PMM instance to monitor multiple Kubernetes clusters.</p> </li> <li> <p>EVEREST-871 - We have improved Percona Everest to ensure you don\u2019t accidentally delete a cluster. We\u2019ve introduced a confirmation pop-up that will prompt you to enter the database\u2019s name correctly. Only when the correct database name is entered can you proceed with deleting the cluster.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-0.9.0-%282024-04-01%29.html#point-in-time-recovery-for-postgresql","title":"Point-in-time recovery for PostgreSQL","text":"<ul> <li> <p>EVEREST-598 - We have now added support for Point-In-Time Recovery (PITR) functionality for PostgreSQL databases.</p> </li> <li> <p>EVEREST-624 - We have added a message on the Percona Everest UI for PostgreSQL informing users that Point-in-time recovery (PITR) is enabled by default and cannot be turned off.</p> </li> <li> <p>EVEREST-619 - Starting with Percona Everest 0.9.0, you can now create a new database using point-in-time recovery for your PostgreSQL databases.</p> </li> <li> <p>EVEREST-896 - We have added a warning on the Percona Everest UI to inform users about the limitations of PostgreSQL for PITR. </p> </li> </ul>"},{"location":"release-notes/Percona-Everest-0.9.0-%282024-04-01%29.html#bugs-fixed","title":"Bugs fixed","text":"<ul> <li> <p>EVEREST-656 - While initiating a backup for MongoDB, the backup status was being displayed as unknown. The issue has been resolved now.</p> </li> <li> <p>EVEREST-759 - We have added an error message to the Percona Everest UI for scheduled backups, which reminds you to set a backup storage location before configuring backup schedules to avoid any hassles.</p> </li> <li> <p>EVEREST-786 - Fixed an issue where the PMM monitoring URL accepted incorrect credentials.</p> </li> <li> <p>EVEREST-813 - When choosing the appropriate cluster size (small, medium, large) on the Resources page, the selector invariably switched to the Custom option. The issue has been resolved now.</p> </li> <li> <p>EVEREST-856 - When editing a database with multiple backup schedules, an error was thrown. The issue has been resolved now.</p> </li> <li> <p>EVEREST-862 - We resolved an issue where the column hide/unhide option was not functioning correctly on various UI pages.</p> </li> <li> <p>EVEREST-885 - Fixed an issue where the Quick install script did not work on Linux machines with ARM CPUs.</p> </li> <li> <p>EVEREST-887 - Storage location could not be chosen if scheduled backups were enabled for the first time while editing a MongoDB database.</p> </li> <li> <p>EVEREST-888 - When creating a backup, the Backup storage field was not automatically populated as it was for scheduled backups. We have resolved this issue now.</p> </li> <li> <p>EVEREST-890 - We have fixed an issue that was causing problems with restoring data to a new MySQL database using point-in-time recovery (PITR).</p> </li> <li> <p>EVEREST-913 - We corrected the AWS load balancer type for the HAProxy replicas to use the network LB type when enabling external access to the DB cluster instead of the classic LB type.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-0.9.1-%282024-04-02%29.html","title":"What\u2019s new in Percona Everest 0.9.1","text":"<p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p> <p>Percona Everest is an open source cloud native database platform that helps developers deploy code faster, scale deployments rapidly, and reduce database administration overhead. Plus, you can regain control over your data, database configuration, and DBaaS costs.</p> <p>Version 0.9.1 introduces the following changes:</p>"},{"location":"release-notes/Percona-Everest-0.9.1-%282024-04-02%29.html#release-highlights","title":"Release highlights","text":"<p>Warning</p> <p>Percona Everest introduces a breaking change that prevents you from directly upgrading to version 0.9.1.</p> <p>To install Percona Everest 0.9.1, make sure to uninstall any previous versions by running the command:</p> <pre><code>everestctl uninstall\n</code></pre>"},{"location":"release-notes/Percona-Everest-0.9.1-%282024-04-02%29.html#fixed-issues","title":"Fixed issues","text":"<ul> <li>EVEREST-949 - We have updated the quick install script to correct the URL for downloading the CLI (<code>everestctl</code>). Previously, the script failed because of an incorrect URL.</li> </ul>"},{"location":"release-notes/Percona-Everest-1.0.0-%282024-06-28%29.html","title":"What\u2019s new in Percona Everest 1.0.0","text":"<p>Warning</p> <p>Google Container Registry (GCR) is scheduled to be deprecated and will officially shut down on March 18, 2025. All versions of Percona Everest prior to 1.4.0 depend on images hosted on GCR, meaning that downloading those images will fail after the shutdown date. We strongly recommend upgrading to Percona Everest version 1.4.0 as soon as possible. If you do not upgrade, Percona Everest will no longer function.</p> <p>For more details, refer to the Container Registry Deprecation documentation.</p> <p>We proudly announce that\u00a0Percona Everest has officially hit the general availability (GA) milestone with the release of version 1.0.0.</p> <p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p> <p>Percona Everest is an open source cloud native database platform that helps provision and manage databases faster, scale deployments rapidly, and reduce database administration overhead. Plus, you can regain control over your data, database configuration, and DBaaS costs.</p>"},{"location":"release-notes/Percona-Everest-1.0.0-%282024-06-28%29.html#upgrading-to-percona-everest-100","title":"Upgrading to Percona Everest 1.0.0","text":"<p>Important</p> <p>Despite being a major version upgrade, we fully support upgrading from Percona Everest 0.10.1 to 1.0.0.</p> <p>Check out our comprehensive documentation for all the details on how to upgrade to Percona Everest 1.0.0.</p>"},{"location":"release-notes/Percona-Everest-1.0.0-%282024-06-28%29.html#release-highlights","title":"Release highlights","text":"<p>Version 1.0.0 introduces the following changes:</p>"},{"location":"release-notes/Percona-Everest-1.0.0-%282024-06-28%29.html#simplified-database-operator-upgrades","title":"Simplified database operator upgrades","text":"<p>We are excited to announce that you can now upgrade database operators and all their components across any namespace with just a single click using our intuitive UI.</p> <p></p> <p>Moreover, before initiating the upgrade process, Everest provides a comprehensive list of tasks that must be completed to ensure a seamless transition of your clusters to the next version of the database operators.</p> <p></p> <p>For a deep dive into this feature, see our comprehensive documentation.</p>"},{"location":"release-notes/Percona-Everest-1.0.0-%282024-06-28%29.html#user-management","title":"User management","text":"<p>Percona Everest 1.0.0 introduces user management features, enabling you to securely log in to the platform through either the Percona Everest user interface or the API. So, get ready for a more secure and user-friendly experience with this update.</p> <p>Local user management involves administering Percona Everest users to ensure secure access to database resources. This encompasses tasks such as creating and deleting users, updating their passwords, etc.</p> <p>If you\u2019re looking for in-depth insights into this feature, see our documentation.</p>"},{"location":"release-notes/Percona-Everest-1.0.0-%282024-06-28%29.html#idp-integration-for-enhanced-security","title":"IdP integration for enhanced security","text":"<p>Starting with Percona Everest 1.0.0, you can now integrate your Percona Everest instance using an external identity provider (IdP). This enables centralized authentication and authorization management, streamlining and simplifying user access. By tapping into IdP integration, you can ensure that users are authenticated and authorized securely.</p> <p>Percona Everest uses OpenID Connect (OIDC) Protocol to integrate with external Identity Providers (IdP).</p> <p></p> <p>To integrate IdP with Percona Everest, first install Percona Everest and then configure OIDC on the IdP\u2019s side as well as the Percona Everest side.</p> <p>To explore the depths of this feature, delve into our documentation.</p>"},{"location":"release-notes/Percona-Everest-1.0.0-%282024-06-28%29.html#all-new-components-page","title":"All new components page","text":"<p>We\u2019re always striving to enhance user experience, and we\u2019re excited to announce our latest addition \u2013 the Components page! This new page is your go-to destination for in-depth details about the pods and containers, such as their status, type, age, and much more.</p> <p></p>"},{"location":"release-notes/Percona-Everest-1.0.0-%282024-06-28%29.html#new-features","title":"New features","text":"<ul> <li> <p>EVEREST-816 - Starting with Percona Everest 1.0.0, you can now upgrade database operators and all their components across any namespace with just a single click using our intuitive UI.</p> </li> <li> <p>EVEREST-1087 - You can now integrate your Percona Everest instance using an external identity provider (IdP). This enables centralized authentication and authorization management, streamlining and simplifying user access.</p> </li> <li> <p>EVEREST-1025 - We introduced the user management feature with Percona Everest 1.0.0, enabling you to securely log in to the platform through either the user interface or the API.</p> </li> <li> <p>EVEREST-974 - Everest now supports editing the DB Engine version after a cluster has been created. However, it\u2019s important to note the following restrictions:</p> <ul> <li>You are unable to upgrade to a different major version. </li> <li>Downgrading the DB Engine version is not supported.</li> </ul> </li> <li> <p>EVEREST-1069 - We\u2019ve recently introduced a new page - the components page. This page provides detailed information about the pods and containers, including their status, type, age, and more.</p> </li> <li> <p>EVEREST-866 - Starting with Percona Everest 1.0.0, you can restore your database from a full backup or using the PITR. However, if you choose a backup other than the latest backup, the PITR option becomes unavailable.</p> </li> <li> <p>EVEREST-872 - When deleting a backup, you can now choose to delete the data from the backup storage as well.</p> </li> <li> <p>EVEREST-873 - When attempting to delete a database, you now have the option to delete the data as well from the backup storage. However, for PostgreSQL databases, the backup storage data is retained.</p> </li> <li> <p>EVEREST-731 - Added support for customizing load balancer source ranges in PostgreSQL clusters.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.0.0-%282024-06-28%29.html#improvements","title":"Improvements","text":"<ul> <li> <p>EVEREST-909 - Percona Everest now validates scheduled backups if another backup is already scheduled for the same time and location.</p> </li> <li> <p>EVEREST-924 - Starting with Percona Everest 1.0.0, you now have the option to create multiple backup schedules using the wizard.</p> </li> <li> <p>EVEREST-931 - When you go through a wizard, return to a specific step, and delete something from a mandatory field, the editing functionality is now disabled.</p> </li> <li> <p>EVEREST-1055 - Starting with Percona Everest 1.0.0, we have introduced a new deleting state. This state will persist until all resources associated with the database have been removed.</p> </li> <li> <p>EVEREST-953 - For an improved user interface (UI) experience, we have consolidated backups and PITR on the same page.</p> </li> <li> <p>EVEREST-971 - Access and secret key inputs are now visible on the UI when adding a storage location. You can use the eye icon to toggle between making the keys visible or hidden. This feature allows you to conveniently view the S3 keys directly from the UI.</p> </li> <li> <p>EVEREST-1007 - For an improved user experience, the Actions button has been moved to the Database Details tab on the right side of the database name.</p> </li> <li> <p>EVEREST-937 - We have made some improvements in our telemetry, including sending telemetry data about the DB cluster every time a user creates one and adding information about the Everest version reported for the instance ID.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.0.0-%282024-06-28%29.html#bugs","title":"Bugs","text":"<ul> <li> <p>EVEREST-807 - Fixed an issue where PITR did not display the storage location being used when enabling PITR during database creation or editing.</p> </li> <li> <p>EVEREST-837 - We have now updated the help for the Command Line Interface (CLI) commands to include the descriptions.</p> </li> <li> <p>EVEREST-841 - Fixed an issue where the user interface (UI) could not identify the correct operator/database cluster for different namespaces.</p> </li> <li> <p>EVEREST-869 - Fixed an issue where <code>everestctl install</code> failed to revert to the default namespace when the namespace was left blank.</p> </li> <li> <p>EVEREST-870 - When running the <code>everestctl install</code> command, the installation wizard asked for values such as namespaces and operators, even though the values were already provided by flags <code>(--namespaces=everest --operator.mongodb=false --operator.postgresql=false --operator.xtradb-cluster=true)</code>. The issue has been resolved now.</p> </li> <li> <p>EVEREST-1003 - Resolved an issue where the installation of operators in a new namespace was failing.</p> </li> <li> <p>EVEREST-1016 - We updated the Last backup status from inactive to scheduled because it was confusing for the users.</p> </li> <li> <p>EVEREST-1034 - The Restores page did not display the restores in a sorted order. The issue has been resolved now.</p> </li> <li> <p>EVEREST-1050 - The information about the restores was not correctly updated on the restores page. The issue has been fixed now.</p> </li> <li> <p>EVEREST-1143 - Resolved an issue where <code>everestctl uninstall</code> command uninstalled Percona Everest despite the user selecting <code>no</code>.</p> </li> <li> <p>EVEREST-1145 - The issue with enabling external access to a DB running in EKS, where the provisioned LB was of the classic type instead of the required network type NLB, has been fixed.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.0.0-%282024-06-28%29.html#known-limitations","title":"Known limitations","text":"<p>Check out the known limitations section for in-depth details about the constraints of Percona Everest.</p>"},{"location":"release-notes/Percona-Everest-1.0.1-%282024-07-08%29.html","title":"What\u2019s new in Percona Everest 1.0.1","text":"<p>Warning</p> <p>Google Container Registry (GCR) is scheduled to be deprecated and will officially shut down on March 18, 2025. All versions of Percona Everest prior to 1.4.0 depend on images hosted on GCR, meaning that downloading those images will fail after the shutdown date. We strongly recommend upgrading to Percona Everest version 1.4.0 as soon as possible. If you do not upgrade, Percona Everest will no longer function.</p> <p>For more details, refer to the Container Registry Deprecation documentation.</p> <p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p> <p>Percona Everest is an open source cloud native database platform that helps provision and manage databases faster, scale deployments rapidly, and reduce database administration overhead. Plus, you can regain control over your data, database configuration, and DBaaS costs.</p> <p>Version 1.0.1 introduces the following changes:</p>"},{"location":"release-notes/Percona-Everest-1.0.1-%282024-07-08%29.html#fixed-issues","title":"Fixed issues","text":"<p>EVEREST-1231 - We\u2019ve addressed an issue that was causing our telemetry to be disabled.</p>"},{"location":"release-notes/Percona-Everest-1.1.0-%282024-08-12%29.html","title":"What\u2019s new in Percona Everest 1.1.0","text":"<p>Warning</p> <p>Google Container Registry (GCR) is scheduled to be deprecated and will officially shut down on March 18, 2025. All versions of Percona Everest prior to 1.4.0 depend on images hosted on GCR, meaning that downloading those images will fail after the shutdown date. We strongly recommend upgrading to Percona Everest version 1.4.0 as soon as possible. If you do not upgrade, Percona Everest will no longer function.</p> <p>For more details, refer to the Container Registry Deprecation documentation.</p> <p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p> <p>Percona Everest is an open source cloud native database platform that helps provision and manage databases faster, scale deployments rapidly, and reduce database administration overhead. Plus, you can regain control over your data, database configuration, and DBaaS costs.</p> <p>Version 1.1.0 introduces the following changes:</p>"},{"location":"release-notes/Percona-Everest-1.1.0-%282024-08-12%29.html#upgrade-instructions","title":"Upgrade instructions","text":"<p>Warning</p> <p>If you are using everestctl v1.1.0 or newer to upgrade from a version prior to v1.0.0, you need to execute the following command:</p> <pre><code>kubectl get deployments everest-operator-controller-manager -n everest-system -o jsonpath='{.spec.template.spec.containers[?(@.name==\"manager\")].env[?(@.name==\"DB_NAMESPACES\")].value}' | tr ',' '\\n' | xargs -I {} kubectl label namespaces {} app.kubernetes.io/managed-by=everest\n</code></pre>"},{"location":"release-notes/Percona-Everest-1.1.0-%282024-08-12%29.html#release-highlights","title":"Release highlights","text":"<p>Important</p> <p>Percona Everest 1.1.0 comes with its own set of limitations that you should be aware of.</p>"},{"location":"release-notes/Percona-Everest-1.1.0-%282024-08-12%29.html#enhancements-for-postgresql-disaster-recovery","title":"Enhancements for PostgreSQL disaster recovery","text":"<p>We\u2019ve made our backups and restores more reliable by setting limits on how we manage backup storage. This proactive approach ensures that we can prevent potential issues from being triggered in edge-case scenarios.</p> <p>Here\u2019s how it works:</p> <ul> <li> <p>You can have up to three backup storages in use at a time, across both on-demand backups and schedules.</p> Example <p>If you already have two scheduled backups using storage <code>bucket-1</code> and <code>bucket-2</code>, and an on-demand backup using <code>bucket-3</code>, you\u2019ll need to use one of these three storages for any new on-demand backup or schedule.</p> <p></p> <p></p> <p></p> </li> <li> <p>You can only create up to three backup schedules for PostgreSQL.</p> <p></p> </li> <li> <p>You cannot change the storage location in existing schedules.</p> </li> <li> <p>You cannot use the same storage location for multiple backup schedules.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.1.0-%282024-08-12%29.html#improvements","title":"Improvements","text":"<ul> <li> <p>EVEREST-1259 - We\u2019ve implemented a rate limiter to control how many API requests you can make within a set time frame. If you exceed this limit on the login page, you\u2019ll receive an error message.</p> </li> <li> <p>EVEREST-1134 \u2013Starting with Percona Everest 1.1.0, you can now upgrade the database version directly from the Namespaces page, skipping the need to use the edit DB wizard.</p> </li> <li> <p>EVEREST-1153 - We\u2019ve improved the CLI experience for install, upgrade, and uninstall commands by streamlining it with concise loading animations and spinners.</p> </li> <li> <p>EVEREST-1088 -  We\u2019ve removed the icons from the Technology column in the database list table.</p> </li> <li> <p>EVEREST-1196 - We\u2019ve added a confirmation dialog that appears when you try to exit the wizard using the side navigation.</p> </li> <li> <p>EVEREST-1070 - We\u2019ve updated the restore icon across Percona Everest for a consistent look.</p> </li> <li> <p>EVEREST-247 - We\u2019ve updated the Postgresql database icon on the UI for better clarity and visibility.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.1.0-%282024-08-12%29.html#backups-and-schedules","title":"Backups and schedules","text":"<ul> <li> <p>EVEREST-1092 - Starting with Percona Everest 1.1.0, you can no longer initiate an on-demand backup while another backup is in progress. This change helps maintain data integrity and minimizes potential impact on database performance.</p> </li> <li> <p>EVEREST-1220 -  In Percona Everest 1.1.0, you\u2019re limited to using a maximum of three different backup storages for PostgreSQL, including those used in existing backup schedules. This restriction ensures reliable backup restoration.</p> </li> <li> <p>EVEREST-1071- We\u2019ve introduced a Deleting state that remains active until all resources associated with the backup are fully removed.</p> </li> <li> <p>EVEREST-1214 - We\u2019ve made it easier to manage backup schedules by removing the restriction on deleting PostgreSQL schedules.</p> </li> <li> <p>EVEREST-1223 - Starting with Percona Everest 1.1.0, you cannot edit the region and bucket for the existing backup storage.</p> </li> <li> <p>EVEREST-1226 - Starting with Percona Everest 1.1.0, you cannot create backup storages with the same bucket, region, and URL. </p> </li> <li> <p>EVEREST-1229 - For a better user experience, you can now see which backup storage is being used for both on-demand backups and schedules.</p> </li> <li> <p>EVEREST-910 - The schedule name and storage location for scheduled backups are now displayed on the UI.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.1.0-%282024-08-12%29.html#bugs-fixed","title":"Bugs fixed","text":"<ul> <li> <p>EVEREST-1233 - You will now see the correct error message when attempting to downgrade a major database version.</p> </li> <li> <p>EVEREST-740 -  MySQL is now correctly selected as the default database engine when creating a database, even if it wasn\u2019t the first operator installed.</p> </li> <li> <p>EVEREST-1181 - The option to upgrade the major version of the database engine for MongoDB and PostgreSQL is now correctly disabled in the database edit section, reflecting the intended functionality.</p> </li> <li> <p>EVEREST-859 - The issue causing an error during namespace deletion while uninstalling Percona Everest has been resolved.</p> </li> <li> <p>EVEREST-1074 - The backup page performance is now optimized for adding and editing backup.</p> </li> <li> <p>EVEREST-1141 - Backup files in the S3 bucket are now properly removed when the corresponding database is deleted.</p> </li> <li> <p>EVEREST-1144 - While editing the backup storage in a PostgreSQL database backup schedule, an error was encountered after three backup schedules were created. The issue has been resolved now.</p> </li> <li> <p>EVEREST-1050 - The restore page now correctly updates the restore information. </p> </li> <li> <p>EVEREST-1244 - While attempting to restore a database, there was a discrepancy between the messages indicating the status of the restoration process and the actual actions being taken by Percona Everest. The issue has been resolved now.</p> </li> <li> <p>EVEREST-307 - CLI errors now display more user-friendly messages without exceptions and stack traces.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.1.0-%282024-08-12%29.html#known-limitations","title":"Known limitations","text":"<p>You can\u2019t use the same URL, bucket, and region in two different backup storages. Doing so may cause issues with restoring from the existing backups.</p> <p>Here\u2019s what you need to know:</p> <p>Scenario 1</p> <p>If you have multiple storages with the same bucket, URL, and region, you won\u2019t be able to edit them after the 1.1.0 update. You\u2019ll need to delete the duplicates.</p> <p>To check whether your existing Everest installation has any backup storages using the same bucket, region, and endpoint URL, execute the following command:</p> <pre><code>curl -sS \"https://raw.githubusercontent.com/percona/everest-doc/main/tools/bin/check-duplicated-storages.sh\" | bash\n</code></pre> <p>Scenario 2</p> <p>What to do if you have schedules or backups that are using duplicated storages in different database technologies.</p>  MongoDB or  MySQL PostgreSQL <p>Create a new backup using a different backup storage. Then, delete the old schedules and backups that use the duplicated storage.</p> <p>Any backups using duplicated backup storages should be deleted. First, delete the backups from both backup storages, then delete the backup schedules, and finally, delete the backup storages themselves. Then, create a new backup storage and take backups using the new backup storage.</p>"},{"location":"release-notes/Percona-Everest-1.1.1-%282024-08-22%29.html","title":"What\u2019s new in Percona Everest 1.1.1","text":"<p>Warning</p> <p>Google Container Registry (GCR) is scheduled to be deprecated and will officially shut down on March 18, 2025. All versions of Percona Everest prior to 1.4.0 depend on images hosted on GCR, meaning that downloading those images will fail after the shutdown date. We strongly recommend upgrading to Percona Everest version 1.4.0 as soon as possible. If you do not upgrade, Percona Everest will no longer function.</p> <p>For more details, refer to the Container Registry Deprecation documentation.</p> <p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p> <p>Percona Everest version 1.1.1 introduces the following changes:</p>"},{"location":"release-notes/Percona-Everest-1.1.1-%282024-08-22%29.html#fixed-issues","title":"Fixed issues","text":"<ul> <li>EVEREST-1349 - While attempting to delete a database cluster after upgrading from Percona Everest version <code>1.0.x</code> to <code>1.1.0</code>, the databases provisioned in <code>v1.0.x</code> were stuck in the Deleting state. The issue has been resolved now.</li> </ul>"},{"location":"release-notes/Percona-Everest-1.2.0-%282024-10-01%29.html","title":"What\u2019s new in Percona Everest 1.2.0","text":"<p>Warning</p> <ul> <li>Percona Everest v1.2.0 introduces breaking changes to the API. Once you upgrade to version 1.2.0, the process cannot be reversed.</li> <li>Google Container Registry (GCR) is scheduled to be deprecated and will officially shut down on March 18, 2025. All versions of Percona Everest prior to 1.4.0 depend on images hosted on GCR, meaning that downloading those images will fail after the shutdown date. We strongly recommend upgrading to Percona Everest version 1.4.0 as soon as possible. If you do not upgrade, Percona Everest will no longer function.</li> </ul> <p>For more details, refer to the Container Registry Deprecation documentation.</p> <p>To begin your journey with Percona Everest, check out the Quickstart Guide for Percona Everest.</p>"},{"location":"release-notes/Percona-Everest-1.2.0-%282024-10-01%29.html#release-summary","title":"Release summary","text":"Sr. No Release summary Description 1. Role-based access control (RBAC) Introducing RBAC in Percona Everest: Ensure security and simplify database access management 2. Breaking API changes Percona Everest v1.2.0: A deep dive into Breaking API changes 3. Operator upgrades Improved multiple operator upgrades 4. New features Check out the new features introduced in Percona Everest 1.2.0 5. Improvements Discover all the enhancements featured in Percona Everest 1.2.0 6. New and deprecated API\u2019s Discover all the new APIs that have been added to Percona Everest 1.2.0, as well as any deprecated APIs 7. Bugs Find out about all the bugs fixed in Percona Everest 1.2.0 8. Known limitations Discover all the known limitations in Percona Everest 1.2.0"},{"location":"release-notes/Percona-Everest-1.2.0-%282024-10-01%29.html#release-highlights","title":"Release highlights","text":"Breaking API changesRBACOperator upgrades"},{"location":"release-notes/Percona-Everest-1.2.0-%282024-10-01%29.html#percona-everest-120-a-deep-dive-into-breaking-api-changes","title":"Percona Everest 1.2.0: A deep dive into Breaking API changes","text":"<p>Beginning with Percona Everest v1.2.0, breaking changes are being introduced to the API for <code>monitoring-instances</code> and <code>backup-storages</code> resources. These updates include:</p> <ul> <li> <p>Before the launch of Percona Everest 1.2.0, the resources\u00a0<code>monitoring-instances</code>\u00a0and\u00a0<code>backup-storages</code>\u00a0had a global scope. Percona Everest used a\u00a0<code>.spec.allowedNamespaces</code>\u00a0field to control access to these global resources. This field defined the namespaces where the resources could be accessed, thus providing some degree of access control.</p> </li> <li> <p>With the upgrade to Percona Everest version 1.2.0, the transition from global scope to the designated namespaces for these resources is an important change in the way access control is managed. This improves security as the resources are only accessible within their designated namespaces. The database clusters can only use <code>monitoring-instances</code> and <code>backup-storages</code> located within the same namespace as the cluster.</p> </li> <li> <p>When upgrading to 1.2.0 using the CLI command <code>everestctl upgrade</code>, all your existing <code>backup-storages</code> and <code>monitoring-instances</code> will be automatically migrated to the namespaces specified in their <code>.spec.allowedNamespaces</code> fields.</p> <p>Note</p> <p>After the upgrade to Percona Everest 1.2.0, you will only be able to access these resources through the new API endpoints.</p> <p>Check out our documentation for in-depth details on the Breaking API changes.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.2.0-%282024-10-01%29.html#introducing-rbac-in-percona-everest-ensure-security-and-simplify-database-access-management","title":"Introducing RBAC in Percona Everest: Ensure security and simplify database access management","text":"<p>Warning</p> <ul> <li>RBAC is currently in Technical Preview. Early adopters are advised to use this feature only for testing purposes and not in production environments.</li> <li>Check out the known limitations section for important information about the limitations of RBAC.</li> </ul> <p>Starting with Percona Everest 1.2.0, we\u2019ve enhanced our platform by introducing Role-Based Access Control (RBAC), which regulates resource access for better management and security.</p> <p>With RBAC, only authorized individuals can access specific resources or perform certain actions based on their assigned roles. This method improves security by minimizing the risk of unauthorized access and helps manage permissions more efficiently across Percona Everest.</p> <p>To enable or disable RBAC in Percona Everest, you can use a configuration flag that allows switching between RBAC-enabled and RBAC-disabled modes. By default, RBAC is disabled.</p> <p>Here\u2019s a breakdown of the key concepts in RBAC:</p> <ul> <li> <p>Roles - Roles are a set of permissions that allow users to access and carry out various tasks within Percona Everest.</p> </li> <li> <p>RBAC resources and privileges: Resources are the entities or objects within Percona Everest that require controlled access. Privileges specify the particular actions that a role is able to perform on a resource.</p> </li> <li> <p>Policy definition: RBAC policies are the rules and guidelines that define how roles, permissions, and users are managed within RBAC.</p> <p>The policy definition in Percona Everest is:</p> <pre><code>p, &lt;subject&gt;, &lt;resource-type&gt;, &lt;action&gt;, &lt;resource-name&gt;\n</code></pre> </li> <li> <p>Role assignment: Assigning specific roles to individual users within Percona Everest is crucial for the roles to be effective.</p> <p>The syntax for assigning a role is as follows:</p> <pre><code>g, username, rolename\n</code></pre> </li> </ul> <p>Explore our comprehensive documentation for everything you need to know about RBAC.</p>"},{"location":"release-notes/Percona-Everest-1.2.0-%282024-10-01%29.html#improved-multiple-operator-upgrades","title":"Improved multiple operator upgrades","text":"<p>Starting with Percona Everest 1.2.0, it\u2019s important to note that due to limitations with the Operator Lifecycle Manager (OLM), it is now required to upgrade all database operators concurrently with their components across any namespace. The upgrade process can be accomplished using our intuitive UI.</p> <p>Before initiating the upgrade process, Percona Everest provides a comprehensive list of tasks that must be completed to ensure a seamless transition of your clusters to the next version of the database operators.</p>"},{"location":"release-notes/Percona-Everest-1.2.0-%282024-10-01%29.html#new-features","title":"New features","text":"<ul> <li> <p>EVEREST-1103: Starting with Percona Everest 1.2.0, we\u2019ve restricted actions based on RBAC roles, ensuring that users are explicitly granted access to the resources required for their specific roles. This enhances security and simplifies access control processes.</p> </li> <li> <p>EVEREST-1142: We have now added a new command for validating your RBAC policy to ensure that your RBAC policies are working as expected.</p> </li> <li> <p>EVEREST-1240: We have added support for PostgreSQL operator version 2.4.1. </p> </li> <li> <p>EVEREST-1298: We have added support for MySQL operator version 1.15.0.</p> </li> <li> <p>EVEREST-1035: We\u2019ve now included Retention copies for PostgreSQL as well when setting up backup schedules.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.2.0-%282024-10-01%29.html#improvements","title":"Improvements","text":"<ul> <li> <p>EVEREST-1165- Due to limitations with the Operator Lifecycle Manager (OLM), it is now required to upgrade all database operators concurrently with their components across any namespace.</p> </li> <li> <p>EVEREST-1212 - Starting with Percona Everest 1.2.0, you can now directly edit the monitoring endpoint from the database overview page instead of having to use the Edit database wizard.</p> </li> <li> <p>EVEREST-1230: We\u2019ve updated the Resources panel on the Database overview page to be independent instead of part of the DB Details panel and improved the overall look and feel of this page.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.2.0-%282024-10-01%29.html#the-latest-in-apis-whats-new-and-whats-deprecated","title":"The latest in APIs: What\u2019s new and what\u2019s deprecated","text":"Newly added API endpointsDeprecated API endpoints <p>Check out the new API endpoints we\u2019ve added in Percona Everest 1.2.0:</p> No API endpoints Method 1. <code>/namespaces/{namespace}/monitoring-instances</code> a.<code>GET</code> b.<code>POST</code> 2. <code>/namespaces/{namespace}/monitoring-instances/{name}</code> a.<code>GET</code>b. <code>PATCH</code>c.<code>DELETE</code> 3. <code>/namespaces/{namespace}/backup-storages</code> a.<code>GET</code> b. <code>POST</code> 4. <code>/namespaces/{namespace}/backup-storages/{name}</code> a.<code>GET</code> b.<code>POST</code> 5. <code>/permissions</code> a.<code>GET</code> <p>This is the list of the API endpoints deprecated from Percona Everest:</p> No API endpoints Method 1. Endpoints deprecated in Percona Everest v1.1.0 and removed in v1.2.0: a. <code>/namespaces/{namespace}/database-engines/{name}/operator-version/preflight</code> 1.<code>GET</code> b. <code>/namespaces/{namespace}/database-engines/{name}/operator-version</code> 1.<code>GET</code>2.<code>PUT</code> 2. Endpoints deprecated in v1.2.0: c. <code>/monitoring-instances</code> 1.<code>GET</code> 2.<code>POST</code> d. <code>/monitoring-instances/{name}</code> 1.<code>GET</code>2. <code>PATCH</code>3.<code>DELETE</code> e. <code>/backup-storages</code> 1.<code>GET</code> 2.<code>POST</code> f. <code>/backup-storages/{name}</code> 1.<code>GET</code>2. <code>PATCH</code>3.<code>DELETE</code>"},{"location":"release-notes/Percona-Everest-1.2.0-%282024-10-01%29.html#bugs","title":"Bugs","text":"<ul> <li> <p>EVEREST-768: The PostgreSQL pods now demonstrate the intended behavior by not getting stuck, as they automatically restart when the database is restarted.</p> </li> <li> <p>EVEREST-1287 - Before Percona Everest 1.2.0, every database node had to be scheduled on a separate K8s node within an EKS distribution. Otherwise, the database would fail to start if it didn\u2019t have a separate K8s node available. Now, it is preferable, but the databases will still come up even if no separate K8s node is available, and this setting is applied regardless of the distribution being used.</p> </li> <li> <p>EVEREST-1232: The backups and restore pages have been updated to show consistent date formats.</p> </li> <li> <p>EVEREST-1273: We have fixed an issue to display an error message when the user edits the backup storage URL to an invalid one.</p> </li> <li> <p>EVEREST-1286: When editing a backup schedule, the option to change the backup name is now disabled.</p> </li> <li> <p>EVEREST-1253: The Delete option in the backup menu is properly now disabled if the backup is in the Deleting status.</p> </li> <li> <p>EVEREST-1279: The CPU value displayed on the Resources page and the Database Summary panel is now consistent.</p> </li> <li> <p>EVEREST-1315: Despite Percona Everest showing a successful upgrade message, the upgrade actually didn\u2019t go as planned. The issue has been resolved now.</p> </li> <li> <p>EVEREST-1323:We\u2019ve resolved the issue that was causing an error to appear on the Components page after creating databases, especially when the status was either initializing or up.</p> </li> <li> <p>EVEREST-1354: We\u2019ve resolved an issue related to an incorrect allocation of CPU and memory resources for PXC clusters. To apply these new settings, a database restart is required.</p> </li> <li> <p>EVEREST-1371: We\u2019ve addressed a couple of issues pertaining to the Monitoring page, one of them being the monitoring endpoint displaying the username instead of the endpoint name.</p> </li> <li> <p>EVEREST-1372: We\u2019ve resolved the issue that prevented us from deleting the monitoring endpoint that is not currently in use.</p> </li> <li> <p>EVEREST-1427 - PostgreSQL no longer gets stuck in an unknown state despite having duplicate backup storage in different namespaces.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.2.0-%282024-10-01%29.html#known-limitations","title":"Known limitations","text":"<ul> <li> <p>RBAC will not work if you have configured Single sign-on (SSO) and your identity provider (IdP) is Microsoft Entra.</p> </li> <li> <p>If you remove permissions for a resource, some permissions will still be valid even after they have been removed. The new set of permissions will only take effect when you refresh the page.</p> </li> <li> <p>When you upgrade PostgreSQL operators to version 2.4.1, the database transitions to the initializing state as part of the upgrade process. However, this initializing state does not cause any downtime.</p> </li> <li> <p>When you upgrade PXC operators to version 1.15.0, single node MySQL databases will be restarted, resulting in downtime. However, it is worth noting that single node databases should not be used in production environments.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html","title":"What\u2019s new in Percona Everest 1.3.0","text":"<p>\u27a1\ufe0f New to Percona Everest? Get started with our Quickstart Guide.</p> Release summary at a glance Sr. No Release summary Description 1. Configure proxy nodes Configure proxy nodes and define their resource limits 2. MongoDB Sharding Introducing sharding in Percona Everest: Optimize your MongoDB databases with sharding 3. Database status Check your database status from the database details page 4. PSMDB Operator v1.17.0 support Support for PSMDB Operator v1.17.0 in Percona Everest 5. Google Container Registry (GCR) deprecation Deprecation of GCR starting May 20, 2025 6. New features Check out the new features introduced in Percona Everest 1.3.0 7. Improvements Discover all the enhancements featured in Percona Everest 1.3.0 8. Deprecated APIs Discover all the Deprecated APIs from Percona Everest 1.3.0 9. Bugs Find out about all the bugs fixed in Percona Everest 1.3.0 10. Known limitations Discover all the known limitations in Percona Everest 1.3.0"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#release-highlights","title":"Release highlights","text":"Configure proxiesMongoDB shardingDatabase statusPSMDB operator v1.17.0"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#capability-to-configure-proxy-nodes-and-define-their-resource-limits","title":"Capability to configure proxy nodes and define their resource limits","text":"<p>Starting with Percona Everest 1.3.0, we have introduced a new feature that permits you to customize the number of proxies and their resources, including the allocation of CPU and RAM for each proxy. This feature mirrors the existing capability to customize the number of database engine replicas and allocate resources to them.</p> <p>With this feature, you now have more flexibility to customize the resources allocated to proxies according to your needs, thus providing more control over your Percona Everest deployments.</p> <p></p>"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#optimize-mongodb-with-sharding-in-percona-everest","title":"Optimize MongoDB with sharding in Percona Everest","text":"<p>Warning</p> <ul> <li>Sharding is currently in Technical Preview. Early adopters are advised to use this feature only for testing purposes and not in production environments.</li> <li> <p>Check out the known limitations section for important information about the limitations of sharding.</p> </li> <li> <p>If you reshard or unshard a collection, create a new backup to avoid data inconsistency and restore failure.</p> </li> </ul> <p>We\u2019re excited to announce that we\u2019ve achieved another milestone with the implementation of MongoDB sharding in Percona Everest 1.3.0. You can now harness the benefits of sharding for your MongoDB databases with Percona Everest.</p> <p>Sharding   is used for horizontal database scaling. It distributes a database horizontally across multiple nodes or servers, known as shards. Each shard manages a portion of the data, forming a sharded cluster, which enables MongoDB to handle large datasets and high user concurrency effectively.</p> <p>The key components of MongoDB sharding are:</p> <ul> <li>Shard: Each shard has a subset of the data.</li> <li>Mongos: The query router directs the client queries to the proper shard(s).</li> <li>Config servers: The configuration servers store the cluster\u2019s metadata and configuration settings.</li> </ul> <p>Here\u2019s how you can enable sharding:</p> <p>On the Create Database wizard, select MongoDB database and turn on the Sharded Cluster toggle.</p> <p></p> <p>If you\u2019re looking to dive deeper into MongoDB sharding, check out the documentation.</p>"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#database-status-at-a-glance","title":"Database status at a glance","text":"<p>Starting with Percona Everest version 1.3.0, you can now quickly monitor the status of your databases right from the database details page for your specific database. This feature saves you time by enabling you to keep an eye on your databases without having to switch to the database view page.</p> <p></p>"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#support-for-psmdb-operator-v1170","title":"Support for PSMDB Operator v1.17.0","text":"<p>Starting with Percona Everest 1.3.0, we are thrilled to announce that we have added support for PSMDB Operator v1.17.0.</p>"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#google-container-registry-gcr","title":"Google Container Registry (GCR)","text":"<p>GCR deprecation</p> <p>GCR is set to be deprecated, with its official shutdown scheduled for May 20, 2025.</p> <p>All Percona Everest versions prior to 1.4.0 depend on images hosted on Google Container Registry (GCR). These images will become unavailable after the shutdown date: May 20, 2025.</p>"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#impact-of-gcr-deprecation","title":"Impact of GCR deprecation","text":"<p>Percona Everest versions older than 1.4.0 will cease to function after this date.</p>"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#action-required","title":"Action required","text":"<p>We strongly recommend upgrading to Percona Everest version 1.4.0 or later as soon as possible. If you do not upgrade, Percona Everest will no longer function.</p>"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#new-features","title":"New features","text":"<ul> <li> <p>EVEREST-1303: We have introduced MongoDB sharding in Percona Everest 1.3.0. Now, you can leverage sharding for your MongoDB databases with Percona Everest.</p> </li> <li> <p>EVEREST-777: Previously, you could only customize the database engine replicas and their resources. Now, you have the ability to customize the number of proxy replicas and their resources, including CPU and RAM, during the database creation.</p> </li> <li> <p>EVEREST-1310: Previously, you could only customize the database engine replicas and their resources. Now, you have the ability to customize the number of proxy replicas and their resources, including CPU and RAM, while editing the database.</p> </li> <li> <p>EVEREST-1239: Starting with Percona Everest, we\u2019ve added support for PSMDB Operator v1.17.0.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#improvements","title":"Improvements","text":"<ul> <li> <p>EVEREST-1006 - You can now view your database status right from the database details page.</p> </li> <li> <p>EVEREST-1208 - You can upgrade the database version directly from the Overview page. However, the Upgrade option will only be visible if you have the necessary permissions. When you click Upgrade, a pop-up will appear, prompting you to select the version of the database to which you want to upgrade.</p> </li> <li> <p>EVEREST-1211 - You can now easily edit your resources directly from the Overview page. There\u2019s no longer a need to navigate the entire database wizard, saving you time and simplifying the process.</p> </li> <li> <p>EVEREST-1459 - We have added a link to Percona Support on the Percona Everest home page, making it easier for you to contact support if needed.</p> </li> <li> <p>EVEREST-1460 - To make your experience with Percona Everest even smoother, we\u2019ve added convenient links right on the login page. Discover everything from Support and a Quickstart guide to our Forum, the K8s Squad program, and our GitHub repository.</p> </li> <li> <p>EVEREST-1470 - The <code>rbac validate</code> command has been enhanced to accept the <code>ConfigMap</code> YAML file. This enables you to validate role-based access control (RBAC) configurations by leveraging the structured data provided in a <code>ConfigMap</code> format.</p> </li> <li> <p>EVEREST-1533 - Users with read-only permissions for a namespace, including all database engines and database clusters within that namespace, currently cannot access the Upgrade option in the user interface. This restriction prevents them from viewing upgrade prerequisites, such as the versions of database clusters that may need to be upgraded.</p> <p>However, starting with Percona Everest 1.3.0, the Upgrade button is clickable for these users. This enables them to view details about the upgrade plan, including any necessary changes for the database clusters, which can help inform administrators about required preparations. However, the option to upgrade the operator remains unclickable for users without the upgrade permissions.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#deprecated-api-endpoints","title":"Deprecated API endpoints","text":"<p>This is the list of the API endpoints deprecated in Percona Everest v1.2.0 and removed from v1.3.0:</p> No API endpoints Method a. <code>/monitoring-instances</code> 1.<code>GET</code> 2.<code>POST</code> b. <code>/monitoring-instances/{name}</code> 1.<code>GET</code>2. <code>PATCH</code>3.<code>DELETE</code> c. <code>/backup-storages</code> 1.<code>GET</code> 2.<code>POST</code> d. <code>/backup-storages/{name}</code> 1.<code>GET</code>2. <code>PATCH</code>3.<code>DELETE</code>"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#bugs","title":"Bugs","text":"<ul> <li> <p>EVEREST-1187 - When creating a PostgreSQL database, if backup schedules were not created initially but added later after the database was created, Point-in-Time Recovery (PITR) was disabled. We have now resolved the issue, and PITR has now been enabled.</p> </li> <li> <p>EVEREST-1266 - On the Components page, the Pod icon now shows the correct color: green if the status is <code>Running</code> and all containers are ready and yellow if the status is <code>Running</code> while some containers are not ready.</p> </li> <li> <p>EVEREST-1384 - The Overview page now displays resources more clearly for an enhanced UI.</p> </li> <li> <p>EVEREST-1390 - We\u2019ve addressed an issue that caused the Components page to get stuck in a loop, refreshing endlessly whenever a database was suspended. </p> </li> <li> <p>EVEREST-1398 - The time format is now unified across all backups and restores, ensuring consistency and clarity.</p> </li> <li> <p>EVEREST-1399 The Resource per node now correctly shows the preset value set when creating the database. Before, the value set during and after database creation did not match.</p> </li> <li> <p>EVEREST-1407 - We resolved an issue where a user not included in the RBAC configuration (lacking permissions) could access certain information on Percona Everest.</p> </li> <li> <p>EVEREST-1430 - We encountered a problem that prevented us from navigating back to the namespace settings page after upgrading the database operator in the Percona Everest GUI. This issue has now been resolved.</p> </li> <li> <p>EVEREST-1444 - The Create database wizard now correctly displays an error if the user does not have database-engines permissions. Also, if the user doesn\u2019t have access to at least one database engine, then that namespace doesn\u2019t show up on the list.</p> </li> <li> <p>EVEREST-1447 - The options to edit and delete backup schedules are now disabled if the user lacks the necessary permissions.</p> </li> <li> <p>EVEREST-1454 - Although the user did not have permission for backup storage, they could see the Add backup storage option while creating a DB cluster. The issue has been resolved now.</p> </li> <li> <p>EVEREST-1455 - Monitoring endpoint information is now consistent when editing a database (DB) cluster. Previously, if you created a DB cluster with monitoring enabled and then removed all permissions related to monitoring before editing the same DB cluster, the endpoint information for monitoring would not be consistent.</p> </li> <li> <p>EVEREST-1457 - We have addressed an issue where the Add monitoring endpoint option appeared while creating a DB cluster, even though the user lacked the required permissions.</p> </li> <li> <p>EVEREST-1464 -  Previously, the Restores page would automatically refresh if a user attempted to access it without the necessary restore permissions. The issue has been resolved now.</p> </li> <li> <p>EVEREST-1506 - You can now edit the database cluster, provided that you have the necessary permissions to do so.</p> </li> <li> <p>EVEREST-1510 - The Add Storage button was displayed for the PostgreSQL database even though backup schedules had already been set up. This issue has been resolved now.</p> </li> <li> <p>EVEREST-1517 -  If users do not have the necessary permissions to perform an action, you can now see the correct error message on the UI.</p> </li> <li> <p>EVEREST-1525 - When deleting a monitoring endpoint, the UI no longer freezes and successfully removes the monitoring endpoint.</p> </li> <li> <p>EVEREST-1526 - We resolved an issue where users lacking backup storage permissions could create a DB cluster with a backup schedule using a storage location.</p> </li> <li> <p>EVEREST-1532 - The option to upgrade an operator is absent on the Percona Everest UI when the database engine name is included in the RBAC policy.</p> </li> <li> <p>EVEREST-1541 - We fixed an issue where the custom number of nodes was not functioning during the setup of MySQL databases.</p> </li> <li> <p>EVEREST-1550 - The database dashboard menu displayed an empty box for users with read-only permissions on the database cluster. This issue has now been resolved.</p> </li> <li> <p>EVEREST-1551 - The Upgrade button now only appears when new operator versions are available for upgrade.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#known-limitations","title":"Known limitations","text":""},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#psmdb-backup-failures","title":"PSMDB backup failures","text":"<p>There maybe instances when your MongoDB backups may encounter unexpected failures. </p> <p>You can check the reason for these failures by running the following command:</p> <pre><code>kubectl get psmdb-backup &lt;BACKUP_NAME&gt; -n &lt;YOUR_NAMESPACE&gt; -o yaml | grep error\n</code></pre> <p>Important</p> <p>We have compiled a list of  a list of workarounds to ensure that your backups function properly again.</p>"},{"location":"release-notes/Percona-Everest-1.3.0-%282024-11-18%29.html#mongodb-sharding","title":"MongoDB sharding","text":"<p>There are a few limitations related to MongoDB sharding. See our limitations section for details about these limitations.</p>"},{"location":"release-notes/Percona-Everest-1.4.0-%282025-01-07%29.html","title":"What\u2019s new in Percona Everest 1.4.0","text":"<p>\u27a1\ufe0f New to Percona Everest? Get started with our Quickstart Guide.</p> \ud83d\udd11 Updates at a glance Sr. No Release summary Description 1. Helm charts Simplify your Percona Everest deployments with Helm 2. Namespace management Manage your namespaces with new everestctl commands 3. Improved edit database flow Improved\u00a0edit database flow for a more streamlined user experience 4. Operators support Support for Percona Operator for MongoDB v1.18.0 (PSMDB) and Percona Operator for PostgreSQL v2.5.0 (PG) 5. Google Container Registry (GCR) deprecation Deprecation of GCR starting May 20, 2025 6. New features Check out the new features introduced in Percona Everest 1.4.0 7. Improvements Discover all the enhancements featured in Percona Everest 1.4.0 8. Bugs Find out about all the bugs fixed in Percona Everest 1.4.0 .9 Known limitations Discover all the known limitations in Percona Everest 1.4.0"},{"location":"release-notes/Percona-Everest-1.4.0-%282025-01-07%29.html#release-highlights","title":"Release highlights","text":"Helm chartsNamespaces managementImproved edit database flowOperators support"},{"location":"release-notes/Percona-Everest-1.4.0-%282025-01-07%29.html#simplify-your-percona-everest-deployments-with-helm","title":"Simplify your Percona Everest deployments with Helm","text":"<p>We are excited to announce the launch of Helm charts in Percona Everest 1.4.0. Helm charts simplify the deployment process by packaging all necessary resources and configurations, making them ideal for automating and managing installations in Kubernetes environments.</p> <p>Percona Helm charts can be found in percona/percona-helm-charts repository in Github.</p> <p>If you are looking to get started with Percona Everest using Helm, check out our comprehensive documentation.</p> <p>Additionally, check our Upgrade and Uninstall sections to find out how to upgrade or uninstall your Percona Everest instances using Helm.    </p>"},{"location":"release-notes/Percona-Everest-1.4.0-%282025-01-07%29.html#manage-your-namespaces-with-new-everestctl-commands","title":"Manage your namespaces with new everestctl commands","text":"<p>Namespace management is essential in Percona Everest for efficiently organizing, securing, and allocating resources, particularly in large and complex Kubernetes environments. By leveraging Kubernetes namespaces, Percona Everest achieves logical isolation, enhanced security, and better resource allocation for databases, backups, and monitoring setups.</p> <p>Starting with Percona Everest 1.4.0, we have introduced new <code>everestctl</code> commands to manage your namespaces. These commands enable you to:</p> <ul> <li>Add new namespaces</li> <li>Update existing namespaces</li> <li>Delete any used namespaces</li> </ul> <p>For a deep dive into managing namespaces for provisioning DB namespaces in Percona Everest, refer to our documentation.</p>"},{"location":"release-notes/Percona-Everest-1.4.0-%282025-01-07%29.html#removal-of-the-edit-db-wizard-for-an-enhanced-user-experience","title":"Removal of the Edit DB Wizard for an enhanced User Experience","text":"<p>Starting with Percona Everest 1.4.0, we have removed the Edit DB wizard to provide a more streamlined user experience. You can now edit specific fields directly from the DB Overview page using our new editable widgets, eliminating the need to navigate through the entire Edit DB wizard.</p> <p></p> <p>Let\u2019s assume you want to make changes to Point-in-time-Recovery (PITR). First, navigate to the specific database. Then, go to Overview &gt; Point-in-time-Recovery (PITR) and click Edit. Make the necessary changes and click Save.</p> <p></p>"},{"location":"release-notes/Percona-Everest-1.4.0-%282025-01-07%29.html#support-for-psmdb-1180-and-pg-250","title":"Support for PSMDB 1.18.0 and PG 2.5.0","text":"<p>Starting with Percona Everest 1.4.0, we are thrilled to announce that we have added support for PSMDB Operator v1.18.0 and PG operator v2.5.0.</p>"},{"location":"release-notes/Percona-Everest-1.4.0-%282025-01-07%29.html#google-container-registry-gcr","title":"Google Container Registry (GCR)","text":"<p>GCR deprecation</p> <p>All Percona Everest versions prior to 1.4.0 depend on images hosted on Google Container Registry (GCR). These images will become unavailable after the shutdown date: March 18, 2025.</p> <p>GCR is set to be deprecated, with its official shutdown scheduled for May 20, 2025.</p> <p>All Percona Everest versions prior to 1.4.0 depend on images hosted on Google Container Registry (GCR). These images will become unavailable after the shutdown date: May 20, 2025.</p>"},{"location":"release-notes/Percona-Everest-1.4.0-%282025-01-07%29.html#impact-of-gcr-deprecation","title":"Impact of GCR deprecation","text":"<p>Percona Everest versions older than 1.4.0 will cease to function after this date.</p>"},{"location":"release-notes/Percona-Everest-1.4.0-%282025-01-07%29.html#action-required","title":"Action required","text":"<p>We strongly recommend upgrading to Percona Everest version 1.4.0 or later as soon as possible. If you do not upgrade, Percona Everest will no longer function.</p> <p>For more details, refer to the Container Registry Deprecation documentation.</p>"},{"location":"release-notes/Percona-Everest-1.4.0-%282025-01-07%29.html#new-features","title":"New features","text":"<ul> <li> <p>EVEREST-1511: We have introduced Helm charts, which simplify the Percona Everest deployment process by packaging all necessary resources and configurations. These charts are ideal for automating and managing installations in Kubernetes environments.</p> </li> <li> <p>EVEREST-1512: You can now seamlessly upgrade your Percona Everest installation using Helm, a package manager for Kubernetes. This streamlined process simplifies the upgrade experience.</p> </li> <li> <p>EVEREST-1673: Starting with Percona Everest 1.4.0, we have introduced new <code>everestctl</code> commands to manage your namespaces.</p> </li> <li> <p>EVEREST-908: Starting with Percona Everest 1.4.0, the Overview page now includes the Connection URL in the Connection Details widget, allowing you to copy it directly.</p> </li> <li> <p>EVEREST-1599: We have added support for PostgreSQL operator v2.5.0.</p> </li> <li> <p>EVEREST-1624: We have added support for PSMDB Operator v1.18.0.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.4.0-%282025-01-07%29.html#improvements","title":"Improvements","text":"<ul> <li> <p>EVEREST-1065: Starting with Percona Everest 1.4.0, we have removed the Edit button from the database list actions. This change provides a more streamlined user experience, allowing you to edit the database directly from the database Overview page without having to go through the entire edit wizard.</p> </li> <li> <p>EVEREST-1066: We have improved the Backups &amp; PITR widget on the database Overview page. With this enhancement, you can now directly enable or disable PITR by clicking Edit from this page.</p> </li> <li> <p>EVEREST-1210: The Advanced Configuration panel on the DB Details widget is now more user-friendly than ever. You can  edit or enable parameters directly from the database Overview page. Just click Edit, and and make your changes with ease.</p> </li> <li> <p>EVEREST-1304: We have simplified the create database wizard. When you click Create Database, a menu with the MySQL, PostgreSQL, and MongoDB options will appear under the button. After selecting a database type, you will be guided to the wizard with the chosen value pre-set.</p> </li> <li> <p>EVEREST-1546: You can see the number of proxies, routers, and bouncers, along with their resources, directly on the Database Summary and Overview pages. This enhancement provides greater visibility into the resources within your clusters.</p> </li> <li> <p>EVEREST-1683: The Backups on the Overview page are organized in descending order, making it easier to find your most recent backups by their start date and time.</p> </li> <li> <p>EVEREST-1686: We\u2019ve adopted a 24-hour time format for our backups and restores to eliminate any potential confusion and ensure consistency across Percona Everest.</p> </li> <li> <p>EVEREST-1687: The label for the upgrade CRD button has been shortened to improve readability.  </p> </li> <li> <p>EVEREST-1701: Starting with Percona Everest 1.4.0, when configuring RBAC policies, the resource name for <code>database-cluster-backups</code> now corresponds to the database name instead of the backup name. This change allows for a more intuitive configuration of permissions for backups at the database level.</p> </li> <li> <p>EVEREST-1702: Starting with Percona Everest 1.4.0, when configuring RBAC policies, the resource name for <code>database-cluster-restores</code> now corresponds to the database name instead of the restore name. This change allows for a more intuitive configuration of permissions for backups at the database level.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.4.0-%282025-01-07%29.html#bugs","title":"Bugs","text":"<ul> <li> <p>EVEREST-1688: If a user changed the value for the number of shards and then scrolled down, the number of shards would unexpectedly increase. Conversely, if they scrolled up, the number of shards would decrease. The value did not remain constant, and similar behavior was observed in other fields as well. This issue has been resolved now, and the values for the fields remain constant.</p> </li> <li> <p>EVEREST-1187: We\u2019ve resolved the issue that prevented Point-In-Time Recovery (PITR) from being enabled for the PostgreSQL database after setting up backup schedules on the Backups page.</p> </li> <li> <p>EVEREST-1235, EVEREST-1254: <code>everestctl</code> now provides relevant error messages when using the <code>install</code> command, helping you identify any issues that occurred during the installation process. For instance, if the kubeconfig is unavailable, the cluster configuration is incorrect, or the cluster cannot be connected to, <code>everestctl</code> will display an appropriate error message.</p> </li> <li> <p>EVEREST-1254: During the uninstallation of Percona Everest, an unusual error code appeared at the end of the process. The issue has been resolved now.</p> </li> <li> <p>EVEREST-1320: The warning message for a gap in Point-in-Time Recovery (PITR) is now shown on both the Backups and Restores pages. Additionally, when the database is up and running, a triangle icon on the dashboard page now correctly directs you to the Backups page.</p> </li> <li> <p>EVEREST-1352: To ensure data integrity, all database actions are now disabled while the database is in a Deleting state.</p> </li> <li> <p>EVEREST-1399: The Resource per node now accurately displays the value set during database creation. Previously, there was a mismatch between the value chosen at setup and what was shown when editing the database. Instead, it defaulted to Custom, which was not the initial selection. </p> </li> <li> <p>EVEREST-1407: We\u2019ve resolved an issue where a user lacking the necessary RBAC permissions could access specific information in Percona Everest.</p> </li> <li> <p>EVEREST-1440: We\u2019ve resolved an issue that caused a delay while loading the Backups page. Furthermore, the Add Storage option was displayed on the Backups page even though the user did not have backup storage permissions.</p> </li> <li> <p>EVEREST-1518, EVEREST-1604: We\u2019ve resolved an issue that permitted users to view and edit DB clusters, as well as restore to the same DB cluster, even if they lacked the necessary permissions for the database engine(s).</p> </li> <li> <p>EVEREST-1534 The Database clusters page was empty for users with access to only one database cluster. This issue has now been resolved.</p> </li> <li> <p>EVEREST-1565: The MongoDB versions are now sorted in descending order, and all the versions are visible on the Basic information page when selecting the Database version.</p> </li> <li> <p>EVEREST-1593: We\u2019ve resolved an issue that was preventing the display name and database version from showing up during a new cluster creation.</p> </li> <li> <p>EVEREST-1594: Scheduled backups failed after several successful runs when the number of shards in the MongoDB sharded cluster was modified. This issue has been resolved now.</p> </li> <li> <p>EVEREST-1608: Percona Everest now displays an error message if the Proxies value in the Custom field for the MySQL database is not entered. Also, unless you enter this value, the Continue button is disabled, which aligns with the expected behavior.</p> </li> <li> <p>EVEREST-1613: On the Edit Topology page, the Resource Size per Node field now displays the initially selected configuration. Previously, when reopening the Edit Topology page, the setting would revert to Custom instead of retaining the chosen option.</p> </li> <li> <p>EVEREST-1615: We have fixed an issue where the uninstallation of Percona Everest failed if a MongoDB sharded cluster was in the Deleting state.</p> </li> <li> <p>EVEREST-1642: When restoring to a new database, modifying its version is no longer possible. This behavior aligns with the expected functionality of Percona Everest.</p> </li> <li> <p>EVEREST-1649: We\u2019ve addressed an issue that caused the Add storage button for backups to remain inactive, even after the page was refreshed. The button would only become active when users switched between different tabs, such as transitioning from the Overview tab to the Backups tab.</p> </li> <li> <p>EVEREST-1650: We have resolved an issue on the Backups page where the button incorrectly displayed Add storage instead of Create backup after adding new storage. This prevented users from creating backups. The issue occurred when trying to add backup storage in a namespace other than the one where the database was originally created (the default namespace).</p> </li> <li> <p>EVEREST-1694: The Backup storages page was appearing empty for users with access to only one backup storage. This issue has now been resolved.</p> </li> <li> <p>EVEREST-1695: The Monitoring endpoints page was empty for users with access to only one monitoring instance. This issue has now been resolved.</p> </li> <li> <p>EVEREST-1703: While setting up a MongoDB sharded cluster in Percona Everest, an error occurred during the topology step. If only 1 config server was selected, an error message appeared, stating that the number of config servers must be greater than one. However, when the config server setting was changed to 3 or any other value, the \u201cNext\u201d button became grayed out, preventing progress to the next step. The issue has been resolved now.</p> </li> <li> <p>EVEREST-1712: We\u2019ve resolved an issue where the Percona Everest UI pages became unresponsive after some time. None of the page elements worked, and the only solution was to close the page and start a new browser session.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.4.0-%282025-01-07%29.html#known-limitations","title":"Known limitations","text":"<ul> <li> <p>In Percona Operator for PostgreSQL version 2.5.0, backups start failing after a minor version upgrade from PostgreSQL 16.3 to 16.4 if monitoring is enabled on the database. </p> <p>Workaround </p> <p>Once you upgrade your PostgreSQL version, it\u2019s essential to also update the <code>pg_stat_monitor</code> extension by executing the following command:</p> <pre><code>ALTER EXTENSION pg_stat_monitor UPDATE;\n</code></pre> </li> <li> <p>The backup storage you choose for your initial backup schedule will be used for all subsequent schedules and point-in-time recovery (PITR).</p> </li> <li> <p>When creating a 1-node MongoDB cluster, the cluster temporarily enters an Error state instead of Initializing before transitioning to the Ready state.</p> </li> <li> <p>When restoring a MySQL database from a backup, the process may fail if the database name is too long. Use a shorter name for the restored database.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html","title":"What\u2019s new in Percona Everest 1.5.0","text":"<p>\u27a1\ufe0f New to Percona Everest? Get started with our Quickstart Guide.</p> \ud83d\udd11 Updates at a glance # Release summary Description 1. Role-based access control (RBAC) Generally Available (GA) RBAC is now GA with Percona Everest 1.5.0 2. RBAC: Integration with IdP groups Assign RBAC policies to user groups obtained from an external IdP 3. Operators support Support for PXC operator 1.16.1 and PSMDB operator 1.19.1 4. Google Container Registry (GCR) deprecation Deprecation of GCR starting May 20, 2025 5. New features Check out the new features introduced in Percona Everest 1.5.0 6. Improvements Discover all the enhancements featured in Percona Everest 1.5.0 7. Bugs Find out about all the bugs fixed in Percona Everest 1.5.0 8. Known limitations Discover all the known limitations in Percona Everest 1.5.0"},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html#release-highlights","title":"Release highlights","text":"RBAC GARBAC with enhanced IdPOperators support"},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html#percona-everest-rbac-is-now-ga","title":"Percona Everest: RBAC is now GA","text":"<p>We\u2019re delighted to announce the General Availability of RBAC in Percona Everest 1.5.0.</p> <p>With RBAC, only authorized individuals can access specific resources or perform certain actions based on their assigned roles. This update introduces:</p> <ul> <li> <p>Granular access management: Allocate roles with detailed permissions to ensure precise access control.</p> </li> <li> <p>Enhanced security: Restrict access to authorized users and teams only.</p> </li> <li> <p>Enhanced IdP integration: Integrate with your Identity Provider to streamline the authentication process and effectively manage the assignment of user roles.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html#streamlining-rbac-with-enhanced-idp-group-integration","title":"Streamlining RBAC with enhanced IdP group integration","text":"<p>Starting with Percona Everest 1.5.0, you can now assign RBAC policies to user groups obtained from the external IDP. This enhancement simplifies permissions management for external users without the need for unique sub IDs. To use IdP groups in Percona Everest RBAC, you must set up the groups claim in your IdP provider configuration.</p> <p>Configure your Identity Provider (IdP) to provide the user\u2019s groups claim by following our documentation.</p> <p>To retrieve the IdP groups, you need to include the <code>groups</code> scope by specifying the following fields:</p> <pre><code>everestctl settings oidc configure --issuer-url=http://url.com --client-id=&lt;your-app-client-id&gt; --scopes openid,profile,email,groups\n</code></pre> <p>Take a look at the descriptions of the various fields in the table below:</p> Field Description openid Grants access to the user\u2019s identity, which is necessary for OIDC flows to issue an ID token with a unique identifier (subject sub). profile Grants access to basic profile information. email Grants access to the user\u2019s email address and its verification status. groups Grants access to obtain information about the user\u2019s group memberships. <p> To explore further, dive into our documentation.</p>"},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html#support-for-psmdb-1191-and-pxc-1161","title":"Support for PSMDB 1.19.1 and PXC 1.16.1","text":"<p>Starting with Percona Everest 1.5.0, we are thrilled to announce that we have added support for PSMDB Operator v1.19.1 and PXC Operator v1.16.1.</p>"},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html#google-container-registry-gcr","title":"Google Container Registry (GCR)","text":"<p>GCR deprecation</p> <p>All Percona Everest versions prior to 1.4.0 depend on images hosted on Google Container Registry (GCR). These images will become unavailable after the shutdown date: March 18, 2025.</p> <p>GCR is set to be deprecated, with its official shutdown scheduled for May 20, 2025.</p> <p>All Percona Everest versions prior to 1.4.0 depend on images hosted on Google Container Registry (GCR). These images will become unavailable after the shutdown date: May 20, 2025.</p>"},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html#impact-of-gcr-deprecation","title":"Impact of GCR deprecation","text":"<p>Percona Everest versions older than 1.4.0 will cease to function after this date.</p>"},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html#action-required","title":"Action required","text":"<p>We strongly recommend upgrading to Percona Everest version 1.4.0 or later as soon as possible. If you do not upgrade, Percona Everest will no longer function.</p> <p>For more details, refer to the Container Registry Deprecation documentation.</p>"},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html#new-features","title":"New features","text":"<ul> <li> <p>EVEREST-1799: Starting with Percona Everest 1.5.0, you can now assign RBAC policies to user groups obtained from an external IDP. This change simplifies permissions management for external users without the need for unique sub IDs. </p> </li> <li> <p>EVEREST-1547: After performing an Everest upgrade, you will now receive a notification indicating that the upgrade has been completed. You can then access all the new features by clicking the Reload button.</p> </li> <li> <p>EVEREST-1549: We have added support for PXC operator v1.16.1.</p> </li> <li> <p>EVEREST-1884: We have added support for PSMDB operator v1.19.1.</p> </li> <li> <p>EVEREST-689: We have added a new option to hide and unhide the password in the password form field on the login page.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html#improvements","title":"Improvements","text":"<ul> <li> <p>EVEREST-970: Our default backup schedule has been updated from Hourly to Daily, starting at 1:00 AM.</p> </li> <li> <p>EVEREST-1796: You can now see a more precise and informative message on the\u00a0Backups &amp; PITR\u00a0widget if no active schedules exist.</p> </li> <li> <p>EVEREST-1579: We have enhanced the shard Topology by modifying the label from Nodes to Nodes per shard. This change provides greater clarity on the distribution of nodes across each shard. Additionally, we now display the total number of nodes within the Database summary panel, giving you a more complete and insightful overview of your database.</p> </li> <li> <p>EVEREST-1612:  The <code>everestctl version</code> command has been updated to provide  information about the version of the Everest server currently installed on your system, if applicable. This enhancement enables you to quickly verify the server version that is in use.</p> </li> <li> <p>EVEREST-1788,   EVEREST-1790: The <code>everestctl namespaces remove</code>, and <code>everestctl namespaces update</code> commands now show a help message that guides you on how to use them.</p> </li> <li> <p>EVEREST-1794: We have improved the description of the help text for the <code>--keep-namespace</code> flag in the <code>everestctl namespaces remove</code> command. Previously, the flag did not clearly explain that it retains the namespace in Kubernetes while only removing everest-managed resources, which led to confusion.</p> </li> <li> <p>EVEREST-1795: When attempting to update a namespace using <code>everestctl</code> that was created with <code>kubectl</code> (not managed by Percona Everest), the error message was unclear. It did not provide actionable steps for the user to resolve the issue. We have improved the error message to give more insights into the issue.</p> </li> <li> <p>EVEREST-1190: You can now easily find out which account you\u2019re using to log into Everest by clicking the Profile button. This button shows the user\u2019s name or email address used to log into Percona Everest.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html#bugs","title":"Bugs","text":"<ul> <li> <p>EVEREST-1261: We fixed an issue where a user who had already added a backup storage location received an incorrect error message when trying to add another one with the same bucket name and URL.</p> </li> <li> <p>EVEREST-1401: Now, when you create/edit the database cluster with sharding enabled for PSMDB, it will display the correct resources required for the specified number of shards.</p> </li> <li> <p>EVEREST-1537: We have resolved an issue that caused Percona Everest uninstallation to fail when attempting to delete database clusters due to a timeout.</p> </li> <li> <p>EVEREST-1581: The database remained in a Deleting state despite all components being deleted. The issue has now been resolved.</p> </li> <li> <p>EVEREST-1588: We have fixed an issue where the PostgreSQL database was stuck in an initializing state after a restore.</p> </li> <li> <p>EVEREST-1589: We have fixed an issue in which the MySQL database remained stuck in an initializing state for a 1-node cluster.</p> </li> <li> <p>EVEREST-1647: Creating a monthly schedule on day 1 at 12:00 AM (the default option when choosing\u00a0Monthly) led to an error for PSMDB. The issue has been resolved now.</p> </li> <li> <p>EVEREST-1674: The message Enforce did not pass appeared randomly in the UI. Additionally, databases in the UI occasionally disappeared and then reappeared after a few seconds. We have now resolved the issue.</p> </li> <li> <p>EVEREST-1724: Sharding no longer resets to its default setting (disabled) when navigating back in the database creation wizard.</p> </li> <li> <p>EVEREST-1728: The database list now refreshes automatically whenever new databases are deployed in recently created namespaces, and this update is reflected across various browser sessions.</p> </li> <li> <p>EVEREST-1758: The Create Database button on the UI was inaccessible until the page was manually refreshed after adding a namespace using the <code>everestctl namespaces add</code> command. The issue has been resolved now.</p> </li> <li> <p>EVEREST-1729: We have added a mechanism to prevent a given CLI version from installing incompatible Percona Everest versions.</p> </li> <li> <p>EVEREST-1735: We have fixed an issue where incorrect information appeared on the PITR Edit button when PITR was enabled.</p> </li> <li> <p>EVEREST-1800: We fixed an issue where users could not create a DB cluster because the DB version was not displayed with a specific RBAC policy.</p> </li> <li> <p>EVEREST-1801: The Create DB cluster option was not visible on the UI if the user did not have the permissions for all the database engines. The issue has been resolved now.</p> </li> <li> <p>EVEREST-1802: A given namespace was not visible on the UI if the user lacked permissions for all database engines in that namespace. This issue has now been resolved.</p> </li> <li> <p>EVEREST-1803:  We have fixed an issue that prevented users from editing or adding monitoring to an existing DB cluster with a specific RBAC policy.</p> </li> <li> <p>EVEREST-1804: The Operator Upgrade option was previously not visible on the UI when users didn\u2019t have access to all DB clusters in a namespace. This issue has now been resolved.</p> </li> <li> <p>EVEREST-1811: <code>everest-operator</code> now restarts seamlessly when a DB operator is installed for the first time.</p> </li> <li> <p>EVEREST-688: You will be logged out from all tabs when you log out from one tab or attempt to perform any action, as per the expected behavior.</p> </li> <li> <p>EVEREST-864: When a user created a database cluster and changed the namespace from A\u2014which had backup storage configured\u2014to a different namespace that did not have a backup storage location, the user interface only reset the values related to Basic Cluster Information and Resources. However, it failed to reset other values in the form, including those related to Backups, Point-in-Time Recovery (PITR), Advanced Configurations, and Monitoring. The issue has been resolved now.</p> </li> <li> <p>EVEREST-1787: After clicking Create Database and returning to the database view page, there was a short delay with a Loading button before the Create Database button appeared. This issue has been resolved now.</p> </li> <li> <p>EVEREST-1792: We have significantly reduced the delay between the loading of fields and their labels.</p> </li> <li> <p>EVEREST-1053: Restores now have different names for different database clusters. We have also implemented a standard naming convention for the restored databases that contains the database name/backup name with time.</p> </li> <li> <p>EVEREST-1808: The content within the textbox was not fully visible when no backups had been created. The issue has been resolved now.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html#known-limitations","title":"Known limitations","text":""},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html#issues-with-pitr-on-mongodb-80","title":"Issues with PITR on MongoDB 8.0","text":"<p>PSMDB Operator version 1.19.1 added support for MongoDB version 8.0. However, due to potential issues with point-in-time recovery on MongoDB 8.0 when sharding is enabled, the recommended MongoDB version is still 7.0.</p> <p>Action required</p> <p>Use MongoDB version 7.0.</p>"},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html#pitr-manual-time-entry-limitation","title":"PITR: Manual time entry limitation","text":"<p>When restoring a database using Point-in-Time Recovery (PITR), you cannot manually change the time between the most recent successful backup and the latest PITR. If you attempt to enter the date and time manually, the system will automatically reset it to align with the latest PITR. </p> <p>Action required</p> <p>Use the date picker to select the desired date and time for PITR restore.</p>"},{"location":"release-notes/Percona-Everest-1.5.0-%282025-03-04%29.html#upgrade-now","title":"Upgrade now","text":"<p>Upgrade to Percona Everest 1.5.0 to access these new features and improvements. Explore our documentation for the upgrade steps.</p>"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html","title":"What\u2019s new in Percona Everest 1.6.0","text":"<p>\u27a1\ufe0f New to Percona Everest? Get started with our Quickstart Guide.</p> \ud83d\udd11 Expand to unleash the key updates # Release summary Description 1. Manual storage scaling Increase the capacity of your storage through manual storage scaling 2. MongoDB: Major DB updates Support for major version upgrades of MongoDB 3. Operator Upgrades Support for Percona Operator for PostgreSQL 2.6.0 and PostgreSQL 17 4. Removed support for PostgreSQL 12 Percona Everest 1.6.0 discontinues support for PostgreSQL 12 5. Google Container Registry (GCR) deprecation Deprecation of GCR starting May 20, 2025 6. New features Check out the new features introduced in Percona Everest 1.6.0 7. Improvements Discover all the enhancements featured in Percona Everest 1.6.0 8. Bugs Find out about all the bugs fixed in Percona Everest 1.6.0 9. Known limitation Discover all the known limitations in Percona Everest 1.6.0"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html#release-highlights","title":"\ud83c\udf1f Release highlights","text":"\ud83d\udcc8 Storage scaling\ud83d\udd04 Major database upgrades Expanded PostgreSQL support"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html#scale-your-storage-with-ease-with-percona-everest-160","title":"Scale your storage with ease with Percona Everest 1.6.0","text":"<p>Starting with Percona Everest 1.6.0, you can leverage manual storage scaling to increase the capacity of your database, offering greater control over resource allocation as your needs evolve.</p> <p>Prerequisites for storage scaling</p> <ul> <li> <p>PersistentVolumeClaim (PVC) volume expansion - Ensure that the <code>StorageClass</code> used by the database\u2019s PersistentVolumeClaim (PVC) supports volume expansion.  Refer to the Kubernetes documentation on Persistent Volumes for more details.</p> </li> <li> <p>Resource quota check - Verify that your resource quotas allow for the requested storage capacity. For more information, see the Kubernetes documentation on Storage Resource Quota </p> </li> </ul> <p>How to modify storage capacity</p> <p>To increase the DISK for a database, go to the Percona Everest home page and select your desired database. Then, navigate to Overview &gt; Resources &gt; Edit and enter the new value for DISK (in Gi).</p> <p></p> <p> If you want to explore this topic in depth, check out our detailed documentation!</p>"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html#seamless-major-version-upgrades-for-mongodb","title":"Seamless major version upgrades for MongoDB","text":"<p>Percona Everest 1.6.0 introduces support for major version upgrades of MongoDB, enabling you to upgrade your databases with minimal downtime and disruption. This enhancement ensures your applications remain secure, performant, and compliant with the latest MongoDB features.</p> <p>To upgrade your MongoDB database, navigate to the Percona Everest homepage and select the database you wish to upgrade. On the Overview page, locate the DB Details panel and click Edit next to Basic Information. Select the desired version and click Upgrade to begin the process.</p> <p></p> <p></p> <p> For a deep dive into this topic, refer to our documentation.</p>"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html#support-for-postgresql-operator-260-and-postgresql-17","title":"Support for PostgreSQL Operator 2.6.0 and PostgreSQL 17","text":"<p>Percona Everest 1.6.0 now includes support for Percona Operator for PostgreSQL 2.6.0 and PostgreSQL 17.</p>"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html#removed-support-for-postgresql-12","title":"\ud83d\uded1 Removed support for PostgreSQL 12","text":"<p>Percona Everest 1.6.0 no longer supports PostgreSQL 12.</p>"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html#action-required","title":"Action required","text":"<p>To upgrade to Percona Everest 1.6.0, you must first migrate your clusters to a supported PostgreSQL version (13 or higher).</p> <p>Migration Guide: Follow our PostgreSQL migration procedure for a step-by-step guide to a seamless upgrade.</p>"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html#google-container-registry-gcr","title":"\ud83d\uded1 Google Container Registry (GCR)","text":"<p>GCR deprecation</p> <p>GCR is set to be deprecated, with its official shutdown scheduled for May 20, 2025.</p> <p>All Percona Everest versions prior to 1.4.0 depend on images hosted on the Google Container Registry (GCR). These images will become unavailable after the shutdown date: May 20, 2025.</p>"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html#impact","title":"Impact","text":"<p>Percona Everest versions older than 1.4.0 will cease to function after this date.</p>"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html#action-required_1","title":"Action required","text":"<p>We strongly recommend upgrading to Percona Everest version 1.4.0 or later as soon as possible. If you do not upgrade, Percona Everest will no longer function.</p> <p>For more details, refer to the Container Registry Deprecation documentation.</p>"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html#new-features","title":"New features","text":"<ul> <li> <p>EVEREST-1870, EVEREST-1871, EVEREST-1872: Starting with Percona Everest 1.6.0, you can leverage manual storage scaling to increase the capacity of your storage for MySQL, MongoDB, and PostgreSQL databases, respectively.</p> </li> <li> <p>EVEREST-1841: Percona Everest 1.6.0 introduces support for major version upgrades of MongoDB, enabling you to upgrade your databases with minimal downtime and disruption.</p> </li> <li> <p>EVEREST-1843 : Percona Everest 1.6.0 includes support for Percona Operator for PostgreSQL 2.6.0 and PostgreSQL 17.</p> </li> <li> <p>EVEREST-1986: The Helm chart now supports deploying an\u00a0Ingress resource to expose the Percona Everest server externally. This enhancement enables seamless integration with ingress controllers (e.g., NGINX) to manage access to the Percona Everest UI and APIs.</p> </li> <li> <p>EVEREST-1852: PMM can now be deployed as a sub-chart by setting <code>pmm.enabled=true</code>. As the PMM chart currently lacks support for namespace overrides, it will be deployed in the designated release namespace: <code>everest-system</code>.</p> <p>Also, PMM can now be fully configured from the Everest chart. This can be done by specifying options under the <code>pmm</code> field. This simplifies deployment management, offering greater flexibility and control for Helm-based workflows.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html#improvements","title":"Improvements","text":"<ul> <li> <p>EVEREST-1202: We\u2019ve refined the table header icons by removing the focus state when users click outside for an enhanced UX.</p> </li> <li> <p>EVEREST-1280: We\u2019ve moved the Storage class field to the Advanced Configurations page for better organization and usability.</p> </li> <li> <p>EVEREST-1312: The installation log now displays the same operator names as selected in the wizard for consistency and clarity.</p> </li> <li> <p>EVEREST-1711: We\u2019ve enhanced the database creation wizard by removing the final confirmation step, which improves user flow and decreases the number of clicks needed to create a database.</p> </li> <li> <p>EVEREST-1921: Updated the database version upgrade modal to prevent selection of the current version, ensuring only valid upgrade options are available.</p> </li> <li> <p>EVEREST-1930: We have introduced a distinct Upgrading state that clearly indicates when a database upgrade is taking place.</p> </li> <li> <p>EVEREST-1912: The Storage Class used by a database cluster is now prominently displayed on the database Overview page, enhancing visibility and making it easier for users to access configuration details directly within the UI.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html#bugs","title":"Bugs","text":"<ul> <li> <p>EVEREST-765: We have fixed an issue that caused Point-In-Time Recovery (PITR) to be disabled after the database was suspended and then resumed.</p> </li> <li> <p>EVEREST-1350: The UI now displays the IP address along with the netmask, ensuring consistency with the backend format.</p> </li> <li> <p>EVEREST-1374: We have identified and addressed an inconsistency in the logic governing the naming restrictions for backup storage and monitoring endpoints.</p> </li> <li> <p>EVEREST-1625: Point-In-Time Recovery (PITR) options were not visible in the UI when no scheduled backups were in place. This occurred even if the most recent backup was completed successfully and PITR was enabled. This issue has been resolved now.</p> </li> <li> <p>EVEREST-1763: When modifying the network topology by reducing the configuration from three nodes to a single node, no error message was displayed. This issue has been resolved, and an error message now appears, indicating that downscaling is not possible.</p> </li> <li> <p>EVEREST-1798: Resolved an issue where the PostgreSQL cluster was repeatedly initialized, leading to backup failures in specific scenarios.</p> </li> <li> <p>EVEREST-1911: Fixed an issue where an empty state briefly appeared before the first DB cluster was displayed.</p> </li> <li> <p>EVEREST-1920: Fixed a UI issue where the custom number of nodes for PostgreSQL was not displaying correctly in the cluster overview.</p> </li> <li> <p>EVEREST-1985: Resolved an issue preventing PITR-based recovery when backup schedules were added after the PostgreSQL database was created.</p> </li> <li> <p>EVEREST-1979: Addressed an issue where the database engine upgrade unexpectedly modified the backup schedule time.</p> </li> <li> <p>EVEREST-1959: The database version was not displayed when creating a new database from a backup. This issue has been resolved now. </p> </li> <li> <p>EVEREST-1963: The <code>storageclass</code> field associated with a database cluster is now non-editable to ensure consistency.</p> </li> <li> <p>EVEREST-1978: The PITR location was initially set incorrectly during backup restoration but has now been corrected.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html#known-limitation","title":"Known limitation","text":"<p>PostgreSQL 17.2 CVE-2025-1094 Vulnerability</p> <p>Images based on PostgreSQL 17.2 are affected by CVE-2025-1094 \u2014 a critical vulnerability in <code>libpq</code> that can lead to SQL injection via the PostgreSQL terminal.</p> <p>Resolution</p> <p>Support for PostgreSQL 17.4 is now available, featuring critical security and stability updates, particularly addressing the CVE identified in version 17.2.</p> <p>We strongly recommend using PostgreSQL version 17.4 instead of 17.2 to take advantage of the latest fixes and improved security features.</p>"},{"location":"release-notes/Percona-Everest-1.6.0-%282025-04-16%29.html#upgrade-now","title":"Upgrade now","text":"<p>Upgrade to Percona Everest 1.6.0 to access these new features and improvements. </p> <p> Explore our documentation for the upgrade steps.</p>"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html","title":"\ud83d\udce6 What\u2019s new in Percona Everest 1.7.0","text":"<p>\u27a1\ufe0f New to Percona Everest? Get started with our Quickstart Guide.</p> <p>Before you upgrade</p> <ul> <li> <p>Before upgrading to Percona Everest 1.7.0, run the following command:</p> <p><pre><code>kubectl label namespaces everest-system app.kubernetes.io/managed-by-\n</code></pre> For details, refer to the Known limitations section.</p> </li> <li> <p>Single Sign-On (SSO) authentication with Microsoft Entra ID does not function in Percona Everest 1.7.0. To ensure it functions properly, upgrade to version 1.8.1.</p> </li> </ul> \ud83d\udd11 Expand to unleash the key updates # Release summary Description 1. GKE Autopilot clusters Deploy Percona Everest on Google Kubernetes Engine (GKE) Autopilot clusters 2. Pod Scheduling policies Pod Scheduling for optimized Kubernetes scheduling\u00b6 3. TLS support Improved Security with TLS support 4. Operator Upgrades Support for Percona XtraDB Cluster (PXC) operator 5. Breaking Changes Learn about the breaking changes introduced in Percona Everest 1.7.0 6. New features Check out the new features introduced in Percona Everest 1.7.0 7. Improvements Discover all the enhancements featured in Percona Everest 1.7.0 8. Bugs Find out about all the bugs fixed in Percona Everest 1.7.0 9. Known limitations Discover all the known limitations in Percona Everest 1.7.0"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#release-highlights","title":"\ud83c\udf1f Release highlights","text":"\u2601\ufe0f GKE Autopilot clusters\u2388 Pod scheduling policies\ud83d\udd10 TLS support  PXC Operator"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#deploy-percona-everest-on-gke-autopilot","title":"Deploy Percona Everest on GKE Autopilot","text":"<p>You can now install Percona Everest on Google Kubernetes Engine (GKE) Autopilot clusters. GKE Autopilot provides a fully managed Kubernetes environment, where Google automatically handles node provisioning, scaling, and security. </p> <p>\ud83d\udcda Learn more about GKE Autopilot in the official documentation.</p>"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#pod-scheduling-policies-in-percona-everest","title":"Pod scheduling policies in Percona Everest","text":"<p>We are thrilled to introduce Pod scheduling policies for Percona Everest. This feature allows database administrators to manage database workload scheduling on Kubernetes. These policies enhance system resilience and ensure that your resources are utilized to their fullest potential.</p> <p>The Pod scheduling policy is preset that includes a set of Kubernetes Affinity rules applied to the appropriate DB cluster components.</p> <p>Kubernetes features three primary types of affinity that play a crucial role in how pods are scheduled and interact within a DB cluster:</p> <ul> <li> <p>Pod affinity: Co-locates pods on the same node or topology domain.</p> </li> <li> <p>Pod anti-affinity: Ensures pods are scheduled on different nodes or domains.</p> </li> <li> <p>Node affinity: Schedules pods based on node labels and conditions.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#default-configuration-for-pod-scheduling-policies","title":"Default configuration for Pod scheduling policies","text":"<p>In Percona Everest, the default pod scheduling policies are preset rules that help ensure the optimal placement of database components across a Kubernetes cluster. These predefined Pod scheduling policies come bundled with every Percona Everest deployment. Thus, Percona Everest users can utilize these predefined settings without the need to create custom rules for every database cluster they set up.</p> <p></p> <p>\ud83d\udcd8 To dive deep into this topic, see our documentation.</p>"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#custom-pod-scheduling-policies","title":"Custom Pod scheduling policies","text":"<p>If you need more control, you can define custom Pod scheduling policies to manage how database pods are placed across Kubernetes nodes. These policies offer fine-grained control over pod distribution using Kubernetes affinity and anti-affinity rules.</p> <p>To create a custom policy, configure the scheduling rules via the Everest UI, as shown below:</p> <p></p> <p>\ud83d\udcd8 To explore this topic in detail, see our documentation.</p>"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#improved-security-with-tls-support","title":"Improved Security with TLS support","text":"<p>Starting with version 1.7.0, Percona Everest can be set up to use Transport Layer Security (TLS) for all incoming connections to the Everest API server. TLS encrypts communication between clients and the API server, safeguarding data from interception or tampering. </p> <p>Administrators can configure server certificates and private keys to enable secure HTTPS access. This enhances the overall security of production environments.</p> <p>\ud83d\udcd8 To explore this topic in detail, see our documentation.</p>"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#support-for-percona-xtradb-cluster-pxc-operator-1170","title":"Support for Percona XtraDB Cluster (PXC) operator 1.17.0","text":"<p>Percona Everest 1.7.0 now includes support for PXC Operator version 1.17.0.</p>"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#breaking-changes","title":"\ud83d\uded1 Breaking changes","text":""},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#pod-scheduling-policy-migration-for-gitops-users","title":"Pod scheduling policy migration for GitOps users","text":"<p>With the introduction of Pod scheduling policies in Percona Everest 1.7.0, a new field named <code>podSchedulingPolicyName</code> has been added to the <code>spec</code> section of the <code>DatabaseCluster</code> CRD.</p> <p>During the upgrade process to Percona Everest 1.7.0, we run a migration script to apply the default scheduling policies to existing DB clusters. However, if you are using GitOps to manage your Percona Everest deployment, you must manually add the <code>podSchedulingPolicyName</code> field to your <code>DatabaseCluster</code> CR manifests to ensure that the default scheduling policies are applied correctly.</p> <p>The default pod scheduling policies are predefined for each database engine and are as follows:</p> <ul> <li>MySQL: <code>everest-default-mysql</code></li> <li>MongoDB: <code>everest-default-mongodb</code></li> <li>PostgreSQL: <code>everest-default-postgresql</code></li> </ul> Example: MySQL DatabaseCluster CR manifest <p>Here\u2019s an example of <code>DatabaseCluster</code> CR manifest  with the <code>podSchedulingPolicyName</code> field:</p> <pre><code>apiVersion: everest.percona.com/v1alpha1\nkind: DatabaseCluster\nmetadata:\nname: my-database-cluster\nspec:\npodSchedulingPolicyName: everest-default-mysql # Specify the default MySQL scheduling policy\nengine:\n    type: pxc\n# Other fields...\n</code></pre>"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#oidc-integration-with-microsoft-entra-id","title":"OIDC integration with Microsoft Entra ID","text":"<p>If you are using Microsoft Entra ID as your OIDC provider for Percona Everest, please be aware of a breaking change in the way access tokens are validated. </p> <p>The access tokens issued by Microsoft Entra ID must now include the <code>aud</code> claim with the value set to the correct application identifier. This can be achieved by requesting the <code>&lt;your-app-client-id&gt;/.default</code> scope when obtaining the access token. Ensure that you configure Everest\u2019s OIDC settings requesting the correct scope to avoid any disruptions in your authentication flow:</p> <pre><code>everestctl settings oidc configure \\\n--issuer-url=http://url.com \\\n--client-id=&lt;your-app-client-id&gt; \\\n--scopes=openid,profile,email,&lt;your-app-client-id&gt;/.default\n</code></pre> <p>\ud83d\udcd8 For detailed information, see our documentation.</p>"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#new-features","title":"New Features","text":"<ul> <li> <p>EVEREST-1605: We\u2019ve introduced a Pod Scheduling Policy panel in the Advanced Configuration step of the DB cluster creation wizard. </p> <p>This feature allows you to define custom Affinity rules while creating a new DB cluster, providing greater control over pod placement and workload distribution.</p> </li> <li> <p>EVEREST-1606: You can now apply Affinity rules to existing DB clusters via a new Pod Scheduling Policy panel, which is available in the Advanced Configuration section of the DB cluster overview page.</p> <ul> <li>This feature allows users to enable the Pod Scheduling Policy for an individual DB cluster after its creation.</li> <li>Once enabled, users can select one of the predefined scheduling policies to influence pod placement according to their workload distribution or fault-tolerance needs.</li> </ul> </li> <li> <p>EVEREST-1607: Database administrators can now quickly view the current affinity configuration status directly from the DB Overview tab. Additionally, a direct navigation link to the Affinity section in the Components tab has been added, allowing administrators to access and modify Kubernetes affinity rules for the database components. </p> </li> <li> <p>EVEREST-1862: The Components tab now features a new Topology View to improve the visibility and management of DB clusters deployed in Percona Everest. This interactive view visually represents the components of the cluster, including pods, services, status, and their relationships.</p> </li> <li> <p>EVEREST-1987: We have added support for PXC operator v1.17.0.</p> </li> <li> <p>EVEREST-1998 Database administrators now have increased control over creating, updating, and deleting Pod Scheduling Policies. This improvement simplifies workload distribution in Percona Everest. Also, it helps to optimize resource utilization and efficiency, ensuring smoother operations and improved scheduling.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#improvements","title":"Improvements","text":"<ul> <li> <p>EVEREST-1106: Percona Everest administrators can now delete users created with <code>everestctl</code>. Once a user is removed, they can no longer use their access tokens to make requests to the Everest API. This improves security by preventing unauthorized access by former users and allows for better user permission management within Percona Everest.</p> </li> <li> <p>EVEREST-1180: Percona Everest can now be configured to use Transport Layer Security (TLS) for all incoming connections to the Everest API server.</p> </li> <li> <p>EVEREST-1901: When adding a Backup Bucket, trailing spaces at the end of the bucket name prevented it from being added. This issue often occurred when copying names, which caused confusion. We have resolved this by removing trailing spaces.</p> </li> <li> <p>EVEREST-1902: When adding \u00a0Monitoring Endpoint URLs, trailing spaces at the end of the URL prevented them from being added. This issue often occurred when copying URLs, leading to confusion. We have improved this by trimming trailing spaces.</p> </li> <li> <p>EVEREST-1974: The Storage Class field was previously non-editable when modifying a DB cluster in the Percona Everest UI, but the message stated that it could be changed based on performance needs. The UI now clearly shows that the Storage Class can only be selected during cluster creation.</p> </li> <li> <p>EVEREST-1914: Focus state is now correctly removed when users click outside of an input field on the UI. This enhances usability by ensuring that input fields no longer appear active after focus is lost.</p> </li> <li> <p>EVEREST-1923: The Everest API access token now becomes invalid immediately upon logout, preventing unauthorized access to your account.</p> </li> <li> <p>EVEREST-1931: We have improved the diagram view for the default zoom and search functionality of DB cluster components in the following ways:</p> <ul> <li>Default Zoom Level: A predefined zoom level is now set to ensure all components are visible upon loading.</li> <li>Reset View Button: This button allows you to reset the zoom level and reposition the view to its default settings.</li> <li>Search Functionality: A search bar has been added to the diagram view, similar to the one in the table view, making it easier to locate components.</li> </ul> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#bug-fixes","title":"Bug Fixes","text":"<ul> <li> <p>EVEREST-1623: We have resolved an issue where HAProxy kept restarting in a 5-node MySQL cluster, which caused connection instability and made the database unavailable.</p> </li> <li> <p>EVEREST-1651: Fixed a problem where creating a new MySQL database from a backup would fail if the database name exceeded a certain length.</p> </li> <li> <p>EVEREST-1700:  Fixed an issue where enabling PMM monitoring led to multiple unnecessary reconciliation cycles and pod restarts during database cluster creation, significantly slowing down startup times. A similar issue that occurred during cluster deletion, causing pod restarts before termination, has also been resolved.</p> </li> <li> <p>EVEREST-1754: Fixed an issue where the error message storage is (re)initializing was displayed on the UI intermittently.</p> </li> <li> <p>EVEREST-1785: Resolved an issue with the PITR pod for a one-node MySQL database that restarted multiple times.</p> </li> <li> <p>EVEREST-2011: The restore function for the MySQL database is now working correctly in PXC version 1.17.0.</p> </li> <li> <p>EVEREST-2018: The TLS installation instructions now accurately guide users on accessing the user interface (UI).</p> </li> <li> <p>EVEREST-1891: When trying to create a database from a backup with the same name as an existing database, there was no validation message or warning. The Continue button became unresponsive and did not provide any error message to the user. We have now resolved this issue.</p> </li> <li> <p>EVEREST-1984: Resolved an issue where creating multiple backup schedules in PostgreSQL led to an error.</p> </li> <li> <p>EVEREST-2025: Resolved an issue where the Content-Security-Policy header included an invalid <code>connect-src</code> value if the OIDC issuer URL ended with a trailing slash. The policy is now correctly generated.</p> <p>Thanks to @aurimasniekis for reporting and fixing this issue.</p> </li> <li> <p>EVEREST-343: Resolved an issue that caused Percona Everest installation to fail on Google Kubernetes Engine (GKE) Autopilot clusters.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#known-limitations","title":"Known limitations","text":""},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#upgrade-to-v170-fails-with-namespace-error","title":"Upgrade to v1.7.0 fails with Namespace error","text":"<p>If you installed Percona Everest version prior to 1.4.0 and successively upgraded to version 1.6.0, you may run into issues when upgrading to version 1.7.0.</p> <p>Workaround</p> <p>Run the following command before you upgrade to Percona Everest version 1.7.0:</p> <pre><code>kubectl label namespaces everest-system app.kubernetes.io/managed-\n</code></pre>"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#microsoft-entra-id","title":"Microsoft Entra ID","text":"<p>When integrating Microsoft Entra ID as your OIDC provider for Percona Everest, it\u2019s essential to ensure that the access tokens issued are compatible with Percona Everest\u2019s token validation logic.</p> <p>\ud83d\udcd8 For detailed information, see our documentation.</p>"},{"location":"release-notes/Percona-Everest-1.7.0-%282025-05-29%29.html#upgrade-now","title":"\ud83d\ude80 Upgrade now","text":"<p>Upgrade to Percona Everest 1.7.0 to access these new features and improvements. </p> <p>\ud83d\udcd8 Explore our Upgrade section for the upgrade steps.</p>"},{"location":"release-notes/Percona-Everest-1.8.0-%282025-07-16%29.html","title":"What\u2019s new in Percona Everest 1.8.0","text":"<p>\u27a1\ufe0f New to Percona Everest? Get started with our Quickstart Guide.</p> <p>Warning</p> <p>Single Sign-On (SSO) authentication with Microsoft Entra ID does not function in Percona Everest 1.8.0. To ensure it functions properly, upgrade to version 1.8.1.</p> Expand to unleash the key updates"},{"location":"release-notes/Percona-Everest-1.8.0-%282025-07-16%29.html#release-summary","title":"\ud83d\udccb Release summary","text":"# Category Description 1. Release highlight: Dataimporters in Percona Everest Import external database backups directly into clusters managed by Percona Everest 2. New features Check out the new features introduced in Percona Everest 1.8.0 3. Improvements Discover all the enhancements featured in Percona Everest 1.8.0 4. Bug fixes Find out about all the bugs fixed in Percona Everest 1.8.0 5. Known limitations Discover all the known limitations in Percona Everest 1.8.0"},{"location":"release-notes/Percona-Everest-1.8.0-%282025-07-16%29.html#release-highlights","title":"\ud83c\udf1f Release highlights","text":""},{"location":"release-notes/Percona-Everest-1.8.0-%282025-07-16%29.html#import-external-backups-into-percona-everest-clusters","title":"Import external backups into Percona Everest clusters","text":"<p>Technical Preview</p> <p>The external backup import feature in Percona Everest is currently in Technical Preview. Early adopters are advised to use this feature only for testing purposes and not in production environments.</p> <p>Starting with Percona Everest 1.8.0, we are excited to roll out a new feature that allows you to directly import backups of clusters managed by the Percona Operators for MongoDB, MySQL (XtraDB), and PostgreSQL, into clusters managed by Percona Everest. This feature leverages an extensible framework that streamlines your backup process.</p>"},{"location":"release-notes/Percona-Everest-1.8.0-%282025-07-16%29.html#key-features","title":"Key features","text":"<ul> <li> <p>Import database backups of clusters managed by the Percona Operators for MongoDB, MySQL (XtraDB), and PostgreSQL into database clusters managed by Percona Everest.</p> </li> <li> <p>Customize the import process using tools like <code>mongodump</code>, <code>pg_dump</code>, or <code>mysqldump</code>.</p> </li> <li> <p>A pluggable and extensible framework that can adapt to various import needs and workflows.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.8.0-%282025-07-16%29.html#how-to-import-external-database-backups-using-the-percona-everest-ui","title":"How to import external database backups using the Percona Everest UI","text":"<p>Here are the steps to import the external backups:</p> <ol> <li> <p>Navigate to the Percona Everest homepage and click Import.</p> </li> <li> <p>Select the database type you want to import (MySQL, PostgreSQL, or MongoDB). The Basic information page will be displayed.</p> </li> <li> <p>Fill in the details on the Basic information page and click Continue. This will take you to the Import information page.</p> </li> <li> <p>On the Import Information page, enter the following:</p> <ul> <li> <p>Choose the data importer from the dropdown.</p> </li> <li> <p>Provide S3 details.</p> <p></p> </li> <li> <p>Specify the File Directory path within your S3 bucket where the backup files are stored. Click Save.</p> <p>Refer to the documentation for details on the correct file path format.</p> <p></p> </li> <li> <p>Enter the key-value pairs of the user secrets (For MongoDB and MySQL) in the DB credentials section.</p> <p></p> </li> </ul> </li> <li> <p>Click Continue until you reach the end of the wizard. Once the import is successful, the database status will change to Up.</p> </li> </ol> <p>If you\u2019re looking to dive deeper into this feature, don\u2019t miss out on our comprehensive documentation.</p>"},{"location":"release-notes/Percona-Everest-1.8.0-%282025-07-16%29.html#new-features","title":"New features","text":"<ul> <li> <p>EVEREST-2068, EVEREST-2069, EVEREST-2070: Starting with Percona Everest 1.8.0, you can import external backups created using the Percona Operators for PostgreSQL, MySQL, and MongoDB into clusters managed by Percona Everest.</p> <p>While the default DataImporters are designed explicitly for backups compatible with Percona Operators, the DataImporters framework is flexible and extensible. This allows you to customize your import process using any backup and restore tools you prefer, such as <code>pg_dump</code>, <code>mysqldump</code>, <code>mongodump</code>, and others.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.8.0-%282025-07-16%29.html#improvements","title":"Improvements","text":"<ul> <li> <p>EVEREST-1806: We have improved the visibility of the proxy validation message when creating a MySQL database.</p> </li> <li> <p>EVEREST-1909: Duplicate IP/Netmask entries for external access are now prevented, ensuring accurate network configurations in database clusters.</p> </li> <li> <p>EVEREST-1946: Since disk resizing is an irreversible operation, Percona Everest now prompts for confirmation before applying disk size changes.</p> </li> <li> <p>EVEREST-1958: When you revisit a wizard step, Percona Everest now automatically expands any collapsed section that contains fields with validation errors. This enhances usability by ensuring errors are immediately visible and easier to resolve.</p> </li> <li> <p>EVEREST-1964: The Edit action in the upgrade section has been renamed to Upgrade to better reflect its purpose, as upgrading is the only supported action in that context.</p> </li> <li> <p>EVEREST-2002: In the Helm upgrade flow, Percona Everest now performs a pre-check to validate CRD compatibility before proceeding with the upgrade. This helps prevent cluster breakage by ensuring that all required Custom Resource Definitions are present and compatible, improving upgrade reliability.</p> </li> <li> <p>EVEREST-2003: The expandable section in the Database Overview page has been removed for an enhanced UX.</p> </li> <li> <p>EVEREST-2005: We\u2019ve added a View DB status Details option to the Actions menu on the Overview page, providing quicker access to database status and cluster-specific information.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.8.0-%282025-07-16%29.html#bug-fixes","title":"Bug fixes","text":"<ul> <li> <p>EVEREST-1838: The Edit option for Point-in-Time Recovery (PITR) was incorrectly disabled for MySQL and MongoDB clusters, even when PITR was enabled. This issue has now been resolved.</p> </li> <li> <p>EVEREST-1890: During MySQL database cluster creation, the selected number of proxies was incorrectly reset to 1 in the UI. The proxy count now reflects the user\u2019s selection accurately.</p> </li> <li> <p>EVEREST-1895: Resolved an issue where the Point-in-Time Recovery (PITR) time could not be adjusted from the last successful backup. Users can now modify the PITR time as intended.</p> </li> <li> <p>EVEREST-1948: The component Age was previously displayed incorrectly on the Components tab. It now reflects the accurate age of each component.</p> </li> <li> <p>EVEREST-2001: Addressed an issue where the Disk, CPU, and Memory input fields became unresponsive or difficult to edit when large values were entered. Input behavior is now consistent and reliable across all value ranges.</p> </li> <li> <p>EVEREST-2030: Fixed an issue where users were not logged out after account deletion. The UI remained active even though the API token had been invalidated. The session is now properly terminated upon deletion.</p> </li> <li> <p>EVEREST-2037: Fixed an issue where the <code>Policy is being used</code> message appeared even when the policy was not linked to any database.</p> </li> <li> <p>EVEREST-2043: While running <code>everestctl install</code>, setting <code>pmm.enabled=true</code> caused PMM to be deployed in the default namespace instead of the <code>everest-system</code> namespace. PMM is now correctly deployed in the <code>everest-system</code> namespace, ensuring consistency with <code>helm install</code>.</p> </li> <li> <p>EVEREST-2052: The PMM client was terminated due to out-of-memory (OOM) errors under specific workloads. This issue has now been resolved.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.8.0-%282025-07-16%29.html#known-limitations","title":"Known limitations","text":""},{"location":"release-notes/Percona-Everest-1.8.0-%282025-07-16%29.html#helm-upgrade-requirement-for-percona-everest-180","title":"Helm upgrade requirement for Percona Everest 1.8.0","text":"<ul> <li>To upgrade from Percona Everest 1.8.0, you have to use the <code>--take-ownership</code> flag, which is available only in Helm CLI v3.17.0 or later. If you need to upgrade with an older version of the Helm CLI, the upgrade may fail due to CRD ownership validation errors. However, you can manually add the required labels and annotations to the Percona Everest CRDs to avoid this issue. For detailed steps on this process, refer to our documentation. </li> </ul>"},{"location":"release-notes/Percona-Everest-1.8.0-%282025-07-16%29.html#limitations-for-dataimporters","title":"Limitations for DataImporters","text":"<ul> <li> <p>Importing backups into sharded MongoDB clusters is currently not supported. The <code>DataImporter</code> for MongoDB only works with non-sharded clusters.</p> </li> <li> <p>Percona Everest does not validate file paths or verify the existence of files in the specified storage buckets. Make sure that the backup directory path is correct and accessible.</p> </li> <li> <p>For some data import methods, you must provide database user credentials that match those of the source database. Percona Everest does not validate these credentials, so ensure they are accurate.</p> </li> <li> <p>Percona Everest does not verify the compatibility of imported data with the version of the target DatabaseCluster. Ensure that the backup is compatible with the database version managed by Percona Everest.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.8.0-%282025-07-16%29.html#ready-to-upgrade","title":"\ud83d\ude80 Ready to Upgrade?","text":"<p>Upgrade to Percona Everest 1.8.0 to access these new features and improvements.</p> <p>\ud83d\udcd6 Explore our Upgrade section for the upgrade steps.</p>"},{"location":"release-notes/Percona-Everest-1.8.1-%282025-08-11%29.html","title":"What\u2019s new in Percona Everest 1.8.1","text":"<p>\u27a1\ufe0f New to Percona Everest? Get started with our Quickstart Guide.</p>"},{"location":"release-notes/Percona-Everest-1.8.1-%282025-08-11%29.html#fixed-issue","title":"Fixed issue","text":"<p>EVEREST-2210: We have resolved an issue that caused Single Sign-On (SSO) authentication with Microsoft Entra ID to fail after upgrading to Percona Everest 1.8.0.</p>"},{"location":"release-notes/Percona-Everest-1.8.1-%282025-08-11%29.html#ready-to-upgrade","title":"\ud83d\ude80 Ready to Upgrade?","text":"<p>Upgrade to Percona Everest 1.8.1 to access these new features and improvements.</p> <p>\ud83d\udcd6 Explore our Upgrade section for the upgrade steps.</p>"},{"location":"release-notes/Percona-Everest-1.9.0-%282025-09-23%29.html","title":"What\u2019s new in Percona Everest 1.9.0","text":"<p>ACTION REQUIRED: Percona Everest and Bitnami Container Catalog changes</p> <p>Bitnami is restructuring its container catalog on September 29, 2025. To avoid potential failures in Percona Everest operations, follow the steps outlined in this post.</p> <p>\u27a1\ufe0f New to Percona Everest? Get started with our Quickstart Guide.</p> Expand to unleash the key updates"},{"location":"release-notes/Percona-Everest-1.9.0-%282025-09-23%29.html#release-summary","title":"\ud83d\udccb Release summary","text":"# Category Description 1. Release highlight: Load Balancer configuration in Percona Everest Define reusable LoadBalancer configurations in Percona Everest. 2. New features Check out the new features introduced in Percona Everest 1.9.0 3. Improvements Discover all the enhancements featured in Percona Everest 1.9.0 4. Bug fixes Find out about all the bugs fixed in Percona Everest 1.9.0 5. Known limitations Discover all the known limitations in Percona Everest 1.9.0"},{"location":"release-notes/Percona-Everest-1.9.0-%282025-09-23%29.html#release-highlights","title":"\ud83c\udf1f Release highlights","text":""},{"location":"release-notes/Percona-Everest-1.9.0-%282025-09-23%29.html#load-balancer-configuration-in-percona-everest","title":"\ud83c\udf10 Load balancer configuration in Percona Everest","text":"<p>Provisioning external access to Kubernetes clusters can be challenging, since cloud providers like AWS, GCP, and Azure each have their own annotations and configurations for LoadBalancers. As a result, users often have to manually adjust settings for each environment, leading to a lack of a unified approach.</p> <p>Percona Everest simplifies the process by enabling administrators to define reusable LoadBalancer configurations. This includes cloud provider-specific settings that can be applied consistently across clusters, ensuring:</p> <ul> <li> <p>\u2705 Consistency across cloud and on-prem environments</p> </li> <li> <p>\ud83d\udd04 Reduced manual effort when provisioning external access</p> </li> <li> <p>\ud83c\udf0d Flexibility to support multiple cloud providers with a unified approach</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.9.0-%282025-09-23%29.html#how-to-create-a-load-balancer-configuration","title":"How to create a load balancer configuration","text":"<p>Here\u2019s how you can create a load balancer configuration:</p> <ol> <li> <p>Open Policies </p> <ul> <li>Navigate to the Percona Everest home page, go to  Settings &gt; Policies, and open the Load Balancer Configuration section.</li> </ul> <p></p> </li> <li> <p>Create configuration</p> <ul> <li> <p>Click Create configuration.</p> </li> <li> <p>Enter a Configuration name and click Create.</p> </li> </ul> <p></p> </li> <li> <p>Add Annotations</p> <ul> <li>Click Add new, then enter the required annotations (key-value pairs).</li> </ul> <p></p> <p>Note</p> <p>The key and value in a Load Balancer configuration for Percona Everest are derived from your Kubernetes environment and the load balancer implementation by your cloud provider.</p> Examples of keys and values used for Load balancer configuration <pre><code>service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\"                    # Use Network Load Balancer (NLB)\nservice.beta.kubernetes.io/aws-load-balancer-scheme: \"internet-facing\"        # Internet-facing vs. internal\nservice.beta.kubernetes.io/aws-load-balancer-internal: \"true\"                   # Internal LB\nservice.beta.kubernetes.io/aws-load-balancer-ssl-cert: \"arn:aws:acm:...\"        # Attach ACM SSL cert\nservice.beta.kubernetes.io/aws-load-balancer-ssl-ports: \"443\"                   # SSL termination ports\nservice.beta.kubernetes.io/aws-load-balancer-backend-protocol: \"http\"        # Protocol between LB and pods\n</code></pre> </li> <li> <p>Save configuration</p> <ul> <li>Click Save configuration, then go Back to view the newly created load balancer configuration.</li> </ul> <p></p> </li> </ol>"},{"location":"release-notes/Percona-Everest-1.9.0-%282025-09-23%29.html#new-features","title":"New features","text":"<ul> <li>EVEREST-548: Starting with Percona Everest 1.9.0, we have added support for managing <code>LoadBalancerConfigs</code>, simplifying how service annotations are applied to database clusters.</li> </ul>"},{"location":"release-notes/Percona-Everest-1.9.0-%282025-09-23%29.html#improvements","title":"Improvements","text":"<ul> <li> <p>EVEREST-2002: Upgrading via Helm now requires manually upgrading the CRDs first before upgrading Percona Everest.</p> </li> <li> <p>EVEREST-2101: The behavior of the Add New button in the External Access section has been improved. Now, you can only add a new field after filling in the previously created field with a value.</p> <p>This enhancement ensures users complete the required information before adding more entries, reducing unnecessary blank fields and improving the overall user experience.</p> </li> <li> <p>EVEREST-2114: The search and filter options now always remain visible on the left side, ensuring a consistent layout and easier navigation.</p> </li> <li> <p>EVEREST-2165: We have added a show password toggle in the PMM monitoring endpoint form. This feature helps us verify if we have entered the correct password.</p> </li> <li> <p>EVEREST-2244: Load balancer config field changes</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.9.0-%282025-09-23%29.html#bug-fixes","title":"Bug fixes","text":"<ul> <li> <p>EVEREST-1012: When creating a new PostgreSQL database using Point-in-Time Recovery (PITR), the restore page previously displayed no information after the database was restored. This issue has been resolved, and the restore page now correctly shows the restore details</p> </li> <li> <p>EVEREST-1961: We have fixed an issue that allowed users to enter invalid monitoring endpoint URLs when editing a monitoring instance, due to a lack of proper validation. This caused databases (MySQL, MongoDB, and PostgreSQL) with scheduled backups and Point-in-Time Recovery (PITR) enabled to restart unexpectedly. Also, it failed to verify the username and password, even for valid URLs.</p> </li> <li> <p>EVEREST-2017: Previously, restoring a backup from one cluster to a new cluster using MinIO storage with Percona XtraDB Cluster (PXC) failed. This issue has been fixed. Backups stored in MinIO can now be successfully restored to new clusters.</p> </li> <li> <p>EVEREST-2031: The Create Policy page previously expanded when an error message was shown. We\u2019ve resolved the issue now, and it displays errors without affecting the page layout.</p> </li> <li> <p>EVEREST-2092: Upgrades using <code>everestctl</code> failed when the initial installation was older than version 1.4.0 and had been successively upgraded to version 1.7.0. The issue has now been resolved.</p> </li> <li> <p>EVEREST-2097: In the Topology Diagram view, the restart information on database cluster cards was misaligned and appeared outside the component card, disrupting the visual layout. This issue has been resolved, and the information now displays correctly within the card.</p> </li> <li> <p>EVEREST-2105: When creating a database from a backup, no error message was displayed on the Basic Information page if the original database name was too long. Now, a clear message will appear on the Basic Information page if the name exceeds the allowed length.</p> </li> <li> <p>EVEREST-2142: When creating a PostgreSQL database, the Host field was updating automatically, but the Username, Password, and Connection URL fields remained empty until the page was manually refreshed. This issue has now been resolved, and all connection details automatically populate once the database is created.</p> </li> <li> <p>EVEREST-2148: Fixed an issue where creating a database from a backup failed if the original database\u2019s user secret did not conform to the required naming convention.</p> </li> <li> <p>EVEREST-2153: Fixed a bug where imported secrets were not deleted if the database was removed during the import process.</p> </li> <li> <p>EVEREST-2202: Previously, database imports failed if the database name exceeded 16 characters. The issue has been resolved now.</p> </li> <li> <p>EVEREST-2206: Resolved an issue that caused Single Sign-On (SSO) to be disabled after upgrading from version 1.6.0 to 1.7.0.</p> </li> <li> <p>EVEREST-2207: Resolved an issue that prevented the successful upgrade of Percona Everest.</p> </li> <li> <p>EVEREST-2211: Previously, PostgreSQL databases would fail to start and crash after performing a Point-in-Time Recovery (PITR). This issue has been resolved, and PostgreSQL now starts up and operates normally after a PITR restoration.</p> </li> <li> <p>EVEREST-2212: The PMM Client previously consumed excessive memory when monitoring was enabled for any database instance. The issue has been resolved now.</p> </li> <li> <p>EVEREST-2214: Percona Everest upgrades previously failed if the <code>everest-system</code> and <code>everest-monitoring</code> namespaces had the label <code>app.kubernetes.io/managed-by=everest</code>. The issue has been resolved now.</p> </li> <li> <p>EVEREST-2216: Fixed an issue that caused the Pod Scheduling Policy field to reset to enabled after clicking the Continue or Previous buttons.</p> </li> <li> <p>EVEREST-2100: After upgrading Everest, editing a cluster with a duplicate IP/Netmask disabled the Save button without displaying an error message. The issue has been resolved now.</p> </li> <li> <p>EVEREST-2096: Addressed multiple issues with the External Access field\u2019s behavior, validation, and usability during cluster creation and editing.</p> </li> <li> <p>EVEREST-2228: Previously, installing Everest on OpenShift caused the Operator Lifecycle Manager (OLM) CRDs from the Helm chart to overwrite existing OLM CRDs on the cluster, leading to unexpected behavior and compatibility issues. The issue has been resolved now.</p> </li> </ul>"},{"location":"release-notes/Percona-Everest-1.9.0-%282025-09-23%29.html#known-limitations","title":"Known limitations","text":"<p>To learn about the specific limitations regarding Load Balancer configuration, check out the dedicated section on Load balancer limitations.</p>"},{"location":"release-notes/Percona-Everest-1.9.0-%282025-09-23%29.html#ready-to-upgrade","title":"\ud83d\ude80 Ready to Upgrade?","text":"<p>Upgrade to Percona Everest 1.9.0 to access these new features and improvements.</p> <p>\ud83d\udcd6 Explore our Upgrade section for the upgrade steps.</p>"},{"location":"release-notes/release_notes_index.html","title":"Percona Everest release notes index","text":"<ul> <li> <p>Percona-Everest 1.9.0 (2025-09-23)</p> </li> <li> <p>Percona-Everest 1.8.1 (2025-08-11)</p> </li> <li> <p>Percona-Everest 1.8.0 (2025-07-16)</p> </li> <li> <p>Percona Everest 1.7.0 (2025-05-29)</p> </li> <li> <p>Percona Everest 1.6.0 (2025-04-16)</p> </li> <li> <p>Percona Everest 1.5.0 (2025-03-04)</p> </li> <li> <p>Percona Everest 1.4.0 (2025-01-07)</p> </li> <li>Percona Everest 1.3.0 (2024-11-18)</li> <li>Percona Everest 1.2.0 (2024-10-01)</li> <li>Percona Everest 1.1.1 (2024-08-22)</li> <li>Percona Everest 1.1.0 (2024-08-12)</li> <li>Percona Everest 1.0.1 (2024-07-08)</li> <li>Percona Everest 1.0.0 (2024-06-28)</li> <li>Percona Everest 0.10.1 (2024-05-23)</li> <li>Percona Everest 0.10.0 (2024-05-03)</li> <li>Percona Everest 0.9.1 (2024-04-02)</li> <li>Percona Everest 0.9.0 (2024-04-01)</li> <li>Percona Everest 0.8.0 (2024-02-22)</li> <li>Percona Everest 0.7.0 (2024-01-31)</li> <li> <p>Percona Everest 0.6.0 (2024-01-11)</p> </li> <li> <p>Percona Everest 0.5.0 (2023-11-28)</p> </li> <li> <p>Percona Everest 0.4.0 (2023-10-30)</p> </li> </ul>"},{"location":"security/session_management.html","title":"Session Management","text":"<p>Session management is the process of handling user sessions to keep them secure, efficient, and continuous. It is used in applications that manage user authentication and authorization, such as web services, databases, and DBaaS platforms.</p>"},{"location":"security/session_management.html#percona-everest-authentication-methods","title":"Percona Everest authentication methods","text":"<p>Percona Everest supports two authentication methods:</p> <ul> <li> <p>Built-in authentication: Suitable for non-production environments</p> </li> <li> <p>External Identity Provider (IdP) authentication: Suitable for production use and enables integration with systems such as Okta and Azure AD.</p> </li> </ul>"},{"location":"security/session_management.html#how-authentication-works-in-percona-everest","title":"How authentication works in Percona Everest","text":"<p>Everest uses access tokens to authenticate users:</p> <ul> <li>Built-in authentication:  Percona Everest generates and manages the access tokens directly.</li> <li>External IdP authentication: The tokens are issued and controlled by the IdP.</li> </ul> <p>Starting with Percona Everest 1.7.0, the access tokens will now be invalidated in the following scenarios:</p> <ul> <li> <p>Once the user has logged out: This applies to both the built-in users and IdP.</p> </li> <li> <p>Once a user is deleted: This only applies to built-in users. The access token for users from an IdP will remain valid until it expires, so we recommend setting a short expiration period for these access tokens.</p> </li> </ul> <p> Important</p> <p>For IdP, we recommend using:</p> <ul> <li>Short-lived access tokens (such as 5 minutes)</li> <li>Long-lived refresh tokens</li> </ul> <p>For more details, refer to the Okta guide on refresh tokens.</p>"},{"location":"security/sso_idp_integration.html","title":"SSO: Percona Everest IdP integration","text":"<p>Identity Provider (IdP) integration connects applications and services with an external identity provider for your organization. This enables centralized authentication and authorization management, improving security and simplifying user access. By leveraging IdP integration, you can ensure that users are securely authenticated and authorized to access various applications and services across your organization.</p> <p>Percona Everest uses OpenID Connect (OIDC) Protocol to integrate with external Identity Providers (IdP).</p> <p>Note</p> <p>To integrate IdP with Percona Everest, first, install Percona Everest and then configure OIDC on the IdP\u2019s side as well as the Percona Everest side.</p>"},{"location":"security/sso_idp_integration.html#configure-oidc-on-the-provider-side","title":"Configure OIDC on the provider side","text":"<ul> <li> <p>Proof Key for Code Exchange (PKCE): When setting up the Provider side, it\u2019s important to configure an application specifically for PKCE authorization.</p> </li> <li> <p>Redirect URIs: </p> <ul> <li>Sign-in redirect URIs should point to <code>&lt;EVEREST_URL&gt;/login-callback</code>.</li> <li> <p>Sign-out redirect URIs should point to <code>&lt;EVEREST_URL&gt;</code>.</p> <p>Important</p> <p>IdP providers often require a secure connection (HTTPS). Therefore, the provider might require your <code>&lt;EVEREST_URL&gt;</code> to be based on HTTPS. If your provider requires this, consider adding a reverse proxy in front of Percona Everest to provide such functionality.</p> </li> </ul> </li> </ul>"},{"location":"security/sso_idp_integration.html#example-oidc-configuration-on-the-provider-side","title":"Example: OIDC configuration on the provider side","text":"<p>Below is an example of the configuration for the IdP provider Okta. </p> <p>Other popular IdPs include Microsoft Azure Active Directory, Auth0, Google Identity Platform, etc.</p> OKTA <ol> <li> <p>Sign in to your Okta organization as a user with administrative privileges.</p> </li> <li> <p>In the Admin Console, go to Applications \u2192 Applications and click Create App Integration.</p> </li> <li> <p>On the Create a new app integration page, set the following:</p> <ul> <li>Sign-in method - OIDC - OpenID Connect</li> <li>Application type - Single-Page Application, and click Next.</li> </ul> <p></p> </li> <li> <p>Set the following fields:</p> <p>a. App integration name - any value</p> <p>b. Sign-in redirect URIs - <code>&lt;EVEREST_URL&gt;/login-callback</code></p> <p>c. Sign-out redirect URIs - <code>&lt;EVEREST_URL&gt;</code></p> <p>Note</p> <p>Okta allows the use of HTTP for development purposes and in cases where the Admin explicitly permits it.</p> <p></p> <p>d. Click Save.</p> <p>e. Copy the <code>clientID</code> of the created app.</p> <p></p> <p>f. Navigate to Security \u2192 API \u2192 Authorization Servers and copy the <code>issuerURL</code> you\u2019d like to use for the Everest authorization. </p> <p></p> <p>Note</p> <p>The values shown are for demonstration purposes only. Replace them with your actual Okta configuration.</p> </li> </ol>"},{"location":"security/sso_idp_integration.html#configure-oidc-on-the-percona-everests-side","title":"Configure OIDC on the Percona Everest\u2019s side","text":"<p>You can configure OIDC on the Percona Everest\u2019s side using <code>everestctl</code> in headless mode or with the wizard.</p> <p>Note</p> <p>You must have obtained the <code>Issuer URL</code> and <code>Client ID</code> values from the Configure OIDC on the provider side section.</p> <p>To configure OIDC using the headless mode, run the following command:</p> <pre><code>everestctl settings oidc configure --issuer-url=http://url.com --client-id=&lt;your-app-client-id\n</code></pre> Output <pre><code>2024-06-18T11:06:18Z    info    oidc/configure.go:110   OIDC provider configured, restarting Everest..\n2024-06-18T11:06:33Z    info    oidc/configure.go:117   OIDC has been configured successfully\n</code></pre> <p>To configure OIDC using the wizard, run the following command:</p> <pre><code>$ everestctl settings oidc configure\n</code></pre> Output <pre><code>? Enter issuer URL &lt;your-provider-url&gt;\n? Enter client ID &lt;your-app-client-id&gt;\n2024-06-18T11:05:15Z    info    oidc/configure.go:110   OIDC provider   configured, restarting Everest..    \n2024-06-18T11:05:30Z    info    oidc/configure.go:117   OIDC has been configured successfully\n</code></pre> What\u2019s happening under the hood? <p>This command stores the updated configuration in k8s and restarts the Everest deployment.</p> <ol> <li> <p>Store Configuration</p> <p>The OIDC settings are stored in the <code>everest-settings</code> ConfigMap in the <code>everest-system</code> namespace, along with other settings, in the following format:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n    name: everest-settings\n    namespace: everest-system\ndata:\n    data:\n    oidc.config: |\n        issuerUrl: &lt;your OIDC provider URL&gt;\n        clientId: &lt;your OIDC provider client ID&gt;\n</code></pre> <p>The Everest user should not directly interact with the <code>everest-settings</code> ConfigMap. Use the <code>everestctl</code> command to set up the OIDC config.</p> </li> <li> <p>Restart Percona Everest</p> <p>OIDC configuration must be in place for Percona Everest to start the API Server, allowing the server to utilize the OIDC provider\u2019s validation. This means that after setting up the OIDC configuration, the Percona Everest API Server needs to be restarted.</p> <p>The <code>everestctl</code> command typically takes approximately 15 seconds to execute. It waits for the Everest Deployment to be up again before exiting successfully.</p> <p>Important</p> <ul> <li> <p>The restart only impacts the Everest UI and API. Database clusters are not affected.</p> </li> <li> <p>The restart results in the loss of the port-forwarding connection. If you had port-forwarding enabled on your machine to access Percona Everest UI and API, you will need to set it up again.</p> </li> </ul> </li> </ol>"},{"location":"security/sso_idp_integration.html#testing-idp-integration","title":"Testing IdP integration","text":"<p>After setting up your OIDC configuration, you can verify the functionality by visiting the Percona Everest login page and attempting to log in using Single Sign-On (SSO).</p> <p></p>"},{"location":"security/sso_idp_integration.html#percona-everest-oidc-configuration-for-microsoft-entra","title":"Percona Everest OIDC configuration for Microsoft Entra","text":"<p>When configuring Everest\u2019s OIDC settings via <code>everestctl</code>, ensure you specify the correct scope:</p> <pre><code>everestctl settings oidc configure \\\n--issuer-url=http://url.com \\\n--client-id=&lt;your-app-client-id&gt; \\\n--scopes=openid,profile,email,&lt;your-app-client-id&gt;/.default\n</code></pre> <p>Note</p> <p>Replace <code>&lt;your-app-client-id&gt;</code> with your actual Microsoft Entra application (client) ID, and ensure the issuer-url points to the correct tenant.</p> <p>With this configuration, the access token will include <code>\"aud\": \"&lt;your-app-client-id&gt;\"</code>, and it will have a valid signature that Percona Everest can verify.</p> <p>For a detailed explanation, see the OIDC integration limitations with Microsoft Entra.</p>"},{"location":"security/tls_setup.html","title":"TLS support for Percona Everest","text":"<p>Percona Everest can be configured to use Transport Layer Security (TLS) for all incoming connections to the Everest API server. TLS ensures that communication between clients and the API server is encrypted, protecting data from interception or tampering. Administrators can configure server certificates and private keys to enable secure HTTPS access, enhancing the overall security posture for production environments.</p> <p>Note</p> <ul> <li>When TLS is enabled, the default server port (8080) will only accept <code>https</code> traffic, and <code>http</code> traffic will be rejected.</li> <li>We do not support redirects from <code>http</code> to <code>https</code>.</li> <li>Self-signed certificates aren\u2019t trusted by most browsers, so it\u2019s best to use a trusted certificate from a Certificate Authority (CA) in production.</li> </ul>"},{"location":"security/tls_setup.html#tls-setup-with-percona-everest","title":"TLS setup with Percona Everest","text":"<p>Important</p> <p>This section provides an example using Helm. You can also use the provided options with <code>everestctl</code> by using the flag <code>--helm.set</code>.</p>"},{"location":"security/tls_setup.html#use-cert-manager-recommended","title":"Use Cert-manager (recommended)","text":""},{"location":"security/tls_setup.html#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Ensure that cert-manager has been deployed on your Kubernetes cluster.</p> </li> <li> <p>Ensure that you have a properly configured Issuer or ClusterIssuer in place. See the documentation for details.</p> </li> </ul>"},{"location":"security/tls_setup.html#set-up-percona-everest-using-cert-manager","title":"Set up Percona Everest using cert-manager","text":"<p>Here are the steps to set up the Percona Everest server using cert-manager:</p> <ol> <li> <p>Create a configuration file named <code>values.yaml</code>:</p> <pre><code>server:\n  tls: \n    enabled: true\n    certificate:\n      create: true\n      domain: example.com\n      issuer:\n        group: cert-manager.io\n        kind: ClusterIssuer \n        name: your-cluster-issuer\n</code></pre> <p>Replace example.com with your actual domain name.</p> </li> <li> <p>Install Percona Everest using the above values:</p> <pre><code>helm install everest-core percona/everest --create-namespace \\\n-n everest-system \\\n-f values.yaml\n</code></pre> </li> </ol> Alternative methods for configuring TLS in Percona Everest"},{"location":"security/tls_setup.html#use-self-signed-certificates","title":"Use self-signed certificates","text":"<p>Use self-signed certificates (automatically generated during installation):</p> <pre><code>helm install everest-core percona/everest --create-namespace \\\n-n everest-system \\\n--set server.tls.enabled=true\n</code></pre>"},{"location":"security/tls_setup.html#configure-tls-with-custom-certificates","title":"Configure TLS with custom certificates","text":"<p>Here are the steps to set up the Percona Everest server using custom certificates:</p> <ol> <li> <p>Prepare your certificate public key (<code>tls.crt</code>) and private key (<code>tls.key</code>) files. </p> </li> <li> <p>Create a configuration file named <code>values.yaml</code>:</p> <pre><code>server:\n  tls: \n    enabled: true\n    secret:\n      certs:\n        tls.key: YOUR_PRIVATE_KEY_FILE\n        tls.crt: YOUR_CERTIFICATE_FILE\n</code></pre> <p>Replace <code>YOUR_PRIVATE_KEY_FILE</code> and <code>YOUR_CERTIFICATE_FILE</code> with the actual contents of your public and private key files.</p> </li> <li> <p>Install Percona Everest using the above values:</p> <pre><code>helm install everest-core percona/everest --create-namespace \\\n-n everest-system \\\n-f values.yaml\n</code></pre> </li> </ol>"},{"location":"uninstall/uninstallEverest.html","title":"Uninstall Percona Everest using everestctl","text":"<p>ACTION REQUIRED: Percona Everest and Bitnami Container Catalog changes</p> <p>Bitnami is restructuring its container catalog on September 29, 2025. To avoid potential failures in Percona Everest operations, follow the steps outlined in this post.</p> <p>important</p> <p>If you installed Percona Everest using <code>everestctl</code>, make sure to uninstall it exclusively through <code>everestctl</code> for a seamless removal.</p> <p>You can run the commands below to remove all Everest resources including:</p> <ul> <li>All Kubernetes objects created by Everest</li> <li>All downloaded binaries and files like everestctl.</li> </ul> <p>Warning</p> <p>Uninstalling Everest will remove all database clusters and associated data from the Kubernetes cluster, including backups!</p> <p>To uninstall Percona Everest, follow these steps:</p> <ol> <li> <p>Run the following command:</p> <pre><code>everestctl uninstall\n</code></pre> </li> <li> <p>Remove the unused Custom Resource Definitions (CRDs).</p> <p>warning</p> <ul> <li>Deleting CRDs can potentially cause issues with any custom resources that depend on those definitions within the kubernetes cluster. Ensure that you do not remove any CRDs that are being used by operator deployments outside of Everest.</li> </ul> </li> </ol>"},{"location":"uninstall/uninstallEverest.html#how-to-remove-crds","title":"How to remove CRDs","text":"<p>During the installation of Everest, the following operators are installed:</p> <ul> <li>Everest</li> <li>VictoriaMetrics</li> <li>OLM</li> </ul> <p>Besides the operators mentioned above, you must have installed at least one of the following operators.</p> <ul> <li>Percona Operator for MySQL(PXC)</li> <li>Percona Operator for MongoDB(PSMDB)</li> <li>Percona Operator for PostgreSQL</li> </ul>"},{"location":"uninstall/uninstallEverest.html#list-of-crds-for-the-operators","title":"List of CRDs for the operators","text":"<p>Below is a list of CRDs for different operators.</p> CRDs of operators installed with Percona EverestCRDs of optional operators that you selected (at least one) OLM operator <pre><code>catalogsources.operators.coreos.com\nclusterserviceversions.operators.coreos.com\ninstallplans.operators.coreos.com\nolmconfigs.operators.coreos.com\noperatorconditions.operators.coreos.com\noperatorgroups.operators.coreos.com\noperators.operators.coreos.com\nsubscriptions.operators.coreos.co\n</code></pre> VictoriaMetrics operator <pre><code>vmrules.operator.victoriametrics.com\nvmnodescrapes.operator.victoriametrics.com\nvmauths.operator.victoriametrics.com\nvmprobes.operator.victoriametrics.com\nvmpodscrapes.operator.victoriametrics.com\nvmsingles.operator.victoriametrics.com\nvmstaticscrapes.operator.victoriametrics.com\nvmservicescrapes.operator.victoriametrics.com\nvmalertmanagerconfigs.operator.victoriametrics.com\nvmalertmanagers.operator.victoriametrics.com\nvmalerts.operator.victoriametrics.com\nvmagents.operator.victoriametrics.com\nvmclusters.operator.victoriametrics.com\nvmusers.operator.victoriametrics.com\nvmscrapeconfigs.operator.victoriametrics.com\nvlogs.operator.victoriametrics.com\n</code></pre> Everest operator <pre><code>databaseclusterbackups.everest.percona.com\ndatabaseclusters.everest.percona.com\ndatabaseengines.everest.percona.com\nbackupstorages.everest.percona.com\ndatabaseclusterrestores.everest.percona.com\nmonitoringconfigs.everest.percona.com\n</code></pre> PXC operator <pre><code>perconaxtradbclusterbackups.pxc.percona.com\nperconaxtradbclusterrestores.pxc.percona.com\nperconaxtradbclusters.pxc.percona.com\n</code></pre> PSMDB operator <pre><code>perconaservermongodbbackups.psmdb.percona.com\nperconaservermongodbrestores.psmdb.percona.com\nperconaservermongodbs.psmdb.percona.com\n</code></pre> PostgreSQL operator (Percona and CrunchyData) <pre><code>perconapgbackups.pgv2.percona.com\nperconapgclusters.pgv2.percona.com\nperconapgrestores.pgv2.percona.com\nperconapgupgrades.pgv2.percona.com\ncrunchybridgeclusters.postgres-operator.crunchydata.com\npgadmins.postgres-operator.crunchydata.com\npgupgrades.postgres-operator.crunchydata.com\npostgresclusters.postgres-operator.crunchydata.com\n</code></pre> <p>warning</p> <p>The Percona Operator for PostgreSQL is a fork of the Crunchy Data\u2019s Postgres operator. Thus, if you are using the Crunchy Data\u2019s Postgres operator, do not remove the CRD <code>postgresclusters.postgres-operator.crunchydata.com.</code></p>"},{"location":"uninstall/uninstallEverest.html#examples-for-removing-crds","title":"Examples for removing CRDs","text":"<p>Here are some examples of how to remove the CRDs.</p>"},{"location":"uninstall/uninstallEverest.html#remove-all-the-crds","title":"Remove all the CRDs","text":"<p>To remove all the CRDS, you can use the following command:</p> <pre><code>cat &lt;&lt;EOF | xargs kubectl delete crd\ncatalogsources.operators.coreos.com\nclusterserviceversions.operators.coreos.com\ninstallplans.operators.coreos.com\nolmconfigs.operators.coreos.com\noperatorconditions.operators.coreos.com\noperatorgroups.operators.coreos.com\noperators.operators.coreos.com\nsubscriptions.operators.coreos.com\nvmrules.operator.victoriametrics.com\nvmnodescrapes.operator.victoriametrics.com\nvmauths.operator.victoriametrics.com\nvmprobes.operator.victoriametrics.com\nvmpodscrapes.operator.victoriametrics.com\nvmsingles.operator.victoriametrics.com\nvmstaticscrapes.operator.victoriametrics.com\nvmservicescrapes.operator.victoriametrics.com\nvmalertmanagerconfigs.operator.victoriametrics.com\nvmalertmanagers.operator.victoriametrics.com\nvmalerts.operator.victoriametrics.com\nvmagents.operator.victoriametrics.com\nvmclusters.operator.victoriametrics.com\nvmusers.operator.victoriametrics.com\nvmscrapeconfigs.operator.victoriametrics.com\nvlogs.operator.victoriametrics.com\ndatabaseclusterbackups.everest.percona.com\ndatabaseclusters.everest.percona.com\ndatabaseengines.everest.percona.com\nbackupstorages.everest.percona.com\ndatabaseclusterrestores.everest.percona.com\nmonitoringconfigs.everest.percona.com\nperconaxtradbclusterbackups.pxc.percona.com\nperconaxtradbclusterrestores.pxc.percona.com\nperconaxtradbclusters.pxc.percona.com\nperconaservermongodbbackups.psmdb.percona.com\nperconaservermongodbrestores.psmdb.percona.com\nperconaservermongodbs.psmdb.percona.com\nperconapgbackups.pgv2.percona.com\nperconapgclusters.pgv2.percona.com\nperconapgrestores.pgv2.percona.com\nperconapgupgrades.pgv2.percona.com\ncrunchybridgeclusters.postgres-operator.crunchydata.com\npgadmins.postgres-operator.crunchydata.com\npgupgrades.postgres-operator.crunchydata.com\npostgresclusters.postgres-operator.crunchydata.com\nEOF   \n</code></pre> Expected output <pre><code>customresourcedefinition.apiextensions.k8s.io \"catalogsources.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"clusterserviceversions.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"installplans.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"olmconfigs.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"operatorconditions.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"operatorgroups.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"operators.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"subscriptions.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmrules.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmnodescrapes.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmauths.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmprobes.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmpodscrapes.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmsingles.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmstaticscrapes.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmservicescrapes.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmalertmanagerconfigs.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmalertmanagers.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmalerts.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmagents.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmclusters.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmusers.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmscrapeconfigs.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vlogs.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"databaseclusterbackups.everest.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"databaseclusters.everest.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"databaseengines.everest.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"backupstorages.everest.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"databaseclusterrestores.everest.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"monitoringconfigs.everest.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconaxtradbclusterbackups.pxc.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconaxtradbclusterrestores.pxc.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconaxtradbclusters.pxc.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconaservermongodbbackups.psmdb.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconaservermongodbrestores.psmdb.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconaservermongodbs.psmdb.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconapgbackups.pgv2.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconapgclusters.pgv2.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconapgrestores.pgv2.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconapgupgrades.pgv2.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"crunchybridgeclusters.postgres-operator.crunchydata.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"pgadmins.postgres-operator.crunchydata.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"pgupgrades.postgres-operator.crunchydata.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"postgresclusters.postgres-operator.crunchydata.com\" deleted\n</code></pre>"},{"location":"uninstall/uninstallEverest.html#remove-crds-of-perconas-postgresql-operator","title":"Remove CRDs of Percona\u2019s PostgreSQL operator","text":"<p>If you are using the PostgreSQL operator from Crunchy Data, do not remove the <code>postgresclusters.postgres-operator.crunchydata.com</code> CRD. </p> <p>In this case, run the following command:</p> <pre><code>cat &lt;&lt;EOF | xargs kubectl delete crd\nperconapgbackups.pgv2.percona.com\nperconapgrestores.pgv2.percona.com\nperconapgclusters.pgv2.percona.com\nEOF\n</code></pre>"},{"location":"uninstall/uninstall_everest_helm.html","title":"Uninstall Percona Everest using Helm","text":"<p>ACTION REQUIRED: Percona Everest and Bitnami Container Catalog changes</p> <p>Bitnami is restructuring its container catalog on September 29, 2025. To avoid potential failures in Percona Everest operations, follow the steps outlined in this post.</p> <p>important</p> <p>If you installed Percona Everest using <code>helm</code> and need to uninstall it, make sure to uninstall it exclusively through <code>helm</code> for seamless removal.</p>"},{"location":"uninstall/uninstall_everest_helm.html#uninstall-the-database-namespaces","title":"Uninstall the database namespaces","text":"<p>If you have created any database namespaces other than the default namespace, ensure to delete them first.</p> <pre><code>helm uninstall everest -n &lt;DBNamespace&gt;\nkubectl delete ns &lt;DBNamespace&gt;\n</code></pre> <p>Note</p> <p>This runs a chart hook that cleans up your database resources. Although it is not recommended, you can skip this step by specifying <code>cleanupOnUninstall=false</code>.</p>"},{"location":"uninstall/uninstall_everest_helm.html#uninstall-percona-everest","title":"Uninstall Percona Everest","text":"<p>To uninstall Percona Everest, follow these steps:</p> <ol> <li> <p>Run the following command:</p> <pre><code>helm uninstall everest-core -n everest-system\nkubectl delete ns everest-system\n</code></pre> </li> <li> <p>Remove the unused Custom Resource Definitions (CRDs).</p> <p>warning</p> <p>Deleting CRDs can potentially cause issues with any custom resources that depend on those definitions within the kubernetes cluster. Ensure that you do not remove any CRDs that are being used by operator deployments outside of Everest.</p> </li> </ol>"},{"location":"uninstall/uninstall_everest_helm.html#remove-crds","title":"Remove CRDs","text":"<p>During the installation of Everest, the following operators are installed:</p> <ul> <li>Everest</li> <li>VictoriaMetrics</li> <li>OLM</li> </ul> <p>Besides the operators mentioned above, you must have installed at least one of the following operators.</p> <ul> <li>Percona Operator for MySQL(PXC)</li> <li>Percona Operator for MongoDB(PSMDB)</li> <li>Percona Operator for PostgreSQL</li> </ul>"},{"location":"uninstall/uninstall_everest_helm.html#list-of-crds-for-the-operators","title":"List of CRDs for the operators","text":"<p>Below is a list of CRDs for different operators.</p> CRDs of operators installed with Percona EverestCRDs of optional operators that you selected (at least one) OLM operator <pre><code>catalogsources.operators.coreos.com\nclusterserviceversions.operators.coreos.com\ninstallplans.operators.coreos.com\nolmconfigs.operators.coreos.com\noperatorconditions.operators.coreos.com\noperatorgroups.operators.coreos.com\noperators.operators.coreos.com\nsubscriptions.operators.coreos.co\n</code></pre> VictoriaMetrics operator <pre><code>vmrules.operator.victoriametrics.com\nvmnodescrapes.operator.victoriametrics.com\nvmauths.operator.victoriametrics.com\nvmprobes.operator.victoriametrics.com\nvmpodscrapes.operator.victoriametrics.com\nvmsingles.operator.victoriametrics.com\nvmstaticscrapes.operator.victoriametrics.com\nvmservicescrapes.operator.victoriametrics.com\nvmalertmanagerconfigs.operator.victoriametrics.com\nvmalertmanagers.operator.victoriametrics.com\nvmalerts.operator.victoriametrics.com\nvmagents.operator.victoriametrics.com\nvmclusters.operator.victoriametrics.com\nvmusers.operator.victoriametrics.com\nvmscrapeconfigs.operator.victoriametrics.com\nvlogs.operator.victoriametrics.com\n</code></pre> Everest operator <pre><code>databaseclusterbackups.everest.percona.com\ndatabaseclusters.everest.percona.com\ndatabaseengines.everest.percona.com\nbackupstorages.everest.percona.com\ndatabaseclusterrestores.everest.percona.com\nmonitoringconfigs.everest.percona.com\n</code></pre> PXC operator <pre><code>perconaxtradbclusterbackups.pxc.percona.com\nperconaxtradbclusterrestores.pxc.percona.com\nperconaxtradbclusters.pxc.percona.com\n</code></pre> PSMDB operator <pre><code>perconaservermongodbbackups.psmdb.percona.com\nperconaservermongodbrestores.psmdb.percona.com\nperconaservermongodbs.psmdb.percona.com\n</code></pre> PostgreSQL operator (Percona and CrunchyData) <pre><code>perconapgbackups.pgv2.percona.com\nperconapgclusters.pgv2.percona.com\nperconapgrestores.pgv2.percona.com\nperconapgupgrades.pgv2.percona.com\ncrunchybridgeclusters.postgres-operator.crunchydata.com\npgadmins.postgres-operator.crunchydata.com\npgupgrades.postgres-operator.crunchydata.com\npostgresclusters.postgres-operator.crunchydata.com\n</code></pre> <p>warning</p> <p>The Percona Operator for PostgreSQL is a fork of the Crunchy Data\u2019s Postgres operator. Thus, if you are using the Crunchy Data\u2019s Postgres operator, do not remove the CRD <code>postgresclusters.postgres-operator.crunchydata.com.</code></p>"},{"location":"uninstall/uninstall_everest_helm.html#examples-for-removing-crds","title":"Examples for removing CRDs","text":"<p>Here are some examples of how to remove the CRDs.</p>"},{"location":"uninstall/uninstall_everest_helm.html#remove-all-the-crds","title":"Remove all the CRDs","text":"<p>To remove all the CRDS, you can use the following command:</p> <pre><code>cat &lt;&lt;EOF | xargs kubectl delete crd\ncatalogsources.operators.coreos.com\nclusterserviceversions.operators.coreos.com\ninstallplans.operators.coreos.com\nolmconfigs.operators.coreos.com\noperatorconditions.operators.coreos.com\noperatorgroups.operators.coreos.com\noperators.operators.coreos.com\nsubscriptions.operators.coreos.com\nvmrules.operator.victoriametrics.com\nvmnodescrapes.operator.victoriametrics.com\nvmauths.operator.victoriametrics.com\nvmprobes.operator.victoriametrics.com\nvmpodscrapes.operator.victoriametrics.com\nvmsingles.operator.victoriametrics.com\nvmstaticscrapes.operator.victoriametrics.com\nvmservicescrapes.operator.victoriametrics.com\nvmalertmanagerconfigs.operator.victoriametrics.com\nvmalertmanagers.operator.victoriametrics.com\nvmalerts.operator.victoriametrics.com\nvmagents.operator.victoriametrics.com\nvmclusters.operator.victoriametrics.com\nvmusers.operator.victoriametrics.com\nvmscrapeconfigs.operator.victoriametrics.com\nvlogs.operator.victoriametrics.com\ndatabaseclusterbackups.everest.percona.com\ndatabaseclusters.everest.percona.com\ndatabaseengines.everest.percona.com\nbackupstorages.everest.percona.com\ndatabaseclusterrestores.everest.percona.com\nmonitoringconfigs.everest.percona.com\nperconaxtradbclusterbackups.pxc.percona.com\nperconaxtradbclusterrestores.pxc.percona.com\nperconaxtradbclusters.pxc.percona.com\nperconaservermongodbbackups.psmdb.percona.com\nperconaservermongodbrestores.psmdb.percona.com\nperconaservermongodbs.psmdb.percona.com\nperconapgbackups.pgv2.percona.com\nperconapgclusters.pgv2.percona.com\nperconapgrestores.pgv2.percona.com\nperconapgupgrades.pgv2.percona.com\ncrunchybridgeclusters.postgres-operator.crunchydata.com\npgadmins.postgres-operator.crunchydata.com\npgupgrades.postgres-operator.crunchydata.com\npostgresclusters.postgres-operator.crunchydata.com\nEOF   \n</code></pre> Expected output <pre><code>customresourcedefinition.apiextensions.k8s.io \"catalogsources.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"clusterserviceversions.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"installplans.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"olmconfigs.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"operatorconditions.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"operatorgroups.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"operators.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"subscriptions.operators.coreos.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmrules.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmnodescrapes.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmauths.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmprobes.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmpodscrapes.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmsingles.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmstaticscrapes.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmservicescrapes.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmalertmanagerconfigs.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmalertmanagers.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmalerts.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmagents.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmclusters.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmusers.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vmscrapeconfigs.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"vlogs.operator.victoriametrics.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"databaseclusterbackups.everest.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"databaseclusters.everest.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"databaseengines.everest.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"backupstorages.everest.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"databaseclusterrestores.everest.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"monitoringconfigs.everest.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconaxtradbclusterbackups.pxc.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconaxtradbclusterrestores.pxc.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconaxtradbclusters.pxc.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconaservermongodbbackups.psmdb.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconaservermongodbrestores.psmdb.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconaservermongodbs.psmdb.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconapgbackups.pgv2.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconapgclusters.pgv2.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconapgrestores.pgv2.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"perconapgupgrades.pgv2.percona.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"crunchybridgeclusters.postgres-operator.crunchydata.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"pgadmins.postgres-operator.crunchydata.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"pgupgrades.postgres-operator.crunchydata.com\" deleted\ncustomresourcedefinition.apiextensions.k8s.io \"postgresclusters.postgres-operator.crunchydata.com\" deleted\n</code></pre>"},{"location":"uninstall/uninstall_everest_helm.html#remove-crds-of-perconas-postgresql-operator","title":"Remove CRDs of Percona\u2019s PostgreSQL operator","text":"<p>If you are using the PostgreSQL operator from Crunchy Data, do not remove the <code>postgresclusters.postgres-operator.crunchydata.com</code> CRD. </p> <p>In this case, run the following command:</p> <pre><code>cat &lt;&lt;EOF | xargs kubectl delete crd\nperconapgbackups.pgv2.percona.com\nperconapgrestores.pgv2.percona.com\nperconapgclusters.pgv2.percona.com\nEOF\n</code></pre>"},{"location":"upgrade/mongodb_major_upgrades.html","title":"Database engine upgrades","text":"<p>Warning</p> <p>If you encounter an issue while upgrading your database version, there is no option to roll back. In this case, you must manually diagnose and resolve the problem.</p>"},{"location":"upgrade/mongodb_major_upgrades.html#mongodb-major-version-upgrades","title":"MongoDB: Major version upgrades","text":"<p>Starting with Percona Everest 1.6.0, you can upgrade your MongoDB database major versions, allowing upgrades with minimal downtime and disruption.</p> <p>Important</p> <p>PostgreSQL and MySQL support only minor engine upgrades.</p>"},{"location":"upgrade/mongodb_major_upgrades.html#before-you-upgrade","title":"Before you upgrade","text":"<p>The prerequisites for performing a major version upgrade of MongoDB in Percona Everest are:</p> <ul> <li>Version compatibility: Verify that your current MongoDB version is eligible for an upgrade.</li> </ul>"},{"location":"upgrade/mongodb_major_upgrades.html#upgrade","title":"Upgrade","text":"<p>To upgrade database versions via the Percona Everest UI:</p> <ol> <li> <p>Log in to the Percona Everest UI. Navigate to the home page, and select the database that you wish to upgrade. </p> </li> <li> <p>On the Overview page, access the DB Details panel and select Edit next to the Basic Information field.</p> <p></p> </li> <li> <p>Select the desired database version, and then click Upgrade.</p> <p></p> </li> </ol>"},{"location":"upgrade/upgrade_operators.html","title":"Upgrade database operators","text":"<p>Starting with Percona Everest 1.2.0, the intuitive UI allows you to upgrade all the database operators and their components in any namespace with a single click.</p>"},{"location":"upgrade/upgrade_operators.html#before-you-upgrade","title":"Before you upgrade","text":"<p> Note</p> <p>We recommend that you take a database backup before starting the upgrade process.</p> <p>Before upgrading a database operator, Everest presents a list of tasks that need to be completed to smoothly transition your clusters to the next version of the database operators. These tasks may include:</p> <ul> <li> <p>Upgrading your database engine version from an unsupported or end-of-life (EOL) version.</p> </li> <li> <p>Ensuring your clusters are using a supported Custom Resource (CR) version.</p> </li> </ul>"},{"location":"upgrade/upgrade_operators.html#upgrade","title":"Upgrade","text":"<p>To upgrade database operators via the Percona Everest UI:</p> <ol> <li> <p>Log in to the Percona Everest UI and navigate to  Settings &gt; Namespaces. You will see all the database operators installed in that namespace.</p> </li> <li> <p>Once the upgrade for the database operators becomes available, you can initiate the upgrade process by clicking on Upgrade.</p> <p></p> </li> <li> <p>A page is displayed showcasing the upgrades available for the various operators.</p> <p></p> </li> <li> <p>Click Upgrade Operators. A confirmation pop-up will appear, asking if you want to proceed with the upgrade.</p> <p></p> </li> <li> <p>After clicking on Upgrade, you will see a page displaying pending actions. The pending actions indicate that you need to restart the database to utilize the updated CR version.</p> <p></p> </li> <li> <p>Click on the pending Actions. A confirmation pop-up will appear, asking if you want to Upgrade CRD version:</p> <p></p> </li> <li> <p>Click on Upgrade to upgrade the operators.</p> </li> </ol>"},{"location":"upgrade/upgrade_with_cli.html","title":"Upgrade Percona Everest using everestctl","text":"<p>ACTION REQUIRED: Percona Everest and Bitnami Container Catalog changes</p> <p>Bitnami is restructuring its container catalog on September 29, 2025. To avoid potential failures in Percona Everest operations, follow the steps outlined in this post.</p> <p>Percona Everest regularly releases updates that contain bug fixes, security improvements, and other enhancements to improve the overall performance of your database.</p>"},{"location":"upgrade/upgrade_with_cli.html#before-you-upgrade","title":"Before you upgrade","text":""},{"location":"upgrade/upgrade_with_cli.html#percona-everest-and-everestctl-version-compatibility","title":"Percona Everest and everestctl version compatibility","text":"<ul> <li>For most cases, we recommend installing the latest version of <code>everestctl</code> before attempting an upgrade.</li> <li>If you\u2019re working with older versions, you must use <code>everestctl</code> versions 1.2 and 1.3 for Percona Everest 1.2 and 1.3, respectively. However, starting with Percona Everest 1.4, use <code>everestctl</code> version 1.4 or higher.</li> </ul>"},{"location":"upgrade/upgrade_with_cli.html#upgrade-constraints","title":"Upgrade constraints","text":"<p>You can only upgrade one minor version at a time. For instance, you can upgrade from version 1.4.0 to version 1.5.0 but you cannot directly upgrade from version 1.4.0 to version 1.6.0.  </p>"},{"location":"upgrade/upgrade_with_cli.html#upgrade-instructions","title":"Upgrade instructions","text":"Version 1.7.0Version 1.3.0 and onwardsVersion 1.2.0Versions prior to 1.2.0"},{"location":"upgrade/upgrade_with_cli.html#upgrade-to-percona-everest-170","title":"Upgrade to Percona Everest 1.7.0","text":"<p>Before you upgrade to Percona Everest 1.7.0, run the following command:</p> <pre><code>kubectl label namespaces everest-system app.kubernetes.io/managed-by-\n</code></pre> <p>Note</p> <p>This command removes the label <code>app.kubernetes.io/managed-by</code> from the <code>everest-system</code> namespace. This label was used in earlier versions of Percona Everest and may interfere with the working of <code>everestctl</code> during an upgrade.</p> <p>Depending on the version of Percona Everest originally installed, you may see different outputs:</p> Percona Everest initially installed versions 1.4.0 and onwards <p>You will get the following output:</p> <pre><code>label \"app.kubernetes.io/managed-by\" not found.\nnamespace/everest-system not labeled\n</code></pre> Percona Everest initially installed versions prior to 1.4.0 <p>You will get the following output:</p> <pre><code>namespace/everest-system unlabeled\n</code></pre> <p>To upgrade Percona Everest, run the following command:</p> <pre><code>everestctl upgrade\n</code></pre> <p>You can always check the available options by running:</p> <pre><code>everestctl upgrade --help\n</code></pre>"},{"location":"upgrade/upgrade_with_cli.html#upgrade-to-percona-everest-130","title":"Upgrade to Percona Everest 1.3.0+","text":"<p>To upgrade Percona Everest, run the following command:</p> <pre><code>everestctl upgrade\n</code></pre> Example: Upgrade from version 1.4.0 to 1.5.0 <p>Install Percona Everest version 1.4.0</p> <pre><code>everestctl install --version 1.4.0 \n\u2753 Provide database namespaces to be managed by Everest: everest \n\u2753 Which operators do you want to install?\n[X] MySQL\n[X] MongoDB\n&gt; [X] PostgreSQL\n\u2139\ufe0f  Installing Everest version 1.4.0\n\n\u2705  Installing Everest Helm chart\n\u2705  Ensuring Everest API deployment is ready\n\u2705  Ensuring Everest operator deployment is ready\n\u2705  Ensuring OLM components are ready\n\u2705  Ensuring Everest CatalogSource is ready\n\u2705  Ensuring monitoring stack is ready\n\u2705  Provisioning database namespace 'everest'\n\n\ud83d\ude80 Thank you for installing Everest (v1.4.0)!\n</code></pre> <p>Now, upgrade to Percona Everest version 1.5.0</p> <pre><code>everestctl upgrade                \n\u2139\ufe0f  Upgrading Everest to version 1.5.0\n\n\u2705  Upgrading Custom Resource Definitions\n\u2705  Upgrading Helm chart\n\u2705  Ensuring Everest API deployment is ready\n\u2705  Ensuring Everest operator deployment is ready\n\u2705  Ensuring Everest CatalogSource is ready\n\n\ud83d\ude80 Everest has been upgraded to version 1.5.0\n</code></pre>"},{"location":"upgrade/upgrade_with_cli.html#upgrade-to-percona-everest-120","title":"Upgrade to Percona Everest 1.2.0","text":"<p>To upgrade Percona Everest, run the following command:</p> <pre><code>everestctl upgrade\n</code></pre> <p>When upgrading to 1.2.0 using the CLI command <code>everestctl upgrade</code>, all your existing backup storages and monitoring instances will be automatically migrated to the namespaces specified in their <code>.spec.allowedNamespaces</code> fields.</p> <p>Following the upgrade, your databases should not experience any downtime. Your backup, restore, and monitoring functionalities should continue to operate normally. </p> <p>In the unlikely event that your upgrade fails, and you need to manually migrate these resources, follow the steps in how to resolve upgrade failures in Percona Everest 1.2.0 section.</p> Resolving upgrade failures due to the breaking API changes <p>Percona Everest 1.2.0 includes some breaking API changes. While all your resources will be migrated automatically, in the unlikely event that your upgrade fails and you need to manually migrate these resources, follow the steps below:</p> <ol> <li> <p>List the existing backup-storages:</p> <pre><code>kubectl get backupstorages -n everest-system -oyaml &gt; new-backupstorages.yaml\n</code></pre> </li> <li> <p>Check whether the backup storage has been retrieved.</p> <pre><code>cat new-backupstorages.yaml\n\napiVersion: everest.percona.com/v1alpha1\nkind: BackupStorage\nmetadata:\nname: s3\nnamespace: everest-system\nspec:\nallowedNamespaces:\n- my-cool-namespace\n- another-cool-namespace\nbucket: my-cool-bucket\ncredentialsSecretName: s3\ndescription: s3\nendpointURL: https://s3.us-west-2.amazonaws.com\nforcePathStyle: false\nregion: us-west-2\ntype: s3\nverifyTLS: true\n</code></pre> <p>Note</p> <p>You may see more than one object, depending on the number of objects created.</p> </li> <li> <p>Edit <code>new-backupstorages.yaml</code> as follows:</p> <ol> <li> <p>For each <code>BackupStorage</code> retrieved, create a copy in each namespace specified under <code>.spec.allowedNamespaces</code>.</p> </li> <li> <p>Remove (or unset) <code>.spec.allowedNamespaces</code> in each copy of the <code>BackupStorages</code> object.</p> </li> <li> <p>Ensure that <code>.metadata</code> contains only <code>name</code> and <code>namespace</code>.</p> </li> </ol> Example <pre><code>apiVersion: everest.percona.com/v1alpha1\nkind: BackupStorage\nmetadata:\nname: s3\nnamespace: my-cool-namespace\nspec:\nallowedNamespaces: []\nbucket: my-cool-bucket\ncredentialsSecretName: s3\ndescription: s3\nendpointURL: https://s3.us-west-2.amazonaws.com\nforcePathStyle: false\nregion: us-west-2\ntype: s3\nverifyTLS: true\n---\napiVersion: everest.percona.com/v1alpha1\nkind: BackupStorage\nmetadata:\nname: s3\nnamespace: another-cool-namespace\nspec:\nallowedNamespaces: []\nbucket: my-cool-bucket\ncredentialsSecretName: s3\ndescription: s3\nendpointURL: https://s3.us-west-2.amazonaws.com\nforcePathStyle: false\nregion: us-west-2\ntype: s3\nverifyTLS: true\n</code></pre> </li> <li> <p>Create your new backup storages:</p> <pre><code>kubectl apply -f new-backupstorages.yaml\n</code></pre> <p>A similar set of steps can also be followed for monitoring configs as well:</p> <pre><code>kubectl get monitoringconfigs -n everest-monitoring &gt; new-monitoringconfigs.yaml\n</code></pre> </li> </ol>"},{"location":"upgrade/upgrade_with_cli.html#upgrade-to-versions-older-than-120","title":"Upgrade to versions older than 1.2.0","text":"<p>Note</p> <p>It is recommended that you create backups of your databases prior to upgrading Percona Everest.</p> <p>During the upgrade of Percona Everest, only Percona Everest and Everest operator are upgraded, whereas the database operators, database clusters and backups remain unchanged.</p> <ol> <li> <p>If you are using <code>everestctl</code> v1.1.0 or newer to upgrade from a version prior to v1.0.0, you need to execute the following command:</p> <pre><code>kubectl get deployments everest-operator-controller-manager -n everest-system -o jsonpath='{.spec.template.spec.containers[?(@.name==\"manager\")].env[?(@.name==\"DB_NAMESPACES\")].value}' | tr ',' '\\n' | xargs -I {} kubectl label namespaces {} app.kubernetes.io/managed-by=everest\n</code></pre> </li> <li> <p>To upgrade Percona Everest, use the following command:</p> <pre><code>everestctl upgrade\n</code></pre> Expected output <pre><code>everestctl upgrade\n2024-05-03T12:06:47Z    info    upgrade/upgrade.go:156  Current Everest version is 0.9.1        {\"component\": \"upgrade\"}\n2024-05-03T12:06:47Z    info    upgrade/upgrade.go:164  Found available upgrade to Everest version 0.10.0   {\"component\": \"upgrade\"}\n2024-05-03T12:06:47Z    info    upgrade/upgrade.go:167  Checking requirements for upgrade to Everest 0.10.0 {\"component\": \"upgrade\"}\n2024-05-03T12:06:47Z    info    upgrade/upgrade.go:310  Checking cli version requirements       {\"component\": \"upgrade\"}\n2024-05-03T12:06:47Z    info    upgrade/upgrade.go:339  Checking operator requirements in namespace n1  {\"component\": \"upgrade\"}\n2024-05-03T12:06:47Z    info    upgrade/upgrade.go:121  Upgrading Percona Catalog to 0.10.0 {\"component\": \"upgrade\"}\n2024-05-03T12:06:47Z    info    upgrade/upgrade.go:130  Waiting for install plan for Everest operator   {\"component\": \"upgrade\"}\n2024-05-03T12:07:14Z    info    upgrade/upgrade.go:139  Upgrading Everest to 0.10.0 in namespace everest-system     {\"component\": \"upgrade\"}\n2024-05-03T12:07:26Z    info    upgrade/upgrade.go:400  Approving install plan install-nv76r for Everest operator       {\"component\": \"upgrade\"}\n2024-05-03T12:07:26Z    info    upgrade/upgrade.go:406  Waiting for install plan installation of Everest operator to finish     {\"component\": \"upgrade\"}\n2024-05-03T12:07:28Z    info    upgrade/upgrade.go:148  Everest has been upgraded to version 0.10.0 {\"component\": \"upgrade\"}\n</code></pre> </li> </ol>"},{"location":"upgrade/upgrade_with_cli.html#how-to-address-a-failed-upgrade","title":"How to address a failed upgrade","text":"<p>If the upgrade fails, you can attempt it again. If the issue persists, create a GitHub issue.</p>"},{"location":"upgrade/upgrade_with_cli.html#after-your-upgrade-is-complete","title":"After your upgrade is complete","text":"<p>After upgrading your Percona Everest version, follow the instructions in step 3 and step 4 of the installation section to reset the admin password and expose the Percona Everest service.</p>"},{"location":"upgrade/upgrade_with_helm.html","title":"Upgrade Percona Everest using Helm","text":"<p>ACTION REQUIRED: Percona Everest and Bitnami Container Catalog changes</p> <p>Bitnami is restructuring its container catalog on September 29, 2025. To avoid potential failures in Percona Everest operations, follow the steps outlined in this post.</p> <p>Percona Everest consistently delivers updates that includes bug fixes, security enhancements, and various improvements designed to optimize the overall performance of your database.</p>"},{"location":"upgrade/upgrade_with_helm.html#before-you-upgrade","title":"Before you upgrade","text":"<p>Important</p> <ul> <li>Upgrade one minor release at a time to avoid unexpected issues. Start by updating to the latest patch release before moving on to the next minor release.</li> <li>For a safe upgrade, we perform a pre-upgrade hook that runs a series of checks. You can disable this by setting <code>upgrade.preflightChecks=false</code>, but doing so means a safe upgrade cannot be assured.</li> </ul>"},{"location":"upgrade/upgrade_with_helm.html#prepare-for-upgrading-to-version-170","title":"Prepare for upgrading to version 1.7.0","text":"<p>Before you upgrade to Percona Everest version 1.7.0, run the following command:</p> <pre><code>kubectl label namespaces everest-system app.kubernetes.io/managed-by-\n</code></pre>"},{"location":"upgrade/upgrade_with_helm.html#upgrade-crds","title":"Upgrade CRDs","text":"<p>In Helm v3, CRDs are not updated automatically during a Helm upgrade. You need to upgrade the CRDs manually.</p> <p>To update the CRDs, run the following command:</p> <pre><code>helm repo update\nhelm upgrade --install everest-crds \\\n    percona/everest-crds \\\n    --namespace everest-system\n    --take-ownership\n</code></pre>"},{"location":"upgrade/upgrade_with_helm.html#upgrading-with-helm-versions-prior-to-3170","title":"Upgrading with Helm versions prior to 3.17.0","text":"<p>If you upgrade from Percona Everest 1.8.0 and use a Helm version older than 3.17.0, the <code>--take-ownership</code> flag will not be available. Without this flag, you may encounter the following validation errors related to missing ownership metadata:</p> <pre><code>invalid ownership metadata; label validation error: missing key \"app.kubernetes.io/managed-by\": must be set to \"Helm\";\nannotation validation error: missing key \"meta.helm.sh/release-name\": must be set to \"everest-crds\";\nannotation validation error: missing key \"meta.helm.sh/release-namespace\": must be set to \"everest-system\"\n</code></pre>"},{"location":"upgrade/upgrade_with_helm.html#workaround-for-helm-versions-older-than-3170","title":"Workaround for Helm versions older than 3.17.0","text":"<p>If you must use a Helm version older than\u00a03.17.0, you can manually simulate the behavior of\u00a0<code>--take-ownership</code>\u00a0by adding the required labels and annotations to the Everest CRDs:</p> <pre><code>CRDS=(databaseclusters.everest.percona.com              databaseengines.everest.percona.com databaseclusterbackups.everest.percona.com databaseclusterrestores.everest.percona.com backupstorages.everest.percona.com monitoringconfigs.everest.percona.com)\nkubectl label crds \"${CRDS[@]}\" app.kubernetes.io/managed-by=Helm --overwrite\nkubectl annotate crds \"${CRDS[@]}\" meta.helm.sh/release-name=everest-crds\nkubectl annotate crds \"${CRDS[@]}\" meta.helm.sh/release-namespace=everest-system\n</code></pre> <p>This ensures the CRDs are correctly recognized as managed by Helm, avoiding validation issues during the upgrade.</p>"},{"location":"upgrade/upgrade_with_helm.html#upgrade-helm-releases","title":"Upgrade Helm releases","text":"<p>Warning</p> <p>When using <code>helm upgrade</code>, specifying <code>--set</code> (or other equivalent flags) causes Helm to revert all other values to the defaults defined in the chart. To avoid this issue, either include the <code>--reuse-values</code> flag or provide the complete set of values, including those used during the installation.</p> <p>To upgrade Percona Everest using Helm, run the following commands:</p> <ol> <li> <p>Upgrade the Helm release for Everest (core components).</p> <pre><code>helm upgrade everest-core percona/everest --namespace everest-system --version \"$VERSION\"      \n</code></pre> <p>where,</p> <p>VERSION is the Percona Everest version you wish to upgrade to.</p> </li> <li> <p>Upgrade the Helm release for the database namespace (if applicable):</p> <pre><code>helm upgrade everest percona/everest-db-namespace --namespace &lt;DB namespace&gt; --version \"$VERSION\"\n</code></pre> <p>where,</p> <p>VERSION is the Percona Everest version you wish to upgrade to.</p> <p>DB namespace is the namespace you wish to upgrade.</p> </li> </ol>"},{"location":"use/API_rate_limit.html","title":"API rate limiting","text":"<p>API rate limiting is a crucial aspect of managing APIs effectively. It involves setting a threshold for the number of requests that an API can receive within a specific period. This enables you to regulate the number of incoming requests, mitigating the risk of server overload or abuse. </p>"},{"location":"use/API_rate_limit.html#sessions-rate-limit","title":"Sessions rate limit","text":"<p>The Everest API has a critical endpoint known as the <code>/session</code> endpoint, which is responsible for exchanging the user\u2019s login credentials (username and password) for a JSON web token (JWT). As this endpoint is used to authenticate users, it is important to implement additional security measures.</p> <p>By default, a Percona Everest installation allows three requests per second to this endpoint. It\u2019s configurable via the <code>CREATE_SESSION_RATE_LIMIT</code> environment variable.</p> <p>Everest monitors failed login attempts per IP address and applies progressive timeouts to prevent unlimited login attempts without being throttled. When a rate limit is reached, the Percona Everest API will throw an error.</p>"},{"location":"use/API_rate_limit.html#customize-api-rate-limiting","title":"Customize API rate limiting","text":"<p>The default rate limit for Percona Everest is 100 requests per second. However, you have the option to modify these limits. To customize API rate limiting, you can adjust the rate limits to align them with your usage patterns and requirements.</p> <p>For example, when dealing with large systems that have many database clusters, the default limit of 100 may not be sufficient, and therefore, you might want to increase the limit.</p> <p>Customizing API rate limiting is crucial for the following reasons:</p> <ul> <li> <p>Attackers can launch brute force attacks on Auth Bearer Tokens by submitting a high volume of automated requests if rate limiting is not applied. Successful brute force attacks may compromise user credentials or sensitive information associated with the Auth Bearer Tokens.</p> </li> <li> <p>The influx of excessive requests can overload the application server, using up bandwidth and storage.</p> </li> </ul> <p>To customize the API rate limiting:</p> <ol> <li> <p>Run the following command:</p> <pre><code>kubectl -n everest-system patch deployment percona-everest --type strategic -p 'spec:\n  strategy:\n    rollingUpdate:\n      maxSurge: 0\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    spec:\n      affinity:\n        podAntiAffinity: {}\n      containers:\n        - name: everest\n          env:\n            - name: API_REQUESTS_RATE_LIMIT\n              value: \"200\" \n            - name: CREATE_SESSION_RATE_LIMIT\n              value: \"3\"' \n</code></pre> <p>Replace 200 with the desired value.</p> </li> <li> <p>After executing the previous command, <code>percona-everest</code> pod will restart automatically. If you had port-forwarding running, it would exit, and you\u2019ll need to rerun it.</p> <pre><code>kubectl port-forward svc/everest 8080:8080 -n everest-system\n</code></pre> </li> </ol>"},{"location":"use/cluster-management.html","title":"Manage clusters","text":"<p>Cluster management involves the administration and maintenance of database clusters. Here\u2019s an overview of Percona Everest cluster management.</p> <ol> <li> <p>Database provisioning</p> <p>Provisioning a database instance involves setting up and configuring a database instance on the Percona Everest platform. </p> <p></p> </li> <li> <p>Editing the database clusters</p> <p>Editing a cluster in a Percona Everest typically involves making configuration changes to an existing database cluster to adapt it to your evolving needs.</p> <p>To edit a database cluster, go to the Overview page of the desired cluster and click Edit on the corresponding widget.</p> <p></p> </li> <li> <p>Scaling</p> <p>Scaling in Percona Everest involves adjusting the capacity and performance of your database instances to meet changing application demands. You can scale Percona Everest vertically and horizontally.</p> <p>To scale your database cluster, go to the Overview page of the desired cluster. Click on Edit in the Resources widget. This will open the Edit Topology screen. Make the necessary changes to the settings and then click Save.</p> <p></p> <p></p> <ul> <li> <p>Vertical scaling</p> <p>Vertical scaling is essential for addressing increased workloads or performance demands. You can scale up or scale down as per your requirements. </p> <ul> <li> <p>Scale up</p> <p>You can vertically scale up your Percona Everest instance by modifying its configuration to a higher performance tier. This involves increasing the memory and/or CPU threshold.</p> </li> <li> <p>Scale down               </p> <p>Similarly, you can scale down (downsize) your database instance when the resource requirements decrease, which can help optimize costs.</p> </li> </ul> </li> <li> <p>Horizontal scaling</p> <p>To scale Percona Everest horizontally, add database nodes to the existing cluster. These nodes share the workload, distributing queries and transactions more evenly, which can lead to improved performance.</p> </li> </ul> </li> <li> <p>Manual storage scaling</p> <p>You can increase the storage capacity of your S3-compatible storage through manual storage scaling. This feature enables you to adapt to rising data demands, providing more flexibility in managing growing database workloads while ensuring system stability and data security.</p> <p>To increase the DISK for a database, go to the Percona Everest home page and select your desired database. Then, navigate to Overview &gt; Resources &gt; Edit and enter the new value for DISK (in Gi).</p> <p></p> </li> <li> <p>Back up and restore</p> <p>Back up and restore are critical aspects of managing and maintaining databases in Percona Everest. Implementing robust backup and recovery strategies is crucial for preserving the integrity and availability of data and ensuring seamless business operations.</p> <p>With the Percona Everest platform, you can generate backups on demand, create new databases using pre-existing backups, and restore backups to existing database clusters.</p> <p></p> </li> <li> <p>Monitoring</p> <p>Monitoring ensures consistent performance by continuously observing various metrics and aspects of the database system. It helps identify performance issues or bottlenecks before they escalate, allowing timely interventions, optimizations, and resource allocation adjustments. This helps us maintain a stable and consistent database system performance over time.</p> <p>You can manage your monitoring settings by navigating to the Overview page of the desired cluster and clicking Edit in the Monitoring widget. You can turn monitoring on or off by using the toggle.</p> <p></p> </li> </ol>"},{"location":"use/database_view.html","title":"Database view","text":"<p>The database view in Percona Everest provides an interface to view and provision your databases. With the database view, you can keep a close eye on all your databases and their status and\u00a0perform tasks such as backup and restore.</p> <p></p> <p>Click on the individual database and select the ellipsis menu (\u2026). This will allow you to perform various actions such as:</p> <p></p> <ul> <li> <p>Restart the database - Restarting your database can improve the performance of your database and enable you to apply recent configuration changes. </p> </li> <li> <p>Create database from a backup - With Percona Everest, you have the ability to create a database from a backup. </p> <p>For more in-depth instructions on how to create a database from a backup, refer to the create a database from a backup .</p> </li> <li> <p>Restore database from a backup - With Percona Everest, you have the ability to restore your database from a backup. </p> <p>For more in-depth instructions on how to restore a database, refer to the restore a database from a backup section.</p> </li> <li> <p>Suspend the database - Suspending your database can save resources when it\u2019s not being used. </p> <p>To resume your database click Resume. You database will be immediately resumed.</p> </li> <li> <p>Delete the database - If you have a database that you no longer use, you can delete it to free up space or resources.</p> </li> </ul>"},{"location":"use/database_view.html#detailed-database-view","title":"Detailed database view","text":"<p>You can view a comprehensive overview of any specific database by clicking on the respective database. Once you do that, you will see the Overview, Backups, Components and Restores tabs.</p>"},{"location":"use/database_view.html#overview","title":"Overview","text":"<p>The Overview tab provides a comprehensive view of all the essential database details, such as:</p> <ul> <li>Basic information about the database</li> <li>Backups information</li> <li>Backups schedules information</li> <li>Point-in-time Recovery status</li> <li>Resources used by the database</li> <li>External access and monitoring status</li> <li>Information about host, port, and credentials</li> </ul> <p></p>"},{"location":"use/database_view.html#components","title":"Components","text":"<p>The Components page offers comprehensive information about pods and containers. Here, you can find everything you need to know, including their current status, types, age, and various other attributes, helping you gain a deep understanding of their functions and performance.</p> <p></p> <p>The Components tab also includes an interactive Topology View that improves the visibility and management of DB clusters deployed in Percona Everest. This view visually represents the cluster\u2019s components, such as pods and services, along with their status and relationships.</p> <p>Click the Toggle Table View to switch between the Topology and Table views.</p> <p></p>"},{"location":"use/database_view.html#backups","title":"Backups","text":"<p>The Backups tab lists all the backups created for the database. This includes the exact date and time when each backup was taken, providing you with a clear overview of the backup history for the database.</p> <p>From the ellipsis (\u2026) menu next to the database you can:</p> <ul> <li> <p>Restore the backup to database. </p> </li> <li> <p>Create a new database from backup. </p> <p></p> </li> </ul> <p>The Backups tab also displays all active schedules for the database. You can edit or delete schedules by clicking Edit or Delete respectively.</p>"},{"location":"use/database_view.html#restores","title":"Restores","text":"<p>The Restores tab displays a list of the database restores along with their respective dates and timestamps. This way, you can easily track and manage the history of all the restores that have been performed on the database.</p> <p>To remove the database\u2019s restore entry, click Delete and the restored database will be deleted.</p> <p></p>"},{"location":"use/db_engine_config.html","title":"Configure database engine","text":"<p>Percona Everest provides configuration settings and options, which are essential for tailoring the database behavior and performance to meet the needs of various applications. You can fine-tune your database operations using these settings and options, thus increasing efficiency and productivity.</p>"},{"location":"use/db_engine_config.html#configure-database-engine-for-new-database-cluster","title":"Configure database engine for new database cluster","text":"<p>To configure your database engine in Percona Everest:</p> <ol> <li> <p>From the Percona Everest main page, navigate to Create database &gt; Advanced Configurations page.</p> </li> <li> <p>Select the Exposure Method as either Cluster IP or Load balancer.</p> </li> <li> <p>From the Load balancer configuration drop-down, choose the configuration you want to apply. Click Add new to add the IP addresses in the Source Range field.</p> <p>If you\u2019re looking to dive deeper into setting up your load balancer, check out our comprehensive guide on Load balancer configuration.</p> <p>Note</p> <ul> <li>Enabling remote access to your database can lead to serious security risks such as unauthorized access, data breaches, and compliance violations.</li> <li>The network mask is always required, so if you want to limit access to a single IP, ensure to add the <code>/32</code> network mask.</li> </ul> <p></p> </li> <li> <p>You can optimize your database\u2019s performance using Database Engine Parameters on the Advanced configurations page.</p> </li> <li>Enable Database engine parameters by using the toggle.</li> <li> <p>Configure specific values to optimize performance, security, and functionality according to your requirements by entering the values in the text box.</p> <p></p> <p>Here are some configuration examples for each supported engine type:</p> <p>MySQL <pre><code>[mysqld]\nkey_buffer_size=16M\nmax_allowed_packet=128M\nmax_connections=250</code>\n<p>Mongo\n<pre><code>operationProfiling:\n  mode: slowOp\n  slowOpThresholdMs: 200</code>\n<p>PostgreSQL\n<pre><code>log_connections = yes\nsearch_path = \u2018\u201c$user\u201d, public\u2019\nshared_buffers = 128MB</code>\n<p>For more information on configuring specific database parameters, see the MySQL, MongoDB, and PostgreSQL configuration documentation.</p>\n\n<li>\n<p>Click Continue till you reach the end of the wizard.</p>\n</li>\n<li>\n<p>Click Create database. The database engine parameters will be updated.</p>\n</li>"},{"location":"use/db_engine_config.html#configure-database-engine-for-an-existing-db-cluster","title":"Configure database engine for an existing DB cluster","text":"<p>To update your database engine in Percona Everest for an existing DB cluster:</p>\n<ol>\n<li>\n<p>Go to the Percona Everest home page and click on the database for which you want to update the database engine. The Overview page will be displayed.</p>\n</li>\n<li>\n<p>On the Advanced configuration widget, click Edit. The Edit advanced configuration screen will be displayed.</p>\n<p></p>\n</li>\n<li>\n<p>Make the necessary changes and then click Save. The database engine parameters will be updated.</p>\n</li>\n</ol>"},{"location":"use/db_provision.html","title":"Provision a database","text":"<p>Provisioning a database instance involves setting up and configuring a database instance on the Percona Everest platform.</p> <p>Warning</p> <p>Refrain from changing the password of administrative users (e.g., root, monitor, or operator) manually in the database. This action may cause inconsistencies with the secrets stored in Kubernetes, which are crucial for the proper functioning of the cluster. Such modifications have the potential to disrupt your cluster.</p> <p>We are developing a new feature that will allow you to modify these settings directly from the user interface (UI).</p>"},{"location":"use/db_provision.html#procedure","title":"Procedure","text":"<p>To provision a new database:</p> <ol> <li> <p>Log into the Percona Everest UI.</p> </li> <li> <p>On the Percona Everest homepage, click Create Database. The menu for the different database types will open. Select the database that you wish to provision. The Basic Information page will then be displayed.</p> <p></p> </li> <li> <p>On the Basic information page, provide the following details:</p> <ul> <li> <p>Select the Namespace where you want to create your database.</p> </li> <li> <p>Choose a name for your database. The name is auto-populated, but you can modify it according to your needs.</p> </li> <li> <p>Select the Database version from the dropdown.</p> </li> <li> <p>In the Storage class field, select one of the classes created by your Kubernetes administrator. </p> <p>Storage classes define what storage configuration and features will be used for storing your database data. Different classes map to different quality-of-service levels, backup policies, persistent volumes, or to arbitrary policies determined by your cluster administrator. For more information, see Storage Classes in the Kubernetes documentation. </p> <p></p> </li> </ul> </li> <li> <p>Click Continue. The Resources page will be displayed.</p> </li> <li> <p>On the Resources page, select the Number of nodes. Also, set Resources size per node by selecting one of the predefined presets or by specifying the CPU, Memory, and Disk. For more information on resources, see the Scale database deployment section.</p> <p>Additionally, based on the database technology you\u2019re working with, select the following:</p> <ul> <li> <p>MySQL: On the Proxies panel, select the Number of proxies and Resource size per proxy.</p> <p>Info</p> <p>Proxies are used primarily to ensure high availability, load balancing, and database failover management. They act as intermediaries, ensuring client requests are directed to the appropriate database instances.</p> <p></p> </li> <li> <p>PostgreSQL: On the PG Bouncers panel, select the Number of PG Bouncers and Resource size per PG Bouncer.</p> <p>Info</p> <p>PgBouncer manages PostgreSQL connections, particularly in high traffic environments.</p> <p></p> </li> <li> <p>MongoDB: If you enable sharding, you can see the Routers panel on the Resources page. Select the Number of routers and the Resource size per router.</p> <p></p> </li> </ul> </li> <li> <p>Click Continue. The Scheduled Backups page will be displayed.</p> </li> <li> <p>On the Scheduled Backups page, set up a schedule to run backup jobs for your new database.</p> <p>Click Create backup schedule. The backup schedule pop-up is displayed.</p> <p>Provide the following details on this page:</p> <ul> <li> <p>Choose a name for your backup schedule. The name is auto-populated, but you can modify it according to your needs.</p> </li> <li> <p>Select the Backup storage from the dropdown.</p> </li> <li> <p>Enter the number of Retention copies for the backups.</p> <p>Note</p> <p>Currently, Retention copies are not supported for PostgreSQL databases.      </p> <p>Retention copies refer to the number of backup instances that should be kept.</p> <p>Example: When you set retention copies to 3, it means that you want to keep a maximum of 3 backup copies at any given time. So, if you have 3 backups already and then run a 4<sup>th</sup> backup, the oldest backup will get deleted automatically. </p> <p> </p> </li> </ul> </li> <li> <p>On the Scheduled Backups page, you can also enable Point-in-time Recovery (PITR) by turning the toggle on.</p> </li> <li> <p>Click Continue. The Advanced Configurations page will be displayed.</p> </li> <li> <p>On the Advanced Configurations page, you can fine-tune the following settings:</p> <ul> <li> <p>Storage: Select the storage class for your database.</p> </li> <li> <p>Pod scheduling policy: Enable and configure rules that define how pods are distributed across nodes.</p> </li> <li> <p>Exposure method: Choose how the database is exposed:</p> <ul> <li> <p>Cluster IP for internal access within the Kubernetes cluster</p> </li> <li> <p>Load Balancer for external access outside the Kubernetes cluster</p> </li> </ul> </li> <li> <p>Database engine parameters: Enable and customize advanced engine parameters for fine-tuned control.</p> </li> </ul> <p>For in-depth information, see the configure database engine section.</p> </li> <li> <p>Click Continue. The Monitoring page will be displayed.</p> </li> <li> <p>On the Monitoring page, you can enable monitoring by turning the toggle on and selecting the Monitoring endpoint from the drop down.</p> <p>If you have not added any monitoring endpoint, click Add monitoring endpoint. For information on adding monitoring endpoints, see the monitoring endpoints section.</p> </li> <li> <p>Click Create Database.</p> </li> <li> <p>Click Go to list of my databases to see the database that you provisioned.</p> </li> </ol>"},{"location":"use/db_provision.html#video-tutorial","title":"Video tutorial","text":"<p>You can also learn about creating databases by checking the video tutorial below:</p>"},{"location":"use/manual_storage_scaling.html","title":"Manual storage scaling","text":"<p>You can increase the capacity of your storage through manual storage scaling. This feature enables you to adapt to rising data demands, providing more flexibility in managing growing database workloads while ensuring system stability and data security.</p>"},{"location":"use/manual_storage_scaling.html#storage-management-in-percona-everest","title":"Storage management in Percona Everest","text":"<p>In Kubernetes environments running Percona Everest, storage is managed using Persistent Volumes (PVs) and Persistent Volume Claims (PVCs). Everest automates storage provisioning through <code>StorageClasses</code>.</p> <p>For storage scaling, Everest supports volume expansion, enabling users to increase storage size provided the associated <code>StorageClass</code> allows it.</p> <p>For detailed information on PVs and PVCs, refer to the official Kubernetes documentation.</p>"},{"location":"use/manual_storage_scaling.html#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>When scaling storage manually for a database managed by Percona Everest, ensure that the <code>StorageClass</code> used by the database\u2019s PersistentVolumeClaim (PVC) supports volume expansion. This setting allows the size of the underlying Persistent Volume to be increased after it has been created.</p> <p>Note</p> <p>In Kubernetes, manual disk scaling only works if the associated <code>StorageClass</code> has the following setting:</p> <pre><code>allowVolumeExpansion: true\n</code></pre> <p>To verify if your storage class allows for volume expansion, execute the following command:</p> <pre><code>kubectl get storageclass\n</code></pre> Expected output <pre><code>NAME                   PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\nexpandable-storage     kubernetes.io/aws-ebs   Delete          WaitForFirstConsumer   true                   42m\n</code></pre> </li> <li> <p>When scaling storage in Percona Everest, always verify that resource quotas allow the requested storage capacity. For more information, see the known limitations section.</p> </li> </ul>"},{"location":"use/manual_storage_scaling.html#editing-storage-capacity","title":"Editing storage capacity","text":"<p>Important</p> <ul> <li>Cluster resizing is permanent and cannot be reversed.</li> <li>Disk size can only be increased. Decreasing the disk is not supported to protect data integrity.</li> </ul> <p>To modify storage capacity, follow these steps:</p> <ol> <li> <p>Navigate to the Overview page for your database from the Percona Everest home page.</p> </li> <li> <p>Click Edit in the Resources panel.  The Edit Topology pop-up will be displayed.</p> </li> <li> <p>Locate the DISK field and enter the disk value (in Gi) to the new desired capacity.</p> <p></p> </li> <li> <p>Click Save.</p> </li> <li> <p>After clicking Save, go back to the Overview page and check that the DISK field reflects the new capacity.</p> </li> </ol> <p>For information about the limitations of manual storage scaling, refer to the known limitations section.</p>"},{"location":"use/mongo_sharding.html","title":"MongoDB sharding","text":"<p>Warning</p> <p>Sharding is currently in Technical Preview. Early adopters are advised to use this feature only for testing purposes and not in production environments.</p> <p>Sharding   is used for horizontal database scaling. It distributes a database horizontally across multiple nodes or servers, known as shards. Each shard manages a portion of the data, forming a sharded cluster, which enables MongoDB to handle large datasets and high user concurrency effectively.</p>"},{"location":"use/mongo_sharding.html#key-components-of-mongodb-sharding","title":"Key components of MongoDB sharding","text":"<ul> <li>Shard: Each shard has a subset of the data.</li> <li> <p>Routers: The query router directs the client queries to the proper shard(s).</p> </li> <li> <p>Config servers: The configuration servers store the cluster\u2019s metadata and configuration settings.</p> </li> </ul>"},{"location":"use/mongo_sharding.html#why-sharding","title":"Why sharding?","text":"<p>Here are the key reasons for implementing sharding:</p>"},{"location":"use/mongo_sharding.html#scalability","title":"Scalability","text":"<p>By increasing the number of shards in the cluster, you can scale your system horizontally. This enables you to manage larger datasets and handle higher traffic volumes, ensuring your system remains responsive and efficient despite growing demands.</p>"},{"location":"use/mongo_sharding.html#improved-performance","title":"Improved performance","text":"<p>By splitting data across multiple servers, sharding reduces the load on any one server, which leads to faster query response times. Since each shard contains only a fraction of the total data, queries targeting a specific shard can be processed faster.</p>"},{"location":"use/mongo_sharding.html#availability","title":"Availability","text":"<p>If one shard (or server) fails, the remaining shards can continue to operate, enhancing the system\u2019s availability and fault tolerance. Data replication across replica sets ensures that no information is lost in the event of a failure.</p>"},{"location":"use/mongo_sharding.html#create-mongodb-sharded-cluster","title":"Create MongoDB sharded cluster","text":"<p>Warning</p> <ul> <li> <p>Once you have a sharded collection, ensure you take a new backup to avoid data inconsistency and potential restoration failures.</p> </li> <li> <p>There are a few more limitations related to MongoDB sharding. See the limitations section for details about these limitations.</p> </li> </ul> <p>To create a sharded cluster:</p> <ol> <li> <p>From the Percona Everest homepage, click Create Database and select the MongoDB database. The Basic information page will be displayed.</p> </li> <li> <p>On the Basic Information page, turn the Sharded Cluster toggle to on.</p> <p></p> </li> <li> <p>Click Continue. The Resources page will be displayed.</p> </li> <li> <p>On the Resources page, choose or enter the following details:</p> <ul> <li> <p>Number of Shards</p> </li> <li> <p>On the Nodes panel, select the Number of nodes per shard and the corresponding Resource size per node.</p> </li> <li> <p>On the Routers panel, select the Number of routers and the corresponding Resource size per router.</p> </li> <li> <p>Number of configuration servers</p> </li> </ul> <p></p> </li> <li> <p>To check if sharding is enabled, go to the database view page and click on the specific database. Then, check the Resources panel to see if sharding is enabled.</p> <p></p> </li> </ol>"},{"location":"use/mongo_sharding.html#obtain-credentials-for-sharding-collections","title":"Obtain credentials for sharding collections","text":"<p>You need to obtain the credentials for a user with permissions to shard collections.</p> <p>Here are instructions on obtaining permissions to shard a collection:</p> <pre><code>MONGODB_CLUSTER_ADMIN_USER=$(kubectl get secrets --namespace &lt;NAMESPACE&gt; everest-secrets-&lt;CLUSTER_NAME&gt; -o template='{{ \"{{\"}}.data.MONGODB_CLUSTER_ADMIN_USER | base64decode {{\"}}\"}}{{\"{{\"}}\"\\n\"{{\"}}\"}}')\n</code></pre> <pre><code>MONGODB_CLUSTER_ADMIN_PASSWORD=$(kubectl get secrets --namespace &lt;NAMESPACE&gt; everest-secrets-&lt;CLUSTER_NAME&gt; -o template='{{ \"{{\"}}.data.MONGODB_CLUSTER_ADMIN_PASSWORD | base64decode {{\"}}\"}}{{\"{{\"}}\"\\n\"{{\"}}\"}}')\n</code></pre> <p>Once you establish a connection with this user, you will have the ability to execute the commands <code>sh.enableSharding()</code> and <code>sh.shardCollection()</code>. </p> <ul> <li> <p>The <code>sh.enableSharding()</code> command allows you to enable sharding for a specific database. </p> <ul> <li>The <code>sh.shardCollection()</code> command is used to partition a collection across multiple shards, optimizing data distribution and query performance.</li> </ul> </li> </ul>"},{"location":"use/mongo_sharding.html#fine-tuning-your-sharding-setup","title":"Fine-tuning your sharding setup","text":"<p>Here are few recommendations to fine-tune your setup for MongoDB sharding.</p> <ul> <li> <p>Scalability: To enhance your cluster\u2019s scalability, consider increasing the number of shards, based on your anticipated load.</p> </li> <li> <p>Fault tolerance: To ensure fault tolerance, MongoDB uses replica sets. This ensures that if one server fails, another replica can take over without impacting the cluster\u2019s availability.</p> </li> <li> <p>Redundancy: It is recommended that the nodes be deployed in a MongoDB sharded cluster as replica sets of 3 or 5 members. This is important for maintaining high availability and ensuring the sharded cluster continues functioning even if some servers fail.</p> </li> </ul>"},{"location":"use/monitor_endpoints.html","title":"Monitoring","text":"<p>Percona Everest provides monitoring capabilities with PMM to maintain a reliable and secure database infrastructure.</p> <p>Important</p> <p>Currently only PMM v2.x is supported. Support for PMM v3.x is planned for future releases.</p> <p>Here are some key benefits you\u2019ll get with monitoring of Percona Everest:</p> <ul> <li>Database availability and uptime tracking</li> <li>Insights into your database performance</li> <li>Proactive issue detection and addressing opportunities</li> <li>Continuous monitoring</li> </ul>"},{"location":"use/monitor_endpoints.html#the-concept-of-namespaces-in-monitoring","title":"The concept of namespaces in monitoring","text":"<p>When you assign namespaces to a monitoring instance, it only determines which databases are authorized to utilize it; you cannot monitor specific namespaces. </p> <p>Each database can only be monitored by one instance, which means that the metrics for the database are only available to that instance.</p> <p>When adding a new monitoring instance, the monitoring stack (kube-state-metrics and victoria-metrics) will automatically start pushing Kubernetes metrics to that instance.</p>"},{"location":"use/monitor_endpoints.html#prerequisites","title":"Prerequisites","text":"<p>To use monitoring in Percona Everest, you should have a PMM instance up and running.</p> <p>For information on installing PMM, see the documentation.</p>"},{"location":"use/monitor_endpoints.html#add-monitoring-endpoint","title":"Add monitoring endpoint","text":"<p>To add monitoring in Percona Everest from the UI:</p> <ol> <li> <p>From the Percona Everest Homepage, navigate to  Settings &gt; Monitoring endpoints. The Add monitoring endpoint dialogue box opens.</p> </li> <li> <p>On the Add monitoring endpoint screen, enter a name for the monitoring instance.</p> <p></p> </li> <li> <p>Select the namespaces where the monitoring endpoint should be available.</p> </li> <li> <p>In the Endpoint field, enter the PMM URL. Enter the credentials received upon installing PMM in the User and Password field.</p> <p>Warning</p> <p>When setting up a new monitoring instance, if your PMM instance uses a self-signed certificate, skip the Verify TLS verification checkbox.        </p> </li> <li> <p>Click Add.</p> </li> </ol>"},{"location":"use/monitor_endpoints.html#enable-monitoring","title":"Enable monitoring","text":""},{"location":"use/monitor_endpoints.html#enable-monitoring-for-a-new-cluster","title":"Enable monitoring for a new cluster","text":"<p>You can enable monitoring for your cluster while creating the database.</p> <p>To enable monitoring for your database cluster, follow these steps:</p> <ol> <li> <p>From the Percona Everest Home page, click Create Database. The Create Database wizard opens.</p> </li> <li> <p>Navigate till you reach the Monitoring page.</p> </li> <li> <p>Turn on the Enable monitoring toggle.</p> <p></p> </li> <li> <p>Select the Monitoring endpoint from the drop down.</p> </li> <li> <p>Click Create Database. This will allow you to  monitor your database cluster.</p> </li> </ol>"},{"location":"use/monitor_endpoints.html#enable-monitoring-for-an-existing-cluster","title":"Enable monitoring for an existing cluster","text":"<p>You can enable monitoring for your cluster even after the database has been created.</p> <p>To enable monitoring for your database cluster, follow these steps:</p> <ol> <li> <p>Navigate to the Percona Everest homepage and choose the database cluster you want to monitor.</p> </li> <li> <p>Navigate to the Overview page and look for the Monitoring panel. Click on Edit.</p> <p></p> </li> <li> <p>Turn on the Enable monitoring toggle.</p> </li> <li> <p>Select the Monitoring endpoint from the drop-down.</p> </li> <li> <p>Click Save. This will allow you to monitor your database cluster.</p> </li> </ol>"},{"location":"use/monitor_endpoints.html#connect-to-pmm-and-monitor-your-databases","title":"Connect to PMM and monitor your databases","text":"<p>Here\u2019s how to monitor your databases using PMM:</p> <ol> <li> <p>Log in to PMM.</p> </li> <li> <p>From the PMM home page, go to  Dashboards &gt; Experimental. Here, you\u2019ll discover a comprehensive view of the various databases that you can view.</p> <p></p> </li> <li> <p>Go to Experimental &gt; Databases Overview to access the Database Overview dashboard. The following image shows that two PostgreSQL databases are monitored.</p> <p></p> </li> <li> <p>On the Databases Overview dashboard, you can monitor a specific database. To do this, select the desired database Engine from the drop-down menu.</p> <p></p> <p>On this dashboard, you will find a graphical representation that highlights the following:</p> <ul> <li>A comprehensive list of databases under monitoring </li> <li> <p>A clear identification of slow-performing queries </p> </li> <li> <p>The execution time for each query</p> </li> <li> <p>A record of all executed queries, providing an overview of the activity. </p> </li> </ul> </li> <li> <p>For instance, to get a comprehensive view of your PostgreSQL databases being monitored, go to  Dashboards &gt; Experimental &gt; PostgreSQL Instance.</p> <p></p> </li> <li> <p>To see a comprehensive list of all the pods in the cluster along with their respective CPU and RAM usage statistics, go to  Dashboards &gt; Experimental &gt; DB Cluster Summary. This provides insights into how your cluster performs and resources are allocated, enabling you to make informed decisions.</p> <p></p> <p>If you\u2019re looking to dive deeper into the dashboard\u2019s features and functionality, check out the PMM documentation.</p> </li> </ol>"},{"location":"use/monitor_endpoints.html#edit-monitoring-endpoint","title":"Edit monitoring endpoint","text":"<p>To edit a monitoring endpoint from the Percona Everest UI:</p> <ol> <li> <p>From the Percona Everest Homepage, navigate to  Settings &gt; Monitoring endpoints.</p> </li> <li> <p>Click on the ellipsis (three dots) next to the endpoint you need to edit.</p> <p></p> </li> <li> <p>Click\u00a0Edit. The Edit monitoring endpoint\u00a0pop-up opens. In this dialogue box, edit the information as per your requirements.</p> <p></p> </li> <li> <p>Click Add.</p> </li> </ol>"},{"location":"use/monitor_endpoints.html#delete-monitoring-endpoint","title":"Delete monitoring endpoint","text":"<p>To delete a monitoring endpoint from the Percona Everest UI:</p> <ol> <li> <p>From the Percona Everest Homepage, navigate to  Settings &gt; Monitoring endpoints.</p> </li> <li> <p>Click on the ellipsis (three dots) next to the endpoint you need to delete.</p> </li> <li> <p>Click Delete. The Delete monitoring endpoint dialogue box opens.</p> <p></p> </li> <li> <p>Click Delete.</p> </li> </ol>"},{"location":"use/multi-namespaces.html","title":"Multiple namespaces","text":"<p>In Kubernetes, the concept of namespaces enables you to create isolated groups of resources within a single cluster. These namespaces provide a way to organize and manage resources without interfering with other resources within the same cluster.</p> <p>Important</p> <p>Resource names must be unique within a specific namespace but not across different namespaces.</p>"},{"location":"use/multi-namespaces.html#use-case-for-multiple-namespaces","title":"Use case for multiple namespaces","text":"<p>If you are dealing with complex environments comprising Kubernetes clusters that need to be used with Percona Everest, you can leverage the multiple namespace feature. This feature enables logical partitioning within the cluster.</p> <p>For example, you can deploy different environments like production, development, and QA within a single cluster by using multiple namespaces. This approach enables you to efficiently manage the clusters.</p>"},{"location":"use/multi-namespaces.html#default-namespaces-in-percona-everest","title":"Default namespaces in Percona Everest","text":"<p>Important</p> <p>The following namespaces are restricted and cannot be used for deploying databases.</p> <p>Percona Everest will create the following namespaces by default. You can see these default namespaces while Percona Everest is being installed.</p> <ul> <li>everest-olm: hosts the Operator Lifecycle Manager that manages all operators that are part of everest</li> <li>everest-system: hosts Everest </li> <li>everest-monitoring: hosts the monitoring stack for kubernetes metrics (VictoriaMetrics and kube-state-metrics)</li> </ul> <p>To set up the namespaces that Percona Everest will manage and where you can deploy your databases, see the Installation section.</p>"},{"location":"use/multi-namespaces.html#configure-multiple-namespaces","title":"Configure multiple namespaces","text":"<p>The following holds true for multiple namespaces:</p> <ul> <li> <p>You can configure multiple namespaces in Percona Everest using the <code>everestctl namespaces add [NAMESPACE]</code> command.</p> </li> <li> <p>You can install different operators in various namespaces using the <code>everestctl namespaces update [NAMESPACE]</code> command.</p> </li> </ul> Example: Configuring multiple namesapces and installing various operators within those namespaces <p>To install various operators in different namespaces, such as MongoDB and MySQL operator in namespace production, and PostgreSQL operator in namespace development, run the following commands:</p> <ol> <li> <p><code>everestctl namespaces add development</code></p> Expected output <pre><code>? Which operators do you want to install? PostgreSQL\n\u2713 Installing namespace 'development'\n</code></pre> </li> <li> <p><code>everestctl namespaces add production</code>.</p> Expected output <pre><code>? Which operators do you want to install? MySQL, MongoDB\n\u2713 Installing namespace 'production'\n</code></pre> </li> </ol> <p>Go to Percona Everest UI and navigate to  Settings &gt; Namespaces. A list of all the namespaces that you have created will appear here.</p> <p></p>"},{"location":"use/multi-namespaces.html#deploy-the-database-in-your-namespace","title":"Deploy the database in your namespace","text":"<p>Once you have configured your namespaces, you can choose the namespace where you want to deploy your new database cluster.</p> <p></p> <p>For information on deploying a new database cluster in the namespace, see the Provision a database section.</p>"},{"location":"use/scaling.html","title":"Scale database deployment","text":"<p>Manual scaling in Percona Everest allows for easy adjustment of database capacity and performance to meet the changing demands.</p>"},{"location":"use/scaling.html#vertical-scaling","title":"Vertical scaling","text":"<p>Vertical scaling is essential for addressing increased workloads or performance demands. You can scale up or scale down as per your requirements. </p> <ul> <li> <p>Scale up</p> <p>You can vertically scale up your Percona Everest instance by modifying its configuration to a higher performance tier. This involves increasing the memory and/or CPU threshold.       </p> <p>Example</p> <p>For optimal cluster performance, select Large as the Resource size per node when creating a database cluster. It has higher preset thresholds for CPU, memory, and disk as compared to Small.            </p> <p></p> </li> <li> <p>Scale down</p> <p>Similarly, you can scale down (downsize) your database instance when the resource requirements decrease, which can help optimize costs.</p> <p>Example</p> <p>If performance is not a criterion and resource requirements are low, opt for Small as the Resource size per node when creating a database cluster. This option has lower preset thresholds for CPU, Memory, and Disk compared to the Large.        </p> </li> </ul>"},{"location":"use/scaling.html#horizontal-scaling","title":"Horizontal scaling","text":"<p>To scale Percona Everest horizontally, add database nodes to the existing cluster. These nodes share the workload, distributing queries and transactions more evenly, which can lead to improved performance, availability, and database resilience.</p> <p></p>"},{"location":"use/scaling.html#how-to-scale-your-database-instances","title":"How to scale your database instances","text":"<p>Important</p> <p>The allocated resources should be sized based on the expected workload to avoid unexpected restarts of the DB cluster nodes due to under-provisioning.</p> <p>To scale your database instances:</p> <ol> <li>From the Percona Everest homepage, select the database you wish to scale. The Overview page will then be displayed.</li> <li>Navigate to the Resources widget and click Edit. This will open the Edit Topology screen.</li> <li>Select the Number of nodes. </li> <li>Select the Resources per node. When selecting the Resources per node, the threshold values are automatically populated in the CPU, MEMORY, and DISK fields.</li> <li>Set the Routers, PG Bouncers, or Proxies and their corresponding resources based on the technology used. Click Save.</li> </ol>"}]}